var documenterSearchIndex = {"docs":
[{"location":"bayesian/#Bayesian-VAR-(BVAR)","page":"Bayesian VAR","title":"Bayesian VAR (BVAR)","text":"This chapter covers Bayesian estimation methods for Vector Autoregression models, including the Minnesota prior, hyperparameter optimization, and MCMC inference.","category":"section"},{"location":"bayesian/#Introduction","page":"Bayesian VAR","title":"Introduction","text":"Bayesian VAR (BVAR) estimation addresses the curse of dimensionality in VAR models by incorporating prior information to shrink coefficient estimates. This is particularly valuable when:\n\nThe number of parameters is large relative to sample size\nPrior economic knowledge should influence estimation\nUncertainty quantification via posterior distributions is desired\nForecasting performance is paramount\n\nKey References: Litterman (1986), Doan, Litterman & Sims (1984), Giannone, Lenza & Primiceri (2015)\n\n","category":"section"},{"location":"bayesian/#Bayesian-Framework","page":"Bayesian VAR","title":"Bayesian Framework","text":"","category":"section"},{"location":"bayesian/#The-Prior-Likelihood-Posterior-Paradigm","page":"Bayesian VAR","title":"The Prior-Likelihood-Posterior Paradigm","text":"In the Bayesian approach, we treat the VAR parameters as random variables and update our beliefs using Bayes' theorem:\n\np(B Sigma  Y) propto p(Y  B Sigma) cdot p(B Sigma)\n\nwhere:\n\np(Y  B Sigma) is the likelihood\np(B Sigma) is the prior\np(B Sigma  Y) is the posterior","category":"section"},{"location":"bayesian/#Natural-Conjugate-Prior","page":"Bayesian VAR","title":"Natural Conjugate Prior","text":"For computational convenience, we use the Normal-Inverse-Wishart conjugate prior:\n\nSigma sim textIW(nu_0 S_0)\n\ntextvec(B)  Sigma sim N(textvec(B_0) Sigma otimes Omega_0)\n\nThis yields a closed-form posterior of the same family.\n\n","category":"section"},{"location":"bayesian/#The-Minnesota-Prior","page":"Bayesian VAR","title":"The Minnesota Prior","text":"","category":"section"},{"location":"bayesian/#Motivation","page":"Bayesian VAR","title":"Motivation","text":"The Minnesota prior (Litterman, 1986; Doan, Litterman & Sims, 1984) shrinks VAR coefficients toward a random walk prior. This reflects the empirical observation that many macroeconomic variables are well-approximated by random walks, especially at short horizons.","category":"section"},{"location":"bayesian/#Prior-Specification","page":"Bayesian VAR","title":"Prior Specification","text":"Prior Mean: Each variable follows a random walk:\n\nEA_1ii = 1 quad EA_1ij = 0 text for  i neq j quad EA_l = 0 text for  l  1\n\nPrior Variance: The prior variance for coefficient (ij) at lag l is:\n\ntextVar(A_lij) = begincases\nfractau^2l^d  textif  i = j text (own lag) \nfractau^2 omega^2l^d cdot fracsigma_i^2sigma_j^2  textif  i neq j text (cross lag)\nendcases\n\nwhere:\n\ntau is the overall tightness (shrinkage intensity)\nd is the lag decay (typically d = 2)\nomega controls cross-variable shrinkage (typically omega  1)\nsigma_i^2 is the residual variance from a univariate AR(1) for variable i","category":"section"},{"location":"bayesian/#Interpretation-of-Hyperparameters","page":"Bayesian VAR","title":"Interpretation of Hyperparameters","text":"Parameter Effect Typical Values\ntau Overall shrinkage (lower = more shrinkage) 0.01 – 1.0\nd Lag decay (higher = faster decay) 1, 2, 3\nomega Cross-variable penalty (lower = more penalty) 0.5 – 1.0","category":"section"},{"location":"bayesian/#Julia-Implementation","page":"Bayesian VAR","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Define hyperparameters\nhyper = MinnesotaHyperparameters(\n    τ = 0.5,      # Overall tightness\n    d = 2.0,      # Lag decay\n    ω_own = 1.0,  # Own-lag variance scaling\n    ω_cross = 1.0, # Cross-lag variance scaling\n    ω_det = 1.0   # Deterministic terms scaling\n)\n\n# Use in BVAR estimation\nchain = estimate_bvar(Y, 2; n_samples=2000, n_adapts=500,\n                      prior=:minnesota, hyper=hyper)\n\n","category":"section"},{"location":"bayesian/#Dummy-Observations-Approach","page":"Bayesian VAR","title":"Dummy Observations Approach","text":"","category":"section"},{"location":"bayesian/#Implementation-via-Augmented-Regression","page":"Bayesian VAR","title":"Implementation via Augmented Regression","text":"We implement the Minnesota prior using dummy observations (Theil-Goldberger mixed estimation). The augmented data matrices are:\n\nPrior on coefficients (tightness dummies):\n\nY_d = beginbmatrix\ntextdiag(sigma_1 ldots sigma_n)  tau \n0_n(p-1) times n \ntextdiag(sigma_1 ldots sigma_n) \n0_1 times n\nendbmatrix quad\nX_d = beginbmatrix\n0_n times 1  J_p otimes textdiag(sigma_1 ldots sigma_n)  tau \n0_n(p-1) times 1  I_p-1 otimes textdiag(sigma_1 ldots sigma_n) \n0_n times 1  0_n times np \nc  0_1 times np\nendbmatrix\n\nwhere J_p = textdiag(1 2^d ldots p^d).\n\nThe posterior is then computed as OLS on the augmented data Y Y_d and X X_d.\n\nReference: Litterman (1986), Kadiyala & Karlsson (1997), Bańbura, Giannone & Reichlin (2010)","category":"section"},{"location":"bayesian/#Julia-Implementation-2","page":"Bayesian VAR","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Generate dummy observations for Minnesota prior\nY_dummy, X_dummy = gen_dummy_obs(Y, p, hyper)\n\n# Augment data\nY_aug = vcat(Y_actual, Y_dummy)\nX_aug = vcat(X_actual, X_dummy)\n\n# Posterior via OLS on augmented data\nB_post = (X_aug'X_aug) \\ (X_aug'Y_aug)\n\n","category":"section"},{"location":"bayesian/#Hyperparameter-Optimization","page":"Bayesian VAR","title":"Hyperparameter Optimization","text":"","category":"section"},{"location":"bayesian/#Marginal-Likelihood","page":"Bayesian VAR","title":"Marginal Likelihood","text":"Rather than selecting tau subjectively, we can optimize it by maximizing the marginal likelihood (Giannone, Lenza & Primiceri, 2015):\n\np(Y  tau) = int p(Y  B Sigma) p(B Sigma  tau)  dB  dSigma\n\nFor the Normal-Inverse-Wishart prior with dummy observations, the log marginal likelihood has an analytical form:\n\nlog p(Y  tau) = c + fracT-k2 logtildeS^-1 - fracT_d2 logtildeS_d^-1 + log fracGamma_n(fracT+T_d - k2)Gamma_n(fracT_d - k2)\n\nwhere tildeS and tildeS_d are the residual sum of squares from the augmented and dummy-only regressions.\n\nReference: Giannone, Lenza & Primiceri (2015), Carriero, Clark & Marcellino (2015)","category":"section"},{"location":"bayesian/#Julia-Implementation-3","page":"Bayesian VAR","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Find optimal shrinkage using marginal likelihood\nbest_hyper = optimize_hyperparameters(Y, p; grid_size=20)\n\nprintln(\"Optimal hyperparameters:\")\nprintln(\"  τ (overall tightness): \", round(best_hyper.tau, digits=4))\nprintln(\"  d (lag decay): \", best_hyper.d)\n\n# Compute log marginal likelihood\nlml = log_marginal_likelihood(Y, p, hyper)","category":"section"},{"location":"bayesian/#Grid-Search-Options","page":"Bayesian VAR","title":"Grid Search Options","text":"# Custom optimization grid\nbest_hyper = optimize_hyperparameters(Y, p;\n    grid_size = 30,           # Number of grid points\n    tau_range = (0.01, 2.0),  # Range for τ\n    d_values = [1, 2, 3]      # Values for d\n)\n\n","category":"section"},{"location":"bayesian/#MCMC-Estimation-with-Turing.jl","page":"Bayesian VAR","title":"MCMC Estimation with Turing.jl","text":"","category":"section"},{"location":"bayesian/#The-BVAR-Model","page":"Bayesian VAR","title":"The BVAR Model","text":"For more flexible priors or non-conjugate settings, we use MCMC via Turing.jl with the NUTS sampler:\n\n@model function bvar_model(Y, X, prior_mean, prior_var, ν₀, S₀)\n    n = size(Y, 2)\n    k = size(X, 2)\n\n    # Prior on error covariance\n    Σ ~ InverseWishart(ν₀, S₀)\n\n    # Prior on coefficients\n    B ~ MatrixNormal(prior_mean, prior_var, Σ)\n\n    # Likelihood\n    for t in axes(Y, 1)\n        Y[t, :] ~ MvNormal(X[t, :]' * B, Σ)\n    end\nend","category":"section"},{"location":"bayesian/#Julia-Implementation-4","page":"Bayesian VAR","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Estimate BVAR with MCMC\nchain = estimate_bvar(Y, p;\n    n_samples = 2000,     # Posterior samples\n    n_adapts = 500,       # Adaptation samples\n    prior = :minnesota,   # Prior type\n    hyper = best_hyper    # Hyperparameters\n)\n\n# Access posterior draws\n# chain.samples contains the MCMC draws","category":"section"},{"location":"bayesian/#Convergence-Diagnostics","page":"Bayesian VAR","title":"Convergence Diagnostics","text":"# Extract chain parameters\nparams = extract_chain_parameters(chain)\n\n# Check R-hat statistics\n# Check effective sample sizes\n# Trace plots for visual inspection\n\nReference: Gelman et al. (2013), Hoffman & Gelman (2014)\n\n","category":"section"},{"location":"bayesian/#Bayesian-Impulse-Response-Functions","page":"Bayesian VAR","title":"Bayesian Impulse Response Functions","text":"","category":"section"},{"location":"bayesian/#Posterior-IRF-Distribution","page":"Bayesian VAR","title":"Posterior IRF Distribution","text":"For each MCMC draw, we compute impulse responses, yielding a posterior distribution over IRFs. We report:\n\nPosterior median: Point estimate\nCredible intervals: 68% (16th-84th percentile) or 90% (5th-95th percentile)","category":"section"},{"location":"bayesian/#Cholesky-Identification","page":"Bayesian VAR","title":"Cholesky Identification","text":"using MacroEconometricModels\n\n# Bayesian IRF with Cholesky identification\nH = 20  # Horizon\nbirf_chol = irf(chain, p, n, H; method=:cholesky)\n\n# birf_chol.quantiles is (H+1) × n × n × 3 array\n# [:, :, :, 1] = 16th percentile\n# [:, :, :, 2] = median\n# [:, :, :, 3] = 84th percentile\n\nprintln(\"Bayesian IRF of GDP to own shock:\")\nfor h in [0, 4, 8, 12, 20]\n    med = round(birf_chol.quantiles[h+1, 1, 1, 2], digits=3)\n    lo = round(birf_chol.quantiles[h+1, 1, 1, 1], digits=3)\n    hi = round(birf_chol.quantiles[h+1, 1, 1, 3], digits=3)\n    println(\"  h=$h: $med [$lo, $hi]\")\nend","category":"section"},{"location":"bayesian/#Sign-Restrictions","page":"Bayesian VAR","title":"Sign Restrictions","text":"# Define sign restriction check function\nfunction check_demand_shock(irf_array)\n    # Demand shock: positive GDP and inflation on impact\n    return irf_array[1, 1, 1] > 0 && irf_array[1, 2, 1] > 0\nend\n\n# Bayesian IRF with sign restrictions\nbirf_sign = irf(chain, p, n, H;\n    method = :sign,\n    check_func = check_demand_shock\n)\n\nprintln(\"Bayesian sign-restricted demand shock → GDP:\")\nfor h in [0, 4, 8, 12]\n    med = round(birf_sign.quantiles[h+1, 1, 1, 2], digits=3)\n    lo = round(birf_sign.quantiles[h+1, 1, 1, 1], digits=3)\n    hi = round(birf_sign.quantiles[h+1, 1, 1, 3], digits=3)\n    println(\"  h=$h: $med [$lo, $hi]\")\nend\n\n","category":"section"},{"location":"bayesian/#Bayesian-FEVD","page":"Bayesian VAR","title":"Bayesian FEVD","text":"","category":"section"},{"location":"bayesian/#Posterior-FEVD-Distribution","page":"Bayesian VAR","title":"Posterior FEVD Distribution","text":"Similarly, forecast error variance decomposition can be computed for each posterior draw:\n\nusing MacroEconometricModels\n\n# Bayesian FEVD\nbfevd = fevd(chain, p, n, H; method=:cholesky)\n\n# Report median and credible intervals\nfor h in [1, 4, 12, 20]\n    println(\"FEVD at h=$h:\")\n    med = round(bfevd.quantiles[h, 1, 1, 2] * 100, digits=1)\n    lo = round(bfevd.quantiles[h, 1, 1, 1] * 100, digits=1)\n    hi = round(bfevd.quantiles[h, 1, 1, 3] * 100, digits=1)\n    println(\"  Shock 1 → Var 1: $med% [$lo%, $hi%]\")\nend\n\n","category":"section"},{"location":"bayesian/#Information-Criteria","page":"Bayesian VAR","title":"Information Criteria","text":"","category":"section"},{"location":"bayesian/#Log-Likelihood","page":"Bayesian VAR","title":"Log-Likelihood","text":"For a Gaussian VAR, the log-likelihood is:\n\nlog L = -fracT cdot n2 log(2pi) - fracT2 logSigma - frac12 sum_t=1^T u_t Sigma^-1 u_t","category":"section"},{"location":"bayesian/#Marginal-Likelihood-(Bayesian)","page":"Bayesian VAR","title":"Marginal Likelihood (Bayesian)","text":"For Bayesian model comparison, we use the marginal likelihood (also called evidence):\n\np(Y  mathcalM) = int p(Y  theta mathcalM) p(theta  mathcalM)  dtheta\n\nModels with higher marginal likelihood better balance fit and complexity.\n\n","category":"section"},{"location":"bayesian/#Complete-Example","page":"Bayesian VAR","title":"Complete Example","text":"using MacroEconometricModels\nusing Random\n\nRandom.seed!(42)\n\n# Generate data\nT, n, p = 200, 3, 2\nY = randn(T, n)\nfor t in 2:T\n    Y[t, :] = 0.5 * Y[t-1, :] + 0.3 * randn(n)\nend\n\n# Step 1: Optimize hyperparameters\nprintln(\"Optimizing hyperparameters...\")\nbest_hyper = optimize_hyperparameters(Y, p; grid_size=20)\nprintln(\"Optimal τ: \", round(best_hyper.tau, digits=4))\n\n# Step 2: Estimate BVAR\nprintln(\"\\nEstimating BVAR with MCMC...\")\nchain = estimate_bvar(Y, p;\n    n_samples = 2000,\n    n_adapts = 500,\n    prior = :minnesota,\n    hyper = best_hyper\n)\n\n# Step 3: Compute Bayesian IRF\nH = 20\nbirf = irf(chain, p, n, H; method=:cholesky)\n\n# Step 4: Report results\nprintln(\"\\nBayesian IRF (shock 1 → variable 1):\")\nfor h in [0, 4, 8, 12, 20]\n    med = round(birf.quantiles[h+1, 1, 1, 2], digits=3)\n    lo = round(birf.quantiles[h+1, 1, 1, 1], digits=3)\n    hi = round(birf.quantiles[h+1, 1, 1, 3], digits=3)\n    println(\"  h=$h: $med [$lo, $hi]\")\nend\n\n","category":"section"},{"location":"bayesian/#Large-BVAR","page":"Bayesian VAR","title":"Large BVAR","text":"","category":"section"},{"location":"bayesian/#Handling-High-Dimensional-Systems","page":"Bayesian VAR","title":"Handling High-Dimensional Systems","text":"For large VAR systems (many variables), the Minnesota prior becomes essential:\n\nusing MacroEconometricModels\n\n# Large system: 20 variables\nn = 20\np = 4\n\n# Stronger shrinkage for large systems\nhyper_large = MinnesotaHyperparameters(\n    τ = 0.1,      # Tighter prior\n    d = 2.0,\n    ω_own = 1.0,\n    ω_cross = 0.5, # Penalize cross-variable coefficients\n    ω_det = 1.0\n)\n\n# Or optimize automatically\nbest_hyper = optimize_hyperparameters(Y_large, p)\n\nReference: Bańbura, Giannone & Reichlin (2010)\n\n","category":"section"},{"location":"bayesian/#References","page":"Bayesian VAR","title":"References","text":"","category":"section"},{"location":"bayesian/#Minnesota-Prior-and-BVAR","page":"Bayesian VAR","title":"Minnesota Prior and BVAR","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). \"Large Bayesian Vector Auto Regressions.\" Journal of Applied Econometrics, 25(1), 71-92.\nCarriero, A., Clark, T. E., & Marcellino, M. (2015). \"Bayesian VARs: Specification Choices and Forecast Accuracy.\" Journal of Applied Econometrics, 30(1), 46-73.\nDoan, T., Litterman, R., & Sims, C. (1984). \"Forecasting and Conditional Projection Using Realistic Prior Distributions.\" Econometric Reviews, 3(1), 1-100.\nGiannone, D., Lenza, M., & Primiceri, G. E. (2015). \"Prior Selection for Vector Autoregressions.\" Review of Economics and Statistics, 97(2), 436-451.\nKadiyala, K. R., & Karlsson, S. (1997). \"Numerical Methods for Estimation and Inference in Bayesian VAR-Models.\" Journal of Applied Econometrics, 12(2), 99-132.\nLitterman, R. B. (1986). \"Forecasting with Bayesian Vector Autoregressions—Five Years of Experience.\" Journal of Business & Economic Statistics, 4(1), 25-38.","category":"section"},{"location":"bayesian/#MCMC-and-Bayesian-Inference","page":"Bayesian VAR","title":"MCMC and Bayesian Inference","text":"Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). CRC Press.\nHoffman, M. D., & Gelman, A. (2014). \"The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.\" Journal of Machine Learning Research, 15(1), 1593-1623.","category":"section"},{"location":"api_functions/#api_functions","page":"Functions","title":"API Functions","text":"This page documents all functions in MacroEconometricModels.jl, organized by module.\n\n","category":"section"},{"location":"api_functions/#VAR-Estimation","page":"Functions","title":"VAR Estimation","text":"","category":"section"},{"location":"api_functions/#Frequentist-Estimation","page":"Functions","title":"Frequentist Estimation","text":"","category":"section"},{"location":"api_functions/#Bayesian-Estimation","page":"Functions","title":"Bayesian Estimation","text":"","category":"section"},{"location":"api_functions/#Prior-Specification","page":"Functions","title":"Prior Specification","text":"","category":"section"},{"location":"api_functions/#Structural-Identification","page":"Functions","title":"Structural Identification","text":"","category":"section"},{"location":"api_functions/#Innovation-Accounting","page":"Functions","title":"Innovation Accounting","text":"","category":"section"},{"location":"api_functions/#Impulse-Response-Functions","page":"Functions","title":"Impulse Response Functions","text":"","category":"section"},{"location":"api_functions/#Forecast-Error-Variance-Decomposition","page":"Functions","title":"Forecast Error Variance Decomposition","text":"","category":"section"},{"location":"api_functions/#Historical-Decomposition","page":"Functions","title":"Historical Decomposition","text":"","category":"section"},{"location":"api_functions/#Summary-Tables","page":"Functions","title":"Summary Tables","text":"","category":"section"},{"location":"api_functions/#Local-Projections","page":"Functions","title":"Local Projections","text":"","category":"section"},{"location":"api_functions/#Core-LP-Estimation-and-Covariance","page":"Functions","title":"Core LP Estimation and Covariance","text":"","category":"section"},{"location":"api_functions/#LP-Extensions-(IV,-Smooth,-State-Dependent,-Propensity)","page":"Functions","title":"LP Extensions (IV, Smooth, State-Dependent, Propensity)","text":"","category":"section"},{"location":"api_functions/#Factor-Models","page":"Functions","title":"Factor Models","text":"","category":"section"},{"location":"api_functions/#GMM-Estimation","page":"Functions","title":"GMM Estimation","text":"","category":"section"},{"location":"api_functions/#Unit-Root-and-Cointegration-Tests","page":"Functions","title":"Unit Root and Cointegration Tests","text":"","category":"section"},{"location":"api_functions/#Utility-Functions","page":"Functions","title":"Utility Functions","text":"","category":"section"},{"location":"api_functions/#MacroEconometricModels._compute_aic_bic-Union{Tuple{T}, Tuple{T, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels._compute_aic_bic","text":"_compute_aic_bic(loglik, k, n)\n\nCompute AIC and BIC from log-likelihood, number of parameters k, and sample size n.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._css_objective-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._css_objective","text":"_css_objective(params, y, p, q; include_intercept=true) -> T\n\nConditional Sum of Squares objective function.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._difference-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._difference","text":"Apply d-order differencing to a time series.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._estimate_ar_ols-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._estimate_ar_ols","text":"Estimate AR model via OLS.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._estimate_css-Union{Tuple{T}, Tuple{Vector{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._estimate_css","text":"_estimate_css(y, p, q; include_intercept=true, max_iter=500, tol=1e-8) -> (params, converged, iterations)\n\nEstimate ARMA parameters via Conditional Sum of Squares.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._estimate_mle-Union{Tuple{T}, Tuple{Vector{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._estimate_mle","text":"_estimate_mle(y, p, q; include_intercept=true, init_params=nothing, max_iter=500, tol=1e-8)\n\nEstimate ARMA parameters via Maximum Likelihood using Kalman filter.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._innovations_algorithm-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._innovations_algorithm","text":"_innovations_algorithm(y, q) -> theta\n\nEstimate MA coefficients via innovations algorithm.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._pack_arma_params-Union{Tuple{T}, Tuple{T, Vector{T}, Vector{T}}} where T","page":"Functions","title":"MacroEconometricModels._pack_arma_params","text":"_pack_arma_params(c, phi, theta; include_intercept=true, log_sigma2=nothing)\n\nPack ARMA parameters into a single vector for optimization.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._truncate_to_invertible-Union{Tuple{Vector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._truncate_to_invertible","text":"Truncate MA coefficients to ensure invertibility.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._truncate_to_stationary-Union{Tuple{Vector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._truncate_to_stationary","text":"Truncate AR coefficients to ensure stationarity.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._validate_arima_inputs-Union{Tuple{T}, Tuple{Vector{T}, Int64, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels._validate_arima_inputs","text":"Validate ARIMA inputs.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._white_noise_fit-Union{Tuple{Vector{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels._white_noise_fit","text":"_white_noise_fit(y; include_intercept=true)\n\nFit a white-noise (p=0, q=0) model. Returns (c, sigma2, loglik, residuals, fitted).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._yule_walker-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._yule_walker","text":"_yule_walker(y, p) -> phi\n\nEstimate AR coefficients via Yule-Walker equations.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_ar-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_ar","text":"estimate_ar(y, p; method=:ols, include_intercept=true) -> ARModel\n\nEstimate AR(p) model: yₜ = c + φ₁yₜ₋₁ + ... + φₚyₜ₋ₚ + εₜ\n\nArguments\n\ny: Time series vector\np: AR order (must be ≥ 1)\nmethod: Estimation method (:ols or :mle)\ninclude_intercept: Whether to include constant term\n\nReturns\n\nARModel with estimated coefficients and diagnostics.\n\nExample\n\ny = randn(200)\nmodel = estimate_ar(y, 2)\nprintln(model.phi)  # AR coefficients\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_arima-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_arima","text":"estimate_arima(y, p, d, q; method=:css_mle, include_intercept=true, max_iter=500) -> ARIMAModel\n\nEstimate ARIMA(p,d,q) model by differencing d times and fitting ARMA(p,q).\n\nArguments\n\ny: Time series vector\np: AR order\nd: Integration order (number of differences)\nq: MA order\nmethod: Estimation method (:css, :mle, or :css_mle)\ninclude_intercept: Whether to include constant term (on differenced series)\nmax_iter: Maximum optimization iterations\n\nReturns\n\nARIMAModel with estimated coefficients and diagnostics.\n\nExample\n\ny = cumsum(randn(200))  # Random walk\nmodel = estimate_arima(y, 1, 1, 0)  # ARIMA(1,1,0)\nprintln(model.phi)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_arma-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_arma","text":"estimate_arma(y, p, q; method=:css_mle, include_intercept=true, max_iter=500) -> ARMAModel\n\nEstimate ARMA(p,q) model: yₜ = c + φ₁yₜ₋₁ + ... + φₚyₜ₋ₚ + εₜ + θ₁εₜ₋₁ + ... + θqεₜ₋q\n\nArguments\n\ny: Time series vector\np: AR order\nq: MA order\nmethod: Estimation method (:css, :mle, or :css_mle)\ninclude_intercept: Whether to include constant term\nmax_iter: Maximum optimization iterations\n\nReturns\n\nARMAModel with estimated coefficients and diagnostics.\n\nExample\n\ny = randn(200)\nmodel = estimate_arma(y, 1, 1)\nprintln(\"AR: \", model.phi, \" MA: \", model.theta)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_ma-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_ma","text":"estimate_ma(y, q; method=:css_mle, include_intercept=true, max_iter=500) -> MAModel\n\nEstimate MA(q) model: yₜ = c + εₜ + θ₁εₜ₋₁ + ... + θqεₜ₋q\n\nArguments\n\ny: Time series vector\nq: MA order (must be ≥ 1)\nmethod: Estimation method (:css, :mle, or :css_mle)\ninclude_intercept: Whether to include constant term\nmax_iter: Maximum optimization iterations\n\nReturns\n\nMAModel with estimated coefficients and diagnostics.\n\nExample\n\ny = randn(200)\nmodel = estimate_ma(y, 1)\nprintln(model.theta)  # MA coefficient\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_var-Tuple{DataFrames.DataFrame, Int64}","page":"Functions","title":"MacroEconometricModels.estimate_var","text":"Estimate VAR from DataFrame. Use vars to select columns.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_var-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_var","text":"estimate_var(Y::AbstractMatrix{T}, p::Int; check_stability::Bool=true) -> VARModel{T}\n\nEstimate VAR(p) via OLS: Yₜ = c + A₁Yₜ₋₁ + ... + AₚYₜ₋ₚ + uₜ.\n\nArguments\n\nY: Data matrix (T × n)\np: Number of lags\ncheck_stability: If true (default), warns if estimated VAR is non-stationary\n\nReturns\n\nVARModel with estimated coefficients, residuals, covariance matrix, and information criteria.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.select_lag_order-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.select_lag_order","text":"Select optimal lag order via information criterion (:aic, :bic, :hqic).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.confint-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"StatsAPI.confint","text":"Confidence intervals at given level (default 95%).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.loglikelihood-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"StatsAPI.loglikelihood","text":"Gaussian log-likelihood.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.predict-Tuple{VARModel}","page":"Functions","title":"StatsAPI.predict","text":"In-sample fitted values.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.predict-Union{Tuple{T}, Tuple{VARModel{T}, Int64}} where T","page":"Functions","title":"StatsAPI.predict","text":"Out-of-sample forecasts for steps periods.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.r2-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"StatsAPI.r2","text":"R² for each equation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#StatsAPI.vcov-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"StatsAPI.vcov","text":"Covariance of vectorized coefficients: Σ ⊗ (X'X)⁻¹.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_bvar-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_bvar","text":"estimate_bvar(Y, p; n_samples=1000, n_adapts=500, prior=:normal, hyper=nothing,\n              sampler=:nuts, sampler_args=(;)) -> Chains\n\nEstimate Bayesian VAR via Turing.jl MCMC.\n\nSamplers: :nuts (default), :hmc, :hmcda, :is, :smc, :pg. Prior: :normal (default) or :minnesota with optional hyper::MinnesotaHyperparameters.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.extract_chain_parameters-Tuple{MCMCChains.Chains}","page":"Functions","title":"MacroEconometricModels.extract_chain_parameters","text":"extract_chain_parameters(chain::Chains) -> (b_vecs, sigmas)\n\nExtract coefficient vectors and covariance matrices from MCMC chain. Handles both diagonal (gradient samplers) and InverseWishart (particle samplers) parameterizations.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.get_sampler-Tuple{Symbol, Int64, NamedTuple}","page":"Functions","title":"MacroEconometricModels.get_sampler","text":"Create Turing sampler from symbol. Supports: :nuts, :hmc, :hmcda, :is, :smc, :pg.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.parameters_to_model-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, Int64, Int64}, Tuple{AbstractVector{T}, AbstractVector{T}, Int64, Int64, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.parameters_to_model","text":"Convert chain parameters to VARModel. Provide data for residual computation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.posterior_mean_model-Tuple{MCMCChains.Chains, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.posterior_mean_model","text":"VARModel with posterior mean parameters.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.posterior_median_model-Tuple{MCMCChains.Chains, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.posterior_median_model","text":"VARModel with posterior median parameters.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.var_bayes_sequential-Union{Tuple{T}, Tuple{Matrix{T}, Matrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.var_bayes_sequential","text":"Sequential BVAR model with full covariance for particle-based samplers (SMC, PG). Uses InverseWishart for compatibility with particle samplers (no AD required).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.var_bayes_vectorized-Union{Tuple{T}, Tuple{Matrix{T}, Matrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.var_bayes_vectorized","text":"Vectorized BVAR model for gradient-based samplers (NUTS, HMC, HMCDA). Uses diagonal covariance for numerical stability with ForwardDiff AD.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.gen_dummy_obs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, MinnesotaHyperparameters}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.gen_dummy_obs","text":"gen_dummy_obs(Y, p, hyper) -> (Y_dummy, X_dummy)\n\nGenerate Minnesota prior dummy observations. Hyperparameters: tau (tightness), decay, lambda (sum-of-coef), mu (co-persistence), omega.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.log_marginal_likelihood-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, MinnesotaHyperparameters}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.log_marginal_likelihood","text":"log_marginal_likelihood(Y, p, hyper) -> T\n\nClosed-form log marginal likelihood for BVAR with Minnesota prior.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.optimize_hyperparameters-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.optimize_hyperparameters","text":"Optimize tau via grid search on marginal likelihood.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.optimize_hyperparameters_full-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.optimize_hyperparameters_full","text":"Full grid search over tau, lambda, mu.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._build_zero_constraint_matrix-Union{Tuple{T}, Tuple{SVARRestrictions, Int64, Array{Matrix{T}, 1}, LinearAlgebra.LowerTriangular{T, Matrix{T}}}} where T","page":"Functions","title":"MacroEconometricModels._build_zero_constraint_matrix","text":"Build constraint matrix for zero restrictions on shock j.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._check_sign_restrictions-Union{Tuple{T}, Tuple{Array{T, 3}, SVARRestrictions}} where T","page":"Functions","title":"MacroEconometricModels._check_sign_restrictions","text":"Check if all sign restrictions are satisfied.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._check_zero_restrictions-Union{Tuple{T}, Tuple{Array{T, 3}, SVARRestrictions}} where T","page":"Functions","title":"MacroEconometricModels._check_zero_restrictions","text":"Check if all zero restrictions are satisfied.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_importance_weight-Union{Tuple{T}, Tuple{Matrix{T}, SVARRestrictions, Array{Matrix{T}, 1}, LinearAlgebra.LowerTriangular{T, Matrix{T}}}} where T","page":"Functions","title":"MacroEconometricModels._compute_importance_weight","text":"Compute importance weight for Q (corrects non-uniform prior from zero restrictions).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_irf_for_Q-Union{Tuple{T}, Tuple{VARModel{T}, Matrix{T}, Array{Matrix{T}, 1}, LinearAlgebra.LowerTriangular{T, Matrix{T}}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_irf_for_Q","text":"Compute structural IRF for rotation Q.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_ma_coefficients-Union{Tuple{T}, Tuple{VARModel{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_ma_coefficients","text":"Compute MA coefficients Φ0, ..., Φhorizon.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._draw_Q_with_zero_restrictions-Union{Tuple{T}, Tuple{SVARRestrictions, Array{Matrix{T}, 1}, LinearAlgebra.LowerTriangular{T, Matrix{T}}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._draw_Q_with_zero_restrictions","text":"Draw orthogonal Q satisfying zero restrictions (Algorithm 2, Arias et al. 2018).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._draw_null_space_vector-Union{Tuple{T}, Tuple{Array{Vector{T}, 1}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._draw_null_space_vector","text":"Draw unit vector from null space of constraints.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._draw_uniform_orthogonal-Union{Tuple{Int64}, Tuple{T}, Tuple{Int64, Type{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._draw_uniform_orthogonal","text":"Draw uniformly from O(n) via QR decomposition.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._weighted_quantile-Union{Tuple{S}, Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{S}, Real}} where {T, S}","page":"Functions","title":"MacroEconometricModels._weighted_quantile","text":"Weighted quantile via linear interpolation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_Q-Union{Tuple{T}, Tuple{VARModel{T}, Symbol, Int64, Any, Any}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_Q","text":"compute_Q(model, method, horizon, check_func, narrative_check; max_draws=100)\n\nCompute identification matrix Q. Methods: :cholesky, :sign, :narrative, :long_run.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_irf-Union{Tuple{T}, Tuple{VARModel{T}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_irf","text":"compute_irf(model, Q, horizon) -> Array{T,3}\n\nCompute IRFs for rotation matrix Q. Returns (horizon × n × n) array. IRF[h, i, j] = response of variable i to shock j at horizon h-1.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_structural_shocks-Union{Tuple{T}, Tuple{VARModel{T}, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_structural_shocks","text":"Compute structural shocks: εₜ = Q'L⁻¹uₜ.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.generate_Q-Union{Tuple{Int64}, Tuple{T}, Tuple{Int64, Type{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.generate_Q","text":"Generate random orthogonal matrix via QR decomposition (Haar measure).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_arias-Union{Tuple{T}, Tuple{VARModel{T}, SVARRestrictions, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identify_arias","text":"identify_arias(model, restrictions, horizon; n_draws=1000, n_rotations=1000) -> AriasSVARResult\n\nIdentify SVAR using Arias et al. (2018) with zero and sign restrictions.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_arias_bayesian-Tuple{Any, Int64, Int64, SVARRestrictions, Int64}","page":"Functions","title":"MacroEconometricModels.identify_arias_bayesian","text":"identify_arias_bayesian(chain, p, n, restrictions, horizon; data=nothing, n_rotations=100, quantiles=[0.16,0.5,0.84])\n\nApply Arias identification to each posterior draw. Returns IRF quantiles, mean, acceptance rates.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_cholesky-Union{Tuple{VARModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identify_cholesky","text":"Identify via Cholesky decomposition (recursive ordering). Returns L where Σ = LL'.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_long_run-Union{Tuple{VARModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identify_long_run","text":"Identify via long-run restrictions: long-run cumulative impact matrix is lower triangular.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_narrative-Union{Tuple{T}, Tuple{VARModel{T}, Int64, Function, Function}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identify_narrative","text":"identify_narrative(model, horizon, sign_check, narrative_check; max_draws=1000)\n\nCombine sign and narrative restrictions. Returns (Q, irf, shocks).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identify_sign-Union{Tuple{T}, Tuple{VARModel{T}, Int64, Function}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identify_sign","text":"identify_sign(model, horizon, check_func; max_draws=1000) -> (Q, irf)\n\nFind Q satisfying sign restrictions via random draws.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.irf_mean-Union{Tuple{AriasSVARResult{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.irf_mean","text":"Compute weighted mean IRF from AriasSVARResult.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.irf_percentiles-Union{Tuple{AriasSVARResult{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.irf_percentiles","text":"Compute weighted IRF percentiles from AriasSVARResult.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.sign_restriction-Tuple{Int64, Int64, Symbol}","page":"Functions","title":"MacroEconometricModels.sign_restriction","text":"Create sign restriction: variable response has given sign (:positive/:negative) at horizon.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.zero_restriction-Tuple{Int64, Int64}","page":"Functions","title":"MacroEconometricModels.zero_restriction","text":"Create zero restriction: variable doesn't respond to shock at horizon.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._simulate_irfs-Union{Tuple{T}, Tuple{VARModel{T}, Symbol, Int64, Any, Any, Symbol, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._simulate_irfs","text":"Simulate IRFs for confidence intervals (bootstrap or asymptotic).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._simulate_var-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._simulate_var","text":"Simulate VAR data from initial conditions and innovations.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.cumulative_irf-Union{Tuple{LPImpulseResponse{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.cumulative_irf","text":"cumulative_irf(irf::LPImpulseResponse{T}) -> LPImpulseResponse{T}\n\nCompute cumulative impulse response: Σₛ₌₀ʰ β_s.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.irf-Tuple{MCMCChains.Chains, Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.irf","text":"irf(chain, p, n, horizon; method=:cholesky, quantiles=[0.16, 0.5, 0.84], ...)\n\nCompute Bayesian IRFs from MCMC chain with posterior quantiles.\n\nUses process_posterior_samples and compute_posterior_quantiles from bayesian_utils.jl.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.irf-Union{Tuple{T}, Tuple{VARModel{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.irf","text":"irf(model, horizon; method=:cholesky, ci_type=:none, reps=200, conf_level=0.95, ...)\n\nCompute IRFs with optional confidence intervals.\n\nMethods: :cholesky, :sign, :narrative, :long_run. CI types: :none, :bootstrap, :theoretical.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.lp_irf-Tuple{AbstractMatrix, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.lp_irf","text":"lp_irf(Y::AbstractMatrix, shock_var::Int, horizon::Int; kwargs...) -> LPImpulseResponse\n\nConvenience function: estimate LP and extract IRF in one call.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.lp_irf-Union{Tuple{LPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.lp_irf","text":"lp_irf(model::LPModel{T}; conf_level::Real=0.95) -> LPImpulseResponse{T}\n\nExtract impulse response function with confidence intervals from LP model.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_fevd-Union{Tuple{T}, Tuple{Array{T, 3}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_fevd","text":"Compute FEVD from IRF array: decomposition[i,j,h] = cumulative MSE contribution.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.fevd-Tuple{MCMCChains.Chains, Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.fevd","text":"fevd(chain, p, n, horizon; quantiles=[0.16, 0.5, 0.84], ...) -> BayesianFEVD\n\nCompute Bayesian FEVD from MCMC chain with posterior quantiles.\n\nUses process_posterior_samples and compute_posterior_quantiles from bayesian_utils.jl.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.fevd-Union{Tuple{T}, Tuple{VARModel{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.fevd","text":"fevd(model, horizon; method=:cholesky, ...) -> FEVD\n\nCompute FEVD showing proportion of h-step forecast error variance attributable to each shock.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_hd_contributions-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Array{Matrix{T}, 1}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_hd_contributions","text":"Compute historical decomposition contributions from structural shocks and MA coefficients. HD[t, i, j] = Σ{s=0}^{t-1} Θs[i, j] * ε_j(t-s)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_initial_conditions-Union{Tuple{T}, Tuple{Matrix{T}, Array{T, 3}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_initial_conditions","text":"Compute initial conditions as residual: actual - total shock contributions.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._compute_structural_ma_coefficients-Union{Tuple{T}, Tuple{VARModel{T}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._compute_structural_ma_coefficients","text":"Compute structural MA coefficients Θs = Φs * P for s = 0, ..., horizon-1. Returns Vector{Matrix{T}} of length horizon.\n\nUses _compute_ma_coefficients from identification.jl to avoid code duplication.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.contribution-Union{Tuple{T}, Tuple{BayesianHistoricalDecomposition{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.contribution","text":"contribution(hd::BayesianHistoricalDecomposition, var, shock; stat=:mean) -> Vector\n\nGet contribution time series for specific variable and shock (Bayesian).\n\nArguments\n\nhd: Bayesian historical decomposition result\nvar: Variable index (Int) or name (String)\nshock: Shock index (Int) or name (String)\nstat: :mean or quantile index (Int)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.contribution-Union{Tuple{T}, Tuple{HistoricalDecomposition{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.contribution","text":"contribution(hd::HistoricalDecomposition, var, shock) -> Vector\n\nGet contribution time series for specific variable and shock.\n\nArguments\n\nhd: Historical decomposition result\nvar: Variable index (Int) or name (String)\nshock: Shock index (Int) or name (String)\n\nExample\n\ncontrib_y1_s1 = contribution(hd, 1, 1)  # Contribution of shock 1 to variable 1\ncontrib_y1_s1 = contribution(hd, \"Var 1\", \"Shock 1\")\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.historical_decomposition-Tuple{MCMCChains.Chains, Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.historical_decomposition","text":"historical_decomposition(chain::Chains, p, n, horizon; data, ...) -> BayesianHistoricalDecomposition\n\nCompute Bayesian historical decomposition from MCMC chain with posterior quantiles.\n\nArguments\n\nchain::Chains: MCMC chain from estimate_bvar\np::Int: Number of lags\nn::Int: Number of variables\nhorizon::Int: Maximum horizon for MA coefficients\n\nKeyword Arguments\n\ndata::AbstractMatrix: Original data matrix (required)\nmethod::Symbol=:cholesky: Identification method\nquantiles::Vector{<:Real}=[0.16, 0.5, 0.84]: Posterior quantile levels\ncheck_func=nothing: Sign restriction check function\nnarrative_check=nothing: Narrative restriction check function\n\nReturns\n\nBayesianHistoricalDecomposition with posterior quantiles and means.\n\nExample\n\nchain = estimate_bvar(Y, 2; n_samples=500)\nhd = historical_decomposition(chain, 2, 3, 198; data=Y)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.historical_decomposition-Union{Tuple{T}, Tuple{VARModel{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.historical_decomposition","text":"historical_decomposition(model::VARModel, horizon; method=:cholesky, ...) -> HistoricalDecomposition\n\nCompute historical decomposition for a VAR model.\n\nDecomposes observed data into contributions from each structural shock plus initial conditions.\n\nArguments\n\nmodel::VARModel: Estimated VAR model\nhorizon::Int: Maximum horizon for MA coefficient computation (typically T_eff)\n\nKeyword Arguments\n\nmethod::Symbol=:cholesky: Identification method (:cholesky, :sign, :narrative, :long_run)\ncheck_func=nothing: Sign restriction check function (for method=:sign or :narrative)\nnarrative_check=nothing: Narrative restriction check function (for method=:narrative)\nmax_draws::Int=1000: Maximum draws for sign/narrative identification\n\nReturns\n\nHistoricalDecomposition containing:\n\ncontributions: Shock contributions (Teff × nvars × n_shocks)\ninitial_conditions: Initial condition effects (Teff × nvars)\nactual: Actual data values\nshocks: Structural shocks\n\nExample\n\nmodel = estimate_var(Y, 2)\nhd = historical_decomposition(model, size(Y, 1) - 2)\nverify_decomposition(hd)  # Check decomposition identity\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.historical_decomposition-Union{Tuple{T}, Tuple{VARModel{T}, SVARRestrictions, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.historical_decomposition","text":"historical_decomposition(model::VARModel, restrictions::SVARRestrictions, horizon; ...) -> BayesianHistoricalDecomposition\n\nCompute historical decomposition using Arias et al. (2018) identification with importance weights.\n\nArguments\n\nmodel::VARModel: Estimated VAR model\nrestrictions::SVARRestrictions: Zero and sign restrictions\nhorizon::Int: Maximum horizon for MA coefficients\n\nKeyword Arguments\n\nn_draws::Int=1000: Number of accepted draws\nn_rotations::Int=1000: Maximum rotation attempts per draw\nquantiles::Vector{<:Real}=[0.16, 0.5, 0.84]: Quantile levels for weighted quantiles\n\nReturns\n\nBayesianHistoricalDecomposition with weighted posterior quantiles and means.\n\nExample\n\nr = SVARRestrictions(3; signs=[sign_restriction(1, 1, :positive)])\nhd = historical_decomposition(model, r, 198; n_draws=500)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.total_shock_contribution-Union{Tuple{T}, Tuple{HistoricalDecomposition{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.total_shock_contribution","text":"total_shock_contribution(hd::AbstractHistoricalDecomposition, var) -> Vector\n\nGet total contribution from all shocks to a variable over time.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.verify_decomposition-Union{Tuple{BayesianHistoricalDecomposition{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.verify_decomposition","text":"verify_decomposition(hd::BayesianHistoricalDecomposition; tol=1e-6) -> Bool\n\nVerify that mean contributions + mean initial_conditions ≈ actual (approximately, due to averaging).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.verify_decomposition-Union{Tuple{HistoricalDecomposition{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.verify_decomposition","text":"verify_decomposition(hd::HistoricalDecomposition; tol=1e-10) -> Bool\n\nVerify that contributions + initial_conditions ≈ actual.\n\nExample\n\nhd = historical_decomposition(model, horizon)\n@assert verify_decomposition(hd) \"Decomposition identity failed\"\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._select_horizons-Tuple{Int64}","page":"Functions","title":"MacroEconometricModels._select_horizons","text":"Select representative horizons for display.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.has_uncertainty-Tuple{AbstractAnalysisResult}","page":"Functions","title":"MacroEconometricModels.has_uncertainty","text":"has_uncertainty(result::AbstractAnalysisResult) -> Bool\n\nCheck if the result includes uncertainty quantification (confidence intervals or posterior quantiles).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.point_estimate-Tuple{AbstractAnalysisResult}","page":"Functions","title":"MacroEconometricModels.point_estimate","text":"point_estimate(result::AbstractAnalysisResult)\n\nGet the point estimate from an analysis result.\n\nReturns the main values/estimates (IRF values, FEVD proportions, HD contributions).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.print_table-Union{Tuple{T}, Tuple{IO, FEVD{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.print_table","text":"print_table([io], f::FEVD, var; horizons=nothing)\n\nPrint formatted FEVD table.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.print_table-Union{Tuple{T}, Tuple{IO, HistoricalDecomposition{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.print_table","text":"print_table([io], hd::HistoricalDecomposition, var; periods=nothing)\n\nPrint formatted HD table.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.print_table-Union{Tuple{T}, Tuple{IO, ImpulseResponse{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.print_table","text":"print_table([io], irf::ImpulseResponse, var, shock; horizons=nothing)\n\nPrint formatted IRF table.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.summary-Union{Tuple{FEVD{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.summary","text":"summary(f::FEVD)\nsummary(f::BayesianFEVD)\n\nPrint FEVD summary with decomposition at selected horizons.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.summary-Union{Tuple{HistoricalDecomposition{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.summary","text":"summary(hd::HistoricalDecomposition)\nsummary(hd::BayesianHistoricalDecomposition)\n\nPrint HD summary with contribution statistics.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.summary-Union{Tuple{ImpulseResponse{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.summary","text":"summary(irf::ImpulseResponse)\nsummary(irf::BayesianImpulseResponse)\n\nPrint IRF summary with values at selected horizons.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.summary-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.summary","text":"summary(model::VARModel)\n\nPrint comprehensive VAR model summary including specification, information criteria, residual covariance, and stationarity check.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{BayesianFEVD{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(f::BayesianFEVD, var; horizons=nothing, stat=:mean) -> Matrix\n\nExtract Bayesian FEVD values. stat can be :mean or quantile index.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{BayesianHistoricalDecomposition{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(hd::BayesianHistoricalDecomposition, var; periods=nothing, stat=:mean) -> Matrix\n\nExtract Bayesian HD contributions. stat can be :mean or quantile index.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{BayesianImpulseResponse{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(irf::BayesianImpulseResponse, var, shock; horizons=nothing) -> Matrix\n\nExtract Bayesian IRF values. Returns [Horizon, Mean, Q1, Q2, ...].\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{FEVD{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(f::FEVD, var; horizons=nothing) -> Matrix\n\nExtract FEVD proportions for a variable. Returns [Horizon, Shock1, Shock2, ...].\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{HistoricalDecomposition{T}, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(hd::HistoricalDecomposition, var; periods=nothing) -> Matrix\n\nExtract HD contributions for a variable. Returns [Period, Actual, Shock1, ..., ShockN, Initial].\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.table-Union{Tuple{T}, Tuple{ImpulseResponse{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.table","text":"table(irf::ImpulseResponse, var, shock; horizons=nothing) -> Matrix\n\nExtract IRF values for a variable-shock pair. Returns matrix with columns: [Horizon, IRF] or [Horizon, IRF, CIlo, CIhi].\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.uncertainty_bounds-Tuple{AbstractAnalysisResult}","page":"Functions","title":"MacroEconometricModels.uncertainty_bounds","text":"uncertainty_bounds(result::AbstractAnalysisResult) -> Union{Nothing, Tuple}\n\nGet uncertainty bounds (lower, upper) if available, otherwise nothing.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.build_control_columns!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Vararg{Int64, 4}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.build_control_columns!","text":"build_control_columns!(X_h::AbstractMatrix{T}, Y::AbstractMatrix{T},\n                       t_start::Int, t_end::Int, lags::Int, start_col::Int) where T\n\nFill control (lagged Y) columns into regressor matrix X_h. Returns the next available column index.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.build_response_matrix-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64, Int64, Vector{Int64}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.build_response_matrix","text":"build_response_matrix(Y::AbstractMatrix{T}, h::Int, t_start::Int, t_end::Int,\n                      response_vars::Vector{Int}) where T\n\nBuild response matrix Y_h at horizon h.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compare_var_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compare_var_lp","text":"compare_var_lp(Y::AbstractMatrix{T}, horizon::Int; lags::Int=4) where T\n\nCompare VAR-based and LP-based impulse responses.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_block_robust_vcov-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, AbstractCovarianceEstimator}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_block_robust_vcov","text":"compute_block_robust_vcov(X::AbstractMatrix{T}, U::AbstractMatrix{T},\n                          cov_estimator::AbstractCovarianceEstimator) where T\n\nCompute block-diagonal robust covariance for multi-equation system.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_horizon_bounds-Tuple{Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.compute_horizon_bounds","text":"compute_horizon_bounds(T_obs::Int, h::Int, lags::Int) -> (t_start, t_end)\n\nCompute valid observation bounds for horizon h.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.construct_lp_matrices-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.construct_lp_matrices","text":"construct_lp_matrices(Y::AbstractMatrix{T}, shock_var::Int, h::Int, lags::Int;\n                      response_vars::Vector{Int}=collect(1:size(Y,2))) where T\n\nConstruct regressor and response matrices for LP regression at horizon h.\n\nReturns: (Yh, Xh, valid_idx)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.create_cov_estimator-Union{Tuple{T}, Tuple{Symbol, Type{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.create_cov_estimator","text":"create_cov_estimator(cov_type::Symbol, ::Type{T}; bandwidth::Int=0) where T\n\nCreate covariance estimator from symbol specification. Eliminates repeated if/else patterns across LP variants.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_lp","text":"estimate_lp(Y::AbstractMatrix{T}, shock_var::Int, horizon::Int;\n            lags::Int=4, response_vars::Vector{Int}=collect(1:size(Y,2)),\n            cov_type::Symbol=:newey_west, bandwidth::Int=0,\n            conf_level::Real=0.95) -> LPModel{T}\n\nEstimate Local Projection impulse response functions (Jordà 2005).\n\nThe LP regression for horizon h:     y{t+h} = αh + βh * shockt + Γh * controlst + ε_{t+h}\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_lp_cholesky-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_lp_cholesky","text":"estimate_lp_cholesky(Y::AbstractMatrix{T}, horizon::Int;\n                     lags::Int=4, cov_type::Symbol=:newey_west, kwargs...) -> Vector{LPModel{T}}\n\nEstimate LP with Cholesky-orthogonalized shocks.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_lp_multi-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_lp_multi","text":"estimate_lp_multi(Y::AbstractMatrix{T}, shock_vars::Vector{Int}, horizon::Int;\n                  kwargs...) -> Vector{LPModel{T}}\n\nEstimate LP for multiple shock variables.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.extract_shock_irf-Union{Tuple{T}, Tuple{Array{Matrix{T}, 1}, Array{Matrix{T}, 1}, Vector{Int64}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.extract_shock_irf","text":"extract_shock_irf(B::Vector{Matrix{T}}, vcov::Vector{Matrix{T}},\n                  response_vars::Vector{Int}, shock_coef_idx::Int;\n                  conf_level::Real=0.95) where T\n\nGeneric IRF extraction from coefficient and covariance vectors. Works for LPModel, LPIVModel, PropensityLPModel.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.bspline_basis-Tuple{AbstractVector{Int64}, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.bspline_basis","text":"bspline_basis(horizons::AbstractVector{Int}, degree::Int, n_interior_knots::Int;\n              T::Type{<:AbstractFloat}=Float64) -> BSplineBasis{T}\n\nConstruct B-spline basis matrix for given horizons.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.bspline_basis_value-Union{Tuple{T}, Tuple{T, Int64, Int64, Vector{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.bspline_basis_value","text":"bspline_basis_value(x::T, i::Int, degree::Int, knots::Vector{T}) where T\n\nEvaluate B-spline basis function using Cox-de Boor recursion.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compare_smooth_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compare_smooth_lp","text":"compare_smooth_lp(Y::AbstractMatrix{T}, shock_var::Int, horizon::Int;\n                  lambda::T=T(1.0), kwargs...) -> NamedTuple\n\nCompare standard LP and smooth LP.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.cross_validate_lambda-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.cross_validate_lambda","text":"cross_validate_lambda(Y::AbstractMatrix{T}, shock_var::Int, horizon::Int;\n                      lambda_grid::Vector{T}=T.(10.0 .^ (-4:0.5:2)),\n                      k_folds::Int=5, kwargs...) -> T\n\nSelect optimal λ via k-fold cross-validation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.doubly_robust_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Bool}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.doubly_robust_lp","text":"doubly_robust_lp(Y::AbstractMatrix{T}, treatment::AbstractVector{Bool},\n                 covariates::AbstractMatrix{T}, horizon::Int; ...) -> PropensityLPModel{T}\n\nDoubly robust LP estimator combining IPW and regression adjustment.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_lp_iv-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_lp_iv","text":"estimate_lp_iv(Y::AbstractMatrix{T}, shock_var::Int, instruments::AbstractMatrix{T},\n               horizon::Int; lags::Int=4, response_vars::Vector{Int}=collect(1:size(Y,2)),\n               cov_type::Symbol=:newey_west, bandwidth::Int=0) -> LPIVModel{T}\n\nEstimate LP with Instrumental Variables (Stock & Watson 2018) using 2SLS.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_propensity_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Bool}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_propensity_lp","text":"estimate_propensity_lp(Y::AbstractMatrix{T}, treatment::AbstractVector{Bool},\n                       covariates::AbstractMatrix{T}, horizon::Int; ...) -> PropensityLPModel{T}\n\nEstimate LP with Inverse Propensity Weighting (Angrist et al. 2018).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_propensity_score-Union{Tuple{T}, Tuple{AbstractVector{Bool}, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_propensity_score","text":"estimate_propensity_score(treatment::AbstractVector{Bool}, X::AbstractMatrix{T};\n                          method::Symbol=:logit) -> Vector{T}\n\nEstimate propensity scores P(D=1|X) via logit or probit.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_smooth_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_smooth_lp","text":"estimate_smooth_lp(Y::AbstractMatrix{T}, shock_var::Int, horizon::Int;\n                   degree::Int=3, n_knots::Int=4, lambda::T=T(0.0),\n                   lags::Int=4, response_vars::Vector{Int}=collect(1:size(Y,2)),\n                   cov_type::Symbol=:newey_west, bandwidth::Int=0) -> SmoothLPModel{T}\n\nEstimate Smooth LP with B-spline parameterization (Barnichon & Brownlees 2019).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_state_lp-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, AbstractVector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_state_lp","text":"estimate_state_lp(Y::AbstractMatrix{T}, shock_var::Int, state_var::AbstractVector{T},\n                  horizon::Int; gamma::Union{T,Symbol}=:estimate, ...) -> StateLPModel{T}\n\nEstimate state-dependent LP (Auerbach & Gorodnichenko 2013).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_transition_params-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_transition_params","text":"estimate_transition_params(state_var::AbstractVector{T}, Y::AbstractMatrix{T},\n                           shock_var::Int; method::Symbol=:nlls, ...) -> NamedTuple\n\nEstimate smooth transition parameters (γ, c).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.exponential_transition-Union{Tuple{T}, Tuple{AbstractVector{T}, T, T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.exponential_transition","text":"exponential_transition(z::AbstractVector{T}, gamma::T, c::T) -> Vector{T}\n\nExponential (symmetric) transition: F(z) = 1 - exp(-γ(z - c)²)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.first_stage_regression-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.first_stage_regression","text":"first_stage_regression(endog::AbstractVector{T}, instruments::AbstractMatrix{T},\n                       controls::AbstractMatrix{T}) -> NamedTuple\n\nFirst-stage regression for 2SLS with F-statistic for instrument relevance.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.indicator_transition-Union{Tuple{T}, Tuple{AbstractVector{T}, T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.indicator_transition","text":"indicator_transition(z::AbstractVector{T}, c::T) -> Vector{T}\n\nSharp indicator transition: F(z) = 1 if z ≥ c, else 0\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.inverse_propensity_weights-Union{Tuple{T}, Tuple{AbstractVector{Bool}, AbstractVector{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.inverse_propensity_weights","text":"inverse_propensity_weights(treatment::AbstractVector{Bool}, propensity::AbstractVector{T};\n                           trimming::Tuple{T,T}=(T(0.01), T(0.99)), normalize::Bool=true) -> Vector{T}\n\nCompute IPW weights with optional trimming.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.logistic_transition-Union{Tuple{T}, Tuple{AbstractVector{T}, T, T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.logistic_transition","text":"logistic_transition(z::AbstractVector{T}, gamma::T, c::T) -> Vector{T}\n\nLogistic transition function: F(z) = exp(-γ(z - c)) / (1 + exp(-γ(z - c)))\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.lp_iv_irf-Union{Tuple{LPIVModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.lp_iv_irf","text":"lp_iv_irf(model::LPIVModel{T}; conf_level::Real=0.95) -> LPImpulseResponse{T}\n\nExtract IRF from LP-IV model.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.propensity_diagnostics-Union{Tuple{PropensityLPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.propensity_diagnostics","text":"propensity_diagnostics(model::PropensityLPModel{T}) -> NamedTuple\n\nPropensity score diagnostics (overlap, balance).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.propensity_irf-Union{Tuple{PropensityLPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.propensity_irf","text":"propensity_irf(model::PropensityLPModel{T}; conf_level::Real=0.95) -> LPImpulseResponse{T}\n\nExtract treatment effect (ATE) IRF from PropensityLPModel.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.roughness_penalty_matrix-Union{Tuple{BSplineBasis{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.roughness_penalty_matrix","text":"roughness_penalty_matrix(basis::BSplineBasis{T}) -> Matrix{T}\n\nCompute roughness penalty matrix R for B-splines (second derivative penalty).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.sargan_test-Union{Tuple{T}, Tuple{LPIVModel{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.sargan_test","text":"sargan_test(model::LPIVModel{T}, h::Int) -> NamedTuple\n\nSargan-Hansen J-test for overidentification at horizon h.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.smooth_lp_irf-Union{Tuple{SmoothLPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.smooth_lp_irf","text":"smooth_lp_irf(model::SmoothLPModel{T}; conf_level::Real=0.95) -> LPImpulseResponse{T}\n\nExtract smoothed IRF from SmoothLPModel.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.state_irf-Union{Tuple{StateLPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.state_irf","text":"state_irf(model::StateLPModel{T}; regime::Symbol=:both, conf_level::Real=0.95) -> NamedTuple\n\nExtract state-dependent IRFs.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.test_regime_difference-Union{Tuple{StateLPModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.test_regime_difference","text":"test_regime_difference(model::StateLPModel{T}; h::Union{Int,Nothing}=nothing) -> NamedTuple\n\nTest whether IRFs differ across regimes.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.tsls_regression-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{T}, AbstractVector{T}, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.tsls_regression","text":"tsls_regression(Y::AbstractMatrix{T}, endog::AbstractVector{T},\n                endog_fitted::AbstractVector{T}, controls::AbstractMatrix{T};\n                cov_estimator::AbstractCovarianceEstimator=NeweyWestEstimator()) -> NamedTuple\n\nSecond-stage regression using fitted values from first stage.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.weak_instrument_test-Union{Tuple{LPIVModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.weak_instrument_test","text":"weak_instrument_test(model::LPIVModel{T}; threshold::T=T(10.0)) -> NamedTuple\n\nTest for weak instruments using Stock-Yogo rule of thumb (F > 10).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_gmm-Union{Tuple{T}, Tuple{Function, AbstractVector{T}, Any}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_gmm","text":"estimate_gmm(moment_fn::Function, theta0::AbstractVector{T}, data;\n             weighting::Symbol=:two_step, max_iter::Int=100,\n             tol::T=T(1e-8), hac::Bool=true, bandwidth::Int=0) -> GMMModel{T}\n\nEstimate parameters via Generalized Method of Moments.\n\nMinimizes: Q(θ) = g(θ)'W g(θ) where g(θ) = (1/n) Σᵢ gᵢ(θ)\n\nArguments:\n\nmoment_fn: Function (theta, data) -> Matrix of moment conditions (n × q)\ntheta0: Initial parameter guess\ndata: Data passed to moment function\nweighting: Weighting method (:identity, :optimal, :two_step, :iterated)\nmax_iter: Maximum iterations for optimization and/or iterated GMM\ntol: Convergence tolerance\nhac: Use HAC correction for optimal weighting\nbandwidth: HAC bandwidth (0 = automatic)\n\nReturns:\n\nGMMModel with estimates, covariance, and J-test results\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.estimate_lp_gmm-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.estimate_lp_gmm","text":"estimate_lp_gmm(Y::AbstractMatrix{T}, shock_var::Int, horizon::Int;\n                lags::Int=4, weighting::Symbol=:two_step) -> Vector{GMMModel{T}}\n\nEstimate Local Projection via GMM.\n\nReturns a GMMModel for each horizon.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.gmm_objective-Union{Tuple{T}, Tuple{AbstractVector{T}, Function, Any, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.gmm_objective","text":"gmm_objective(theta::AbstractVector{T}, moment_fn::Function, data,\n              W::AbstractMatrix{T}) -> T\n\nCompute GMM objective: Q(θ) = g(θ)'W g(θ)\n\nwhere g(θ) = (1/n) Σᵢ gᵢ(θ,data)\n\nArguments:\n\ntheta: Parameter vector\nmoment_fn: Function (theta, data) -> Matrix of moment conditions (n × q)\ndata: Data passed to moment function\nW: Weighting matrix (q × q)\n\nReturns:\n\nGMM objective value\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.gmm_summary-Union{Tuple{GMMModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.gmm_summary","text":"gmm_summary(model::GMMModel{T}) -> NamedTuple\n\nSummary statistics for GMM estimation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.identity_weighting-Union{Tuple{Int64}, Tuple{T}, Tuple{Int64, Type{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.identity_weighting","text":"identity_weighting(n_moments::Int, ::Type{T}=Float64) -> Matrix{T}\n\nIdentity weighting matrix (one-step GMM).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.j_test-Union{Tuple{GMMModel{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.j_test","text":"j_test(model::GMMModel{T}) -> NamedTuple\n\nHansen's J-test for overidentifying restrictions.\n\nH0: All moment conditions are valid (E[g(θ₀)] = 0) H1: Some moment conditions are violated\n\nReturns:\n\nJ_stat: Test statistic\np_value: p-value from chi-squared distribution\ndf: Degrees of freedom (nmoments - nparams)\nreject_05: Whether to reject at 5% level\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.lp_gmm_moments-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64, Any, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.lp_gmm_moments","text":"lp_gmm_moments(Y::AbstractMatrix{T}, shock_var::Int, h::Int, theta,\n               lags::Int) -> Matrix{T}\n\nConstruct moment conditions for LP estimated via GMM.\n\nMoments: E[Zt * ε{t+h}] = 0 where ε{t+h} = y{t+h} - θ' * X_t and Z includes all exogenous variables.\n\nThis is useful when you need to impose cross-equation restrictions.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.minimize_gmm-Union{Tuple{T}, Tuple{Function, AbstractVector{T}, Any, AbstractMatrix{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.minimize_gmm","text":"minimize_gmm(moment_fn::Function, theta0::AbstractVector{T}, data,\n             W::AbstractMatrix{T}; max_iter::Int=100, tol::T=T(1e-8)) -> NamedTuple\n\nMinimize GMM objective using gradient descent with BFGS-like updates.\n\nReturns:\n\ntheta: Minimizer\nobjective: Final objective value\nconverged: Convergence flag\niterations: Number of iterations\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.numerical_gradient-Union{Tuple{T}, Tuple{Function, AbstractVector{T}}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.numerical_gradient","text":"numerical_gradient(f::Function, x::AbstractVector{T}; eps::T=T(1e-7)) -> Matrix{T}\n\nCompute numerical gradient (Jacobian) of function f at point x using central differences.\n\nArguments:\n\nf: Function that takes vector x and returns vector (moment conditions)\nx: Point at which to evaluate gradient\neps: Step size for finite differences\n\nReturns:\n\nJacobian matrix (nmoments × nparams)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.optimal_weighting_matrix-Union{Tuple{T}, Tuple{Function, AbstractVector{T}, Any}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.optimal_weighting_matrix","text":"optimal_weighting_matrix(moment_fn::Function, theta::AbstractVector{T}, data;\n                         hac::Bool=true, bandwidth::Int=0) -> Matrix{T}\n\nCompute optimal GMM weighting matrix: W = inv(Var(g)).\n\nFor i.i.d. data: W = inv((1/n) Σᵢ gᵢ gᵢ') For time series: Uses HAC estimation with Newey-West kernel.\n\nArguments:\n\nmoment_fn: Moment function\ntheta: Current parameter estimate\ndata: Data\nhac: Use HAC correction for serial correlation\nbandwidth: HAC bandwidth (0 = automatic)\n\nReturns:\n\nOptimal weighting matrix (q × q)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._build_adf_matrix-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, Int64, Symbol}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._build_adf_matrix","text":"Build ADF regression matrix.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._long_run_variance-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._long_run_variance","text":"Compute long-run variance using Bartlett kernel.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._ngperron_pvalue-Union{Tuple{T}, Tuple{T, Symbol, Symbol}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._ngperron_pvalue","text":"Approximate p-value for Ng-Perron tests.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._nw_bandwidth-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels._nw_bandwidth","text":"Compute Newey-West bandwidth using Andrews (1991) AR(1) rule.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.adf_critical_values","page":"Functions","title":"MacroEconometricModels.adf_critical_values","text":"Compute ADF critical values using MacKinnon response surface.\n\n\n\n\n\n","category":"function"},{"location":"api_functions/#MacroEconometricModels.adf_pvalue-Union{Tuple{T}, Tuple{T, Symbol, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.adf_pvalue","text":"Approximate p-value for ADF test using MacKinnon (1994) interpolation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.adf_select_lags-Union{Tuple{T}, Tuple{AbstractVector{T}, Int64, Symbol, Symbol}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.adf_select_lags","text":"Compute optimal lag length for ADF test using information criterion.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.adf_test-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.adf_test","text":"adf_test(y; lags=:aic, max_lags=nothing, regression=:constant) -> ADFResult\n\nAugmented Dickey-Fuller test for unit root.\n\nTests H₀: y has a unit root (non-stationary) against H₁: y is stationary.\n\nArguments\n\ny: Time series vector\nlags: Number of augmenting lags, or :aic/:bic/:hqic for automatic selection\nmax_lags: Maximum lags for automatic selection (default: floor(12*(T/100)^0.25))\nregression: Deterministic terms - :none, :constant (default), or :trend\n\nReturns\n\nADFResult containing test statistic, p-value, critical values, etc.\n\nExample\n\ny = cumsum(randn(200))  # Random walk (has unit root)\nresult = adf_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀\n\nReferences\n\nDickey, D. A., & Fuller, W. A. (1979). Distribution of the estimators for autoregressive time series with a unit root. JASA, 74(366), 427-431.\nMacKinnon, J. G. (2010). Critical values for cointegration tests. Queen's Economics Department Working Paper No. 1227.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.is_stationary-Union{Tuple{VARModel{T}}, Tuple{T}} where T","page":"Functions","title":"MacroEconometricModels.is_stationary","text":"is_stationary(model::VARModel) -> VARStationarityResult\n\nCheck if estimated VAR model is stationary.\n\nA VAR(p) is stationary if and only if all eigenvalues of the companion matrix have modulus strictly less than 1.\n\nReturns\n\nVARStationarityResult with:\n\nis_stationary: Boolean indicating stationarity\neigenvalues: Complex eigenvalues of companion matrix\nmax_modulus: Maximum eigenvalue modulus\ncompanion_matrix: The (np × np) companion form matrix\n\nExample\n\nmodel = estimate_var(Y, 2)\nresult = is_stationary(model)\nif !result.is_stationary\n    println(\"Warning: VAR is non-stationary, max modulus = \", result.max_modulus)\nend\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.johansen_test-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.johansen_test","text":"johansen_test(Y, p; deterministic=:constant) -> JohansenResult\n\nJohansen cointegration test for VAR system.\n\nTests for the number of cointegrating relationships among variables using trace and maximum eigenvalue tests.\n\nArguments\n\nY: Data matrix (T × n)\np: Number of lags in the VECM representation\ndeterministic: Specification for deterministic terms\n:none - No deterministic terms\n:constant - Constant in cointegrating relation (default)\n:trend - Linear trend in levels\n\nReturns\n\nJohansenResult containing trace and max-eigenvalue statistics, cointegrating vectors, adjustment coefficients, and estimated rank.\n\nExample\n\n# Generate cointegrated system\nn, T = 3, 200\nY = randn(T, n)\nY[:, 2] = Y[:, 1] + 0.1 * randn(T)  # Y2 cointegrated with Y1\n\nresult = johansen_test(Y, 2)\nresult.rank  # Should detect 1 or 2 cointegrating relations\n\nReferences\n\nJohansen, S. (1991). Estimation and hypothesis testing of cointegration vectors in Gaussian vector autoregressive models. Econometrica, 59(6), 1551-1580.\nOsterwald-Lenum, M. (1992). A note with quantiles of the asymptotic distribution of the ML cointegration rank test statistics. Oxford BEJM.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.kpss_pvalue-Union{Tuple{T}, Tuple{T, Symbol}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.kpss_pvalue","text":"Approximate p-value for KPSS test.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.kpss_test-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.kpss_test","text":"kpss_test(y; regression=:constant, bandwidth=:auto) -> KPSSResult\n\nKwiatkowski-Phillips-Schmidt-Shin test for stationarity.\n\nTests H₀: y is stationary against H₁: y has a unit root.\n\nArguments\n\ny: Time series vector\nregression: :constant (level stationarity) or :trend (trend stationarity)\nbandwidth: Bartlett kernel bandwidth, or :auto for Newey-West selection\n\nReturns\n\nKPSSResult containing test statistic, p-value, critical values, etc.\n\nExample\n\ny = randn(200)  # Stationary series\nresult = kpss_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀ (stationarity)\n\nReferences\n\nKwiatkowski, D., Phillips, P. C., Schmidt, P., & Shin, Y. (1992). Testing the null hypothesis of stationarity against the alternative of a unit root. Journal of Econometrics, 54(1-3), 159-178.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.ngperron_test-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.ngperron_test","text":"ngperron_test(y; regression=:constant) -> NgPerronResult\n\nNg-Perron unit root tests with GLS detrending (MZα, MZt, MSB, MPT).\n\nTests H₀: y has a unit root against H₁: y is stationary. These tests have better size properties than ADF/PP in small samples.\n\nArguments\n\ny: Time series vector\nregression: :constant (default) or :trend\n\nReturns\n\nNgPerronResult containing MZα, MZt, MSB, MPT statistics and critical values.\n\nExample\n\ny = cumsum(randn(100))\nresult = ngperron_test(y)\n# Check if MZt rejects at 5%\nresult.MZt < result.critical_values[:MZt][5]\n\nReferences\n\nNg, S., & Perron, P. (2001). Lag length selection and the construction of unit root tests with good size and power. Econometrica, 69(6), 1519-1554.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.pp_test-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.pp_test","text":"pp_test(y; regression=:constant, bandwidth=:auto) -> PPResult\n\nPhillips-Perron test for unit root with non-parametric correction.\n\nTests H₀: y has a unit root against H₁: y is stationary.\n\nArguments\n\ny: Time series vector\nregression: :none, :constant (default), or :trend\nbandwidth: Newey-West bandwidth, or :auto for automatic selection\n\nReturns\n\nPPResult containing test statistic (Zt), p-value, critical values, etc.\n\nExample\n\ny = cumsum(randn(200))  # Random walk\nresult = pp_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀\n\nReferences\n\nPhillips, P. C., & Perron, P. (1988). Testing for a unit root in time series regression. Biometrika, 75(2), 335-346.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.test_all_variables-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.test_all_variables","text":"test_all_variables(Y; test=:adf, kwargs...) -> Vector\n\nApply unit root test to each column of Y.\n\nArguments\n\nY: Data matrix (T × n)\ntest: Test to apply (:adf, :kpss, :pp, :za, :ngperron)\nkwargs...: Additional arguments passed to the test\n\nReturns\n\nVector of test results, one per variable.\n\nExample\n\nY = randn(200, 3)\nY[:, 1] = cumsum(Y[:, 1])  # Make first column non-stationary\nresults = test_all_variables(Y; test=:adf)\n[r.pvalue for r in results]  # P-values for each variable\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.unit_root_summary-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.unit_root_summary","text":"unit_root_summary(y; tests=[:adf, :kpss, :pp], kwargs...) -> NamedTuple\n\nRun multiple unit root tests and return summary with PrettyTables output.\n\nArguments\n\ny: Time series vector\ntests: Vector of test symbols to run (default: [:adf, :kpss, :pp])\nkwargs...: Additional arguments passed to individual tests\n\nReturns\n\nNamedTuple with test results, conclusion, and summary table.\n\nExample\n\ny = cumsum(randn(200))\nsummary = unit_root_summary(y)\nsummary.conclusion  # Overall conclusion\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.za_pvalue-Union{Tuple{T}, Tuple{T, Symbol}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.za_pvalue","text":"Approximate p-value for Zivot-Andrews test.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.za_test-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.za_test","text":"za_test(y; regression=:both, trim=0.15, lags=:aic, max_lags=nothing) -> ZAResult\n\nZivot-Andrews test for unit root with endogenous structural break.\n\nTests H₀: y has a unit root without break against H₁: y is stationary with break.\n\nArguments\n\ny: Time series vector\nregression: Type of break - :constant (intercept), :trend (slope), or :both\ntrim: Trimming fraction for break search (default 0.15)\nlags: Number of augmenting lags, or :aic/:bic for automatic selection\nmax_lags: Maximum lags for selection\n\nReturns\n\nZAResult containing minimum t-statistic, break point, p-value, etc.\n\nExample\n\n# Series with structural break\ny = vcat(randn(100), randn(100) .+ 2)\nresult = za_test(y; regression=:constant)\n\nReferences\n\nZivot, E., & Andrews, D. W. K. (1992). Further evidence on the great crash, the oil-price shock, and the unit-root hypothesis. JBES, 10(3), 251-270.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels._default_names-Tuple{Int64, String}","page":"Functions","title":"MacroEconometricModels._default_names","text":"Generate default names: [\"prefix 1\", \"prefix 2\", ...]\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.companion_matrix-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.companion_matrix","text":"Construct companion matrix F for VAR(p) → VAR(1) representation.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_posterior_quantiles!-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{T}, AbstractArray{T}, AbstractVector}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_posterior_quantiles!","text":"compute_posterior_quantiles!(quantile_out::AbstractArray{T}, mean_out::AbstractArray{T},\n                              samples::AbstractArray{T}, q_vec::AbstractVector{T}) where {T}\n\nCompute quantiles and means from posterior samples (in-place).\n\nOperates over the first dimension (samples) and computes quantiles/means for all other dimensions.\n\nArguments\n\nquantile_out: Output array for quantiles, size = (otherdims..., nquantiles)\nmean_out: Output array for means, size = (other_dims...)\nsamples: Input samples array, size = (nsamples, otherdims...)\nq_vec: Vector of quantile levels (e.g., [0.16, 0.5, 0.84])\n\nExample\n\nsamples = randn(1000, 20, 3, 3)  # 1000 samples of 20×3×3 IRF\nq_out = zeros(20, 3, 3, 3)      # 3 quantiles\nm_out = zeros(20, 3, 3)\ncompute_posterior_quantiles!(q_out, m_out, samples, [0.16, 0.5, 0.84])\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_posterior_quantiles-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractVector}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_posterior_quantiles","text":"compute_posterior_quantiles(samples::AbstractArray{T}, q_vec::AbstractVector;\n                             threaded::Bool=false) where {T}\n\nCompute quantiles and means from posterior samples (allocating version).\n\nArguments\n\nsamples: Input samples array, size = (nsamples, otherdims...)\nq_vec: Vector of quantile levels\nthreaded: Use threaded version for large arrays\n\nReturns\n\nquantiles: Array of shape (otherdims..., nquantiles)\nmeans: Array of shape (other_dims...)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_posterior_quantiles_threaded!-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{T}, AbstractArray{T}, AbstractVector}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_posterior_quantiles_threaded!","text":"compute_posterior_quantiles_threaded!(quantile_out::AbstractArray{T}, mean_out::AbstractArray{T},\n                                       samples::AbstractArray{T}, q_vec::AbstractVector{T}) where {T}\n\nThreaded version of quantile computation for large arrays.\n\nUses Threads.@threads to parallelize over the index space. Recommended when prod(size(samples)[2:end]) > 1000.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_weighted_quantiles!-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{T}, AbstractArray{T}, AbstractVector{T}, AbstractVector}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_weighted_quantiles!","text":"compute_weighted_quantiles!(quantile_out::AbstractArray{T}, mean_out::AbstractArray{T},\n                             samples::AbstractArray{T}, weights::AbstractVector{T},\n                             q_vec::AbstractVector) where {T}\n\nCompute weighted quantiles and weighted means from posterior samples (in-place).\n\nUsed for importance-weighted posterior inference (e.g., Arias et al. 2018 SVAR).\n\nArguments\n\nquantile_out: Output array for quantiles\nmean_out: Output array for weighted means\nsamples: Input samples array, size = (nsamples, otherdims...)\nweights: Importance weights, normalized to sum to 1\nq_vec: Vector of quantile levels\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.compute_weighted_quantiles_threaded!-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{T}, AbstractArray{T}, AbstractVector{T}, AbstractVector}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.compute_weighted_quantiles_threaded!","text":"compute_weighted_quantiles_threaded!(quantile_out::AbstractArray{T}, mean_out::AbstractArray{T},\n                                      samples::AbstractArray{T}, weights::AbstractVector{T},\n                                      q_vec::AbstractVector) where {T}\n\nThreaded version of weighted quantile computation for large arrays.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.construct_var_matrices-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.construct_var_matrices","text":"Construct VAR design matrices: Yeff = X * B + U. Returns (Yeff, X) where X = [1, Y{t-1}, ..., Y{t-p}].\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.extract_ar_coefficients-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Int64, Int64}} where T","page":"Functions","title":"MacroEconometricModels.extract_ar_coefficients","text":"Extract AR coefficient matrices [A₁, ..., Aₚ] from stacked B matrix.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.logdet_safe-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.logdet_safe","text":"Log determinant with eigenvalue fallback for numerical issues.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.process_posterior_samples-Tuple{MCMCChains.Chains, Int64, Int64, Function}","page":"Functions","title":"MacroEconometricModels.process_posterior_samples","text":"process_posterior_samples(chain::Chains, p::Int, n::Int, compute_func::Function;\n                          data::AbstractMatrix=Matrix{Float64}(undef, 0, 0),\n                          method::Symbol=:cholesky, horizon::Int=20,\n                          check_func=nothing, narrative_check=nothing,\n                          max_draws::Int=100) -> (Vector{Any}, Int)\n\nGeneric framework for processing posterior samples from MCMC chain.\n\nProcess\n\nExtract chain parameters using extract_chain_parameters\nLoop over samples, reconstructing VARModel for each\nCompute identification matrix Q using specified method\nApply compute_func(model, Q, horizon) to get result for each sample\n\nArguments\n\nchain::Chains: MCMC chain from estimate_bvar\np::Int: Number of VAR lags\nn::Int: Number of variables\ncompute_func::Function: Function taking (model, Q, horizon) -> result\n\nKeyword Arguments\n\ndata::AbstractMatrix: Original data (required for narrative method and residual computation)\nmethod::Symbol: Identification method (:cholesky, :sign, :narrative, :long_run)\nhorizon::Int: IRF/computation horizon\ncheck_func: Sign restriction check function (for method=:sign or :narrative)\nnarrative_check: Narrative restriction check function (for method=:narrative)\nmax_draws::Int: Maximum draws for sign/narrative identification\n\nReturns\n\nresults::Vector{Any}: Vector of results from compute_func for each sample\nn_samples::Int: Number of samples processed\n\nExample\n\n# Compute IRF for each posterior sample\nresults, n_samples = process_posterior_samples(chain, p, n,\n    (m, Q, h) -> compute_irf(m, Q, h);\n    horizon=20, method=:cholesky\n)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.robust_inv-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.robust_inv","text":"Compute inverse with fallback to pseudo-inverse for singular matrices.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.safe_cholesky-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.safe_cholesky","text":"Cholesky decomposition with automatic jitter for numerical stability.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.stack_posterior_results-Union{Tuple{T}, Tuple{Vector, Tuple}, Tuple{Vector, Tuple, Type{T}}} where T","page":"Functions","title":"MacroEconometricModels.stack_posterior_results","text":"stack_posterior_results(results::Vector, result_size::Tuple, ::Type{T}=Float64) where {T}\n\nStack vector of results into single array for quantile computation.\n\nArguments\n\nresults: Vector of arrays from posterior samples\nresult_size: Expected size of each result array\nT: Element type\n\nReturns\n\nArray of size (nsamples, resultsize...)\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.univariate_ar_variance-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"Functions","title":"MacroEconometricModels.univariate_ar_variance","text":"AR(1) residual standard deviation for Minnesota prior scaling.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_dynamic_factor_inputs-NTuple{4, Int64}","page":"Functions","title":"MacroEconometricModels.validate_dynamic_factor_inputs","text":"Validate dynamic factor model inputs.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_factor_inputs-Tuple{Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.validate_factor_inputs","text":"Validate factor model inputs: 1 ≤ r ≤ min(T, N).\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_in_range-Tuple{Real, String, Real, Real}","page":"Functions","title":"MacroEconometricModels.validate_in_range","text":"Validate lo ≤ value ≤ hi.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_option-Tuple{Symbol, String, Tuple}","page":"Functions","title":"MacroEconometricModels.validate_option","text":"Validate symbol is in valid_options.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_positive-Tuple{Real, String}","page":"Functions","title":"MacroEconometricModels.validate_positive","text":"Validate value > 0.\n\n\n\n\n\n","category":"method"},{"location":"api_functions/#MacroEconometricModels.validate_var_inputs-Tuple{Int64, Int64, Int64}","page":"Functions","title":"MacroEconometricModels.validate_var_inputs","text":"Validate VAR inputs: p ≥ 1, T > p + minobsfactor, n ≥ 1.\n\n\n\n\n\n","category":"method"},{"location":"manual/#Manual","page":"VAR","title":"Manual","text":"This manual provides a comprehensive theoretical background for the macroeconometric methods implemented in MacroEconometricModels.jl, including precise mathematical formulations and references to the literature.","category":"section"},{"location":"manual/#Vector-Autoregression-(VAR)","page":"VAR","title":"Vector Autoregression (VAR)","text":"","category":"section"},{"location":"manual/#The-Reduced-Form-VAR-Model","page":"VAR","title":"The Reduced-Form VAR Model","text":"A VAR(p) model for an n-dimensional vector of endogenous variables y_t is defined as:\n\ny_t = c + A_1 y_t-1 + A_2 y_t-2 + cdots + A_p y_t-p + u_t\n\nwhere:\n\ny_t is an n times 1 vector of endogenous variables at time t\nc is an n times 1 vector of intercepts\nA_i are n times n coefficient matrices for lag i = 1 ldots p\nu_t is an n times 1 vector of reduced-form innovations with Eu_t = 0 and Eu_t u_t = Sigma\n\nReference: Sims (1980), Lütkepohl (2005, Chapter 2)","category":"section"},{"location":"manual/#Compact-Matrix-Representation","page":"VAR","title":"Compact Matrix Representation","text":"For estimation, we stack observations into matrices. Let T denote the effective sample size after accounting for lags. Define:\n\nY = beginbmatrix y_p+1  y_p+2  vdots  y_T endbmatrix_(T-p) times n quad\nX = beginbmatrix 1  y_p  y_p-1  cdots  y_1 \n1  y_p+1  y_p  cdots  y_2 \nvdots  vdots  vdots  ddots  vdots \n1  y_T-1  y_T-2  cdots  y_T-p endbmatrix_(T-p) times (1+np)\n\nThe VAR can be written in matrix form as:\n\nY = X B + U\n\nwhere B = c A_1 A_2 ldots A_p is a (1+np) times n coefficient matrix.","category":"section"},{"location":"manual/#OLS-Estimation","page":"VAR","title":"OLS Estimation","text":"The OLS estimator is given by:\n\nhatB = (XX)^-1 XY\n\nThe residual covariance matrix is estimated as:\n\nhatSigma = frac1T-p-k hatUhatU\n\nwhere hatU = Y - XhatB and k = 1 + np is the number of regressors per equation.\n\nReference: Hamilton (1994, Chapter 11), Lütkepohl (2005, Section 3.2)","category":"section"},{"location":"manual/#Stability-Condition","page":"VAR","title":"Stability Condition","text":"A VAR(p) is stable (stationary) if all eigenvalues of the companion matrix F lie inside the unit circle:\n\nF = beginbmatrix\nA_1  A_2  cdots  A_p-1  A_p \nI_n  0  cdots  0  0 \n0  I_n  cdots  0  0 \nvdots  vdots  ddots  vdots  vdots \n0  0  cdots  I_n  0\nendbmatrix_np times np\n\nStability Check: lambda_i  1 for all eigenvalues lambda_i of F.","category":"section"},{"location":"manual/#Information-Criteria-for-Lag-Selection","page":"VAR","title":"Information Criteria for Lag Selection","text":"The optimal lag length can be selected using information criteria:\n\nAkaike Information Criterion (AIC):\n\ntextAIC(p) = loghatSigma + frac2T(n^2 p + n)\n\nBayesian Information Criterion (BIC):\n\ntextBIC(p) = loghatSigma + fraclog TT(n^2 p + n)\n\nHannan-Quinn Criterion (HQ):\n\ntextHQ(p) = loghatSigma + frac2 log(log T)T(n^2 p + n)\n\nSelect the lag order p that minimizes the criterion.\n\nReference: Lütkepohl (2005, Section 4.3)\n\n","category":"section"},{"location":"manual/#Structural-VAR-(SVAR)-and-Identification","page":"VAR","title":"Structural VAR (SVAR) and Identification","text":"","category":"section"},{"location":"manual/#From-Reduced-Form-to-Structural-Shocks","page":"VAR","title":"From Reduced-Form to Structural Shocks","text":"The reduced-form residuals u_t are linear combinations of structural shocks varepsilon_t:\n\nu_t = B_0 varepsilon_t\n\nwhere:\n\nB_0 is the n times n contemporaneous impact matrix\nvarepsilon_t are structural shocks with Evarepsilon_t varepsilon_t = I_n\n\nThe relationship between the reduced-form and structural covariance is:\n\nSigma = B_0 B_0\n\nThe identification problem is that infinitely many B_0 matrices satisfy this condition. To identify structural shocks, we need n(n-1)2 additional restrictions.\n\nReference: Kilian & Lütkepohl (2017, Chapter 8)","category":"section"},{"location":"manual/#Cholesky-Identification-(Recursive)","page":"VAR","title":"Cholesky Identification (Recursive)","text":"The Cholesky decomposition imposes a lower triangular structure on B_0:\n\nB_0 = textchol(Sigma)\n\nThis implies a recursive causal ordering where variable i responds contemporaneously only to variables 1 2 ldots i-1.\n\nEconomic Interpretation: The ordering reflects assumptions about the speed of adjustment. Variables ordered first respond only to their own shocks contemporaneously.\n\nReference: Sims (1980), Christiano, Eichenbaum & Evans (1999)","category":"section"},{"location":"manual/#Sign-Restrictions","page":"VAR","title":"Sign Restrictions","text":"Sign restrictions identify structural shocks by constraining the signs of impulse responses at selected horizons. Let Theta_h denote the impulse response at horizon h. The identification algorithm:\n\nCompute the Cholesky decomposition: P = textchol(Sigma)\nDraw a random orthogonal matrix Q from the Haar measure (using QR decomposition of a random matrix)\nCompute candidate impact matrix: B_0 = PQ\nCheck if impulse responses Theta_0 = B_0 Theta_1 ldots satisfy the sign restrictions\nIf restrictions are satisfied, keep the draw; otherwise, discard and repeat\n\nImplementation: We use the algorithm of Rubio-Ramírez, Waggoner & Zha (2010).\n\nReference: Faust (1998), Uhlig (2005), Rubio-Ramírez, Waggoner & Zha (2010)","category":"section"},{"location":"manual/#Narrative-Restrictions","page":"VAR","title":"Narrative Restrictions","text":"Narrative restrictions combine sign restrictions with historical information about specific shocks at particular dates. Following Antolín-Díaz & Rubio-Ramírez (2018):\n\nShock Sign Narrative: At date t^*, structural shock j was positive/negative\nShock Contribution Narrative: At date t^*, shock j was the main driver of variable i\n\nThe algorithm:\n\nDraw orthogonal matrix Q satisfying sign restrictions\nRecover structural shocks: varepsilon = B_0^-1 u\nCheck if narrative constraints are satisfied\nWeight the draw using importance sampling\n\nReference: Antolín-Díaz & Rubio-Ramírez (2018)","category":"section"},{"location":"manual/#Long-Run-(Blanchard-Quah)-Identification","page":"VAR","title":"Long-Run (Blanchard-Quah) Identification","text":"Long-run restrictions constrain the cumulative effect of structural shocks. For a stationary VAR, the long-run impact matrix is:\n\nC(1) = (I_n - A_1 - A_2 - cdots - A_p)^-1 B_0\n\nBlanchard & Quah (1989) impose that certain shocks have zero long-run effect on specific variables by requiring C(1) to be lower triangular:\n\nC(1) = textcholleft( (I - A(1))^-1 Sigma (I - A(1))^-1 right)\n\nThen B_0 = (I - A(1)) C(1).\n\nEconomic Application: Demand shocks have no long-run effect on output (supply-driven long-run fluctuations).\n\nReference: Blanchard & Quah (1989), King, Plosser, Stock & Watson (1991)\n\n","category":"section"},{"location":"manual/#Innovation-Accounting","page":"VAR","title":"Innovation Accounting","text":"For detailed coverage of innovation accounting tools, see the dedicated Innovation Accounting chapter. This includes:\n\nImpulse Response Functions (IRF): Dynamic effects of structural shocks\nForecast Error Variance Decomposition (FEVD): Variance contribution of each shock\nHistorical Decomposition (HD): Decompose observed movements into shock contributions\nSummary Tables: Publication-quality output with summary(), table(), print_table()\n\n","category":"section"},{"location":"manual/#Bayesian-VAR-(BVAR)","page":"VAR","title":"Bayesian VAR (BVAR)","text":"For comprehensive coverage of Bayesian VAR estimation, see the dedicated Bayesian VAR chapter. Key topics include:\n\nMinnesota/Litterman prior specification\nHyperparameter optimization via marginal likelihood (Giannone, Lenza & Primiceri, 2015)\nMCMC estimation with Turing.jl\nPosterior inference and credible intervals\n\n","category":"section"},{"location":"manual/#Information-Criteria-and-Model-Selection","page":"VAR","title":"Information Criteria and Model Selection","text":"","category":"section"},{"location":"manual/#Log-Likelihood","page":"VAR","title":"Log-Likelihood","text":"For a Gaussian VAR, the log-likelihood is:\n\nlog L = -fracT cdot n2 log(2pi) - fracT2 logSigma - frac12 sum_t=1^T u_t Sigma^-1 u_t","category":"section"},{"location":"manual/#Marginal-Likelihood-(Bayesian)","page":"VAR","title":"Marginal Likelihood (Bayesian)","text":"For Bayesian model comparison, we use the marginal likelihood (also called evidence):\n\np(Y  mathcalM) = int p(Y  theta mathcalM) p(theta  mathcalM)  dtheta\n\nModels with higher marginal likelihood better balance fit and complexity.\n\n","category":"section"},{"location":"manual/#Covariance-Estimation","page":"VAR","title":"Covariance Estimation","text":"","category":"section"},{"location":"manual/#Newey-West-HAC-Estimator","page":"VAR","title":"Newey-West HAC Estimator","text":"For robust inference in the presence of heteroskedasticity and autocorrelation, we use the Newey-West (1987, 1994) estimator:\n\nhatV_NW = (XX)^-1 hatS (XX)^-1\n\nwhere the long-run covariance hatS is:\n\nhatS = hatGamma_0 + sum_j=1^m w_j (hatGamma_j + hatGamma_j)\n\nwith hatGamma_j = frac1T sum_t=j+1^T hatu_t hatu_t-j x_t x_t-j.","category":"section"},{"location":"manual/#Kernel-Functions","page":"VAR","title":"Kernel Functions","text":"The weight function w_j depends on the kernel:\n\nBartlett (Newey-West):\n\nw_j = 1 - fracjm+1\n\nParzen:\n\nw_j = begincases\n1 - 6x^2 + 6x^3  x leq 05 \n2(1-x)^3  05  x leq 1\nendcases\n\nwhere x = j(m+1).\n\nQuadratic Spectral (Andrews, 1991):\n\nw_j = frac2512pi^2 x^2 left( fracsin(6pi x5)6pi x5 - cos(6pi x5) right)","category":"section"},{"location":"manual/#Automatic-Bandwidth-Selection","page":"VAR","title":"Automatic Bandwidth Selection","text":"Newey & West (1994) provide a data-driven bandwidth:\n\nm^* = 11447 left( hatalpha cdot T right)^13\n\nwhere hatalpha is estimated from an AR(1) fit to the residuals:\n\nhatalpha = frac4hatrho^2(1-hatrho)^4\n\nReference: Newey & West (1987, 1994), Andrews (1991)\n\n","category":"section"},{"location":"manual/#References","page":"VAR","title":"References","text":"","category":"section"},{"location":"manual/#Vector-Autoregression","page":"VAR","title":"Vector Autoregression","text":"Christiano, L. J., Eichenbaum, M., & Evans, C. L. (1999). \"Monetary Policy Shocks: What Have We Learned and to What End?\" Handbook of Macroeconomics, 1, 65-148.\nHamilton, J. D. (1994). Time Series Analysis. Princeton University Press.\nLütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis. Springer.\nSims, C. A. (1980). \"Macroeconomics and Reality.\" Econometrica, 48(1), 1-48.","category":"section"},{"location":"manual/#Structural-Identification","page":"VAR","title":"Structural Identification","text":"Antolín-Díaz, J., & Rubio-Ramírez, J. F. (2018). \"Narrative Sign Restrictions for SVARs.\" American Economic Review, 108(10), 2802-2829.\nBlanchard, O. J., & Quah, D. (1989). \"The Dynamic Effects of Aggregate Demand and Supply Disturbances.\" American Economic Review, 79(4), 655-673.\nFaust, J. (1998). \"The Robustness of Identified VAR Conclusions about Money.\" Carnegie-Rochester Conference Series on Public Policy, 49, 207-244.\nKilian, L., & Lütkepohl, H. (2017). Structural Vector Autoregressive Analysis. Cambridge University Press.\nRubio-Ramírez, J. F., Waggoner, D. F., & Zha, T. (2010). \"Structural Vector Autoregressions: Theory of Identification and Algorithms for Inference.\" Review of Economic Studies, 77(2), 665-696.\nUhlig, H. (2005). \"What Are the Effects of Monetary Policy on Output? Results from an Agnostic Identification Procedure.\" Journal of Monetary Economics, 52(2), 381-419.","category":"section"},{"location":"manual/#Bayesian-Methods","page":"VAR","title":"Bayesian Methods","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). \"Large Bayesian Vector Auto Regressions.\" Journal of Applied Econometrics, 25(1), 71-92.\nCarriero, A., Clark, T. E., & Marcellino, M. (2015). \"Bayesian VARs: Specification Choices and Forecast Accuracy.\" Journal of Applied Econometrics, 30(1), 46-73.\nDoan, T., Litterman, R., & Sims, C. (1984). \"Forecasting and Conditional Projection Using Realistic Prior Distributions.\" Econometric Reviews, 3(1), 1-100.\nGiannone, D., Lenza, M., & Primiceri, G. E. (2015). \"Prior Selection for Vector Autoregressions.\" Review of Economics and Statistics, 97(2), 436-451.\nKadiyala, K. R., & Karlsson, S. (1997). \"Numerical Methods for Estimation and Inference in Bayesian VAR-Models.\" Journal of Applied Econometrics, 12(2), 99-132.\nLitterman, R. B. (1986). \"Forecasting with Bayesian Vector Autoregressions—Five Years of Experience.\" Journal of Business & Economic Statistics, 4(1), 25-38.","category":"section"},{"location":"manual/#Inference","page":"VAR","title":"Inference","text":"Andrews, D. W. K. (1991). \"Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation.\" Econometrica, 59(3), 817-858.\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). CRC Press.\nHoffman, M. D., & Gelman, A. (2014). \"The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.\" Journal of Machine Learning Research, 15(1), 1593-1623.\nKilian, L. (1998). \"Small-Sample Confidence Intervals for Impulse Response Functions.\" Review of Economics and Statistics, 80(2), 218-230.\nNewey, W. K., & West, K. D. (1987). \"A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix.\" Econometrica, 55(3), 703-708.\nNewey, W. K., & West, K. D. (1994). \"Automatic Lag Selection in Covariance Matrix Estimation.\" Review of Economic Studies, 61(4), 631-653.","category":"section"},{"location":"api/#API-Reference","page":"Overview","title":"API Reference","text":"This section provides the complete API documentation for MacroEconometricModels.jl.\n\nThe API documentation is organized into the following pages:\n\nTypes: Core type definitions for models, results, and estimators\nFunctions: Function documentation organized by module","category":"section"},{"location":"api/#Quick-Reference-Tables","page":"Overview","title":"Quick Reference Tables","text":"","category":"section"},{"location":"api/#Estimation-Functions","page":"Overview","title":"Estimation Functions","text":"Function Description\nestimate_var(Y, p) Estimate VAR(p) via OLS\nestimate_bvar(Y, p; ...) Estimate Bayesian VAR with MCMC\nestimate_lp(Y, shock_var, H; ...) Standard Local Projection\nestimate_lp_iv(Y, shock_var, Z, H; ...) LP with instrumental variables\nestimate_smooth_lp(Y, shock_var, H; ...) Smooth LP with B-splines\nestimate_state_lp(Y, shock_var, state_var, H; ...) State-dependent LP\nestimate_propensity_lp(Y, treatment, covariates, H; ...) LP with propensity scores\ndoubly_robust_lp(Y, treatment, covariates, H; ...) Doubly robust LP estimator\nestimate_factors(X, r; ...) Static factor model via PCA\nestimate_dynamic_factors(X, r, p; ...) Dynamic factor model\nestimate_gdfm(X, q; ...) Generalized dynamic factor model\nestimate_gmm(moment_fn, theta0, data; ...) GMM estimation","category":"section"},{"location":"api/#Structural-Analysis-Functions","page":"Overview","title":"Structural Analysis Functions","text":"Function Description\nirf(model, H; ...) Compute impulse response functions\nfevd(model, H; ...) Forecast error variance decomposition\nidentify_cholesky(model) Cholesky identification\nidentify_sign(model; ...) Sign restriction identification\nidentify_long_run(model) Blanchard-Quah identification\nidentify_narrative(model; ...) Narrative sign restrictions","category":"section"},{"location":"api/#Unit-Root-Test-Functions","page":"Overview","title":"Unit Root Test Functions","text":"Function Description\nadf_test(y; ...) Augmented Dickey-Fuller unit root test\nkpss_test(y; ...) KPSS stationarity test\npp_test(y; ...) Phillips-Perron unit root test\nza_test(y; ...) Zivot-Andrews structural break test\nngperron_test(y; ...) Ng-Perron unit root tests (MZα, MZt, MSB, MPT)\njohansen_test(Y, p; ...) Johansen cointegration test\nis_stationary(model) Check VAR model stationarity\nunit_root_summary(y; ...) Run multiple tests with summary\ntest_all_variables(Y; ...) Apply test to all columns","category":"section"},{"location":"api/#LP-IRF-Extraction","page":"Overview","title":"LP IRF Extraction","text":"Function Description\nlp_irf(model; ...) Extract IRF from LPModel\nlp_iv_irf(model; ...) Extract IRF from LPIVModel\nsmooth_lp_irf(model; ...) Extract smoothed IRF\nstate_irf(model; ...) Extract state-dependent IRFs\npropensity_irf(model; ...) Extract ATE impulse response","category":"section"},{"location":"api/#Factor-Model-Functions","page":"Overview","title":"Factor Model Functions","text":"Function Description\nestimate_factors(X, r; ...) Estimate r-factor model\nic_criteria(X, r_max) Bai-Ng information criteria\nscree_plot_data(model) Data for scree plot","category":"section"},{"location":"api/#Diagnostic-Functions","page":"Overview","title":"Diagnostic Functions","text":"Function Description\noptimize_hyperparameters(Y, p; ...) Optimize Minnesota prior\nweak_instrument_test(model; ...) Test for weak instruments\nsargan_test(model, h) Overidentification test\ntest_regime_difference(model; ...) Test regime differences\npropensity_diagnostics(model) Propensity score diagnostics\nj_test(model) Hansen J-test for GMM\ngmm_summary(model) Summary statistics for GMM","category":"section"},{"location":"api/#Covariance-Functions","page":"Overview","title":"Covariance Functions","text":"Function Description\nnewey_west(X, residuals; ...) Newey-West HAC estimator\nwhite_vcov(X, residuals; ...) White heteroskedasticity-robust\ndriscoll_kraay(X, residuals; ...) Driscoll-Kraay panel-robust\nlong_run_variance(x; ...) Long-run variance estimate\nlong_run_covariance(X; ...) Long-run covariance matrix\noptimal_bandwidth_nw(residuals) Automatic bandwidth selection","category":"section"},{"location":"api/#Utility-Functions","page":"Overview","title":"Utility Functions","text":"Function Description\nconstruct_var_matrices(Y, p) Build VAR design matrices\ncompanion_matrix(B, n, p) VAR companion form\nrobust_inv(A) Robust matrix inverse\nsafe_cholesky(A; ...) Stable Cholesky decomposition","category":"section"},{"location":"factormodels/#Factor-Models","page":"Factor Models","title":"Factor Models","text":"This chapter covers static factor models for dimensionality reduction in large macroeconomic panels, including estimation via principal components and information criteria for selecting the number of factors.","category":"section"},{"location":"factormodels/#Introduction","page":"Factor Models","title":"Introduction","text":"Factor models are fundamental tools in macroeconometrics for extracting common sources of variation from large panels of economic indicators. They enable:\n\nDimensionality Reduction: Summarize N variables with r ll N factors\nForecasting: Use factors as predictors in regressions (diffusion indices)\nStructural Analysis: Identify common shocks driving multiple series\nFAVAR: Combine factors with VARs for high-dimensional structural analysis\n\nReference: Stock & Watson (2002a, 2002b), Bai & Ng (2002)\n\n","category":"section"},{"location":"factormodels/#The-Static-Factor-Model","page":"Factor Models","title":"The Static Factor Model","text":"","category":"section"},{"location":"factormodels/#Model-Specification","page":"Factor Models","title":"Model Specification","text":"The static factor model decomposes an N-dimensional vector of observables x_t into common and idiosyncratic components:\n\nx_it = lambda_i F_t + e_it quad i = 1 ldots N quad t = 1 ldots T\n\nIn matrix form:\n\nX = F Lambda + E\n\nwhere:\n\nX is the T times N data matrix\nF is the T times r matrix of latent factors\nLambda is the N times r matrix of factor loadings\nE is the T times N matrix of idiosyncratic errors\nr is the number of factors (with r ll min(T N))","category":"section"},{"location":"factormodels/#Assumptions","page":"Factor Models","title":"Assumptions","text":"Factors and Loadings:\n\nEF_t = 0, textVar(F_t) = I_r (normalization)\nfrac1T sum_t F_t F_t xrightarrowp Sigma_F positive definite\nfrac1N Lambda Lambda xrightarrowp Sigma_Lambda positive definite\n\nIdiosyncratic Errors:\n\nEe_it = 0\nWeak cross-sectional and temporal dependence allowed\nWeak correlation with factors: frac1NT sum_it EF_t e_it to 0\n\nReference: Bai & Ng (2002), Bai (2003)\n\n","category":"section"},{"location":"factormodels/#Estimation-via-Principal-Components","page":"Factor Models","title":"Estimation via Principal Components","text":"","category":"section"},{"location":"factormodels/#Principal-Components-Analysis-(PCA)","page":"Factor Models","title":"Principal Components Analysis (PCA)","text":"The factors and loadings are estimated by minimizing the sum of squared idiosyncratic errors:\n\nmin_F Lambda sum_i=1^N sum_t=1^T (x_it - lambda_i F_t)^2\n\nsubject to the normalization FFT = I_r.","category":"section"},{"location":"factormodels/#Solution","page":"Factor Models","title":"Solution","text":"The solution involves the eigenvalue decomposition of XX (or XX):\n\nCase 1: T  N (short panel)\n\nCompute XX (T times T matrix)\nhatF = sqrtT times (first r eigenvectors of XX)\nhatLambda = X hatF  T\n\nCase 2: N leq T (tall panel)\n\nCompute XX (N times N matrix)\nhatLambda = sqrtN times (first r eigenvectors of XX)\nhatF = X hatLambda  N","category":"section"},{"location":"factormodels/#Data-Preprocessing","page":"Factor Models","title":"Data Preprocessing","text":"Before estimation, data is typically:\n\nDemeaned: Center each series to have zero mean\nStandardized: Scale each series to have unit variance\n\nThis prevents high-variance series from dominating the factor extraction.","category":"section"},{"location":"factormodels/#Identification","page":"Factor Models","title":"Identification","text":"The factors and loadings are identified only up to an r times r invertible rotation. If (F Lambda) is a solution, so is (FH Lambda H^-1) for any invertible H.\n\nThe normalization FFT = I_r and LambdaLambda diagonal pins down rotation up to sign.\n\nReference: Stock & Watson (2002a), Bai & Ng (2002)","category":"section"},{"location":"factormodels/#Julia-Implementation","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# X is T×N data matrix\n# Estimate r-factor model\n\nmodel = estimate_factors(X, r;\n    standardize = true,    # Standardize data\n    method = :pca          # Principal components\n)\n\n# Access results\nF = model.factors          # T×r estimated factors\nΛ = model.loadings         # N×r estimated loadings\n\n","category":"section"},{"location":"factormodels/#Determining-the-Number-of-Factors","page":"Factor Models","title":"Determining the Number of Factors","text":"","category":"section"},{"location":"factormodels/#The-Selection-Problem","page":"Factor Models","title":"The Selection Problem","text":"Choosing r is crucial:\n\nToo few factors: Omitted common variation, biased estimates\nToo many factors: Overfitting, including noise as signal","category":"section"},{"location":"factormodels/#Bai-and-Ng-(2002)-Information-Criteria","page":"Factor Models","title":"Bai & Ng (2002) Information Criteria","text":"Bai & Ng propose three information criteria:\n\nIC1:\n\nIC_1(r) = log hatsigma^2(r) + r cdot fracN + TNT logleft( fracNTN+T right)\n\nIC2:\n\nIC_2(r) = log hatsigma^2(r) + r cdot fracN + TNT log(C_NT^2)\n\nIC3:\n\nIC_3(r) = log hatsigma^2(r) + r cdot fraclog(C_NT^2)C_NT^2\n\nwhere:\n\nhatsigma^2(r) = frac1NT sum_it hate_it^2 is the average squared residual\nC_NT^2 = min(N T)\n\nSelection Rule: Choose hatr that minimizes IC_k(r) over r in 1 ldots r_max.\n\nProperties:\n\nIC2 and IC3 perform best in simulations\nAll three are consistent: hatr xrightarrowp r_0 as N T to infty\n\nReference: Bai & Ng (2002)","category":"section"},{"location":"factormodels/#Julia-Implementation-2","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Compute IC for r = 1, ..., r_max\nr_max = 10\nic = ic_criteria(X, r_max)\n\n# Optimal number by each criterion\nprintln(\"IC1 selects: \", ic.r_IC1, \" factors\")\nprintln(\"IC2 selects: \", ic.r_IC2, \" factors\")\nprintln(\"IC3 selects: \", ic.r_IC3, \" factors\")\n\n# IC values for all r\nfor r in 1:r_max\n    println(\"r=$r: IC1=$(ic.IC1[r]), IC2=$(ic.IC2[r]), IC3=$(ic.IC3[r])\")\nend\n\n","category":"section"},{"location":"factormodels/#Scree-Plot-Analysis","page":"Factor Models","title":"Scree Plot Analysis","text":"","category":"section"},{"location":"factormodels/#Visual-Factor-Selection","page":"Factor Models","title":"Visual Factor Selection","text":"The scree plot displays eigenvalues (or variance explained) against factor number. The \"elbow\" in the plot suggests the number of significant factors.","category":"section"},{"location":"factormodels/#Variance-Explained","page":"Factor Models","title":"Variance Explained","text":"For each factor j:\n\nIndividual Variance:\n\ntextVarExp_j = fracmu_jsum_k=1^N mu_k\n\nCumulative Variance:\n\ntextCumVarExp_r = sum_j=1^r textVarExp_j\n\nwhere mu_j is the j-th largest eigenvalue of XXT (or XXN).","category":"section"},{"location":"factormodels/#Julia-Implementation-3","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\nmodel = estimate_factors(X, r)\n\n# Get scree plot data\nscree = scree_plot_data(model)\n\n# Variance explained\nfor j in 1:min(10, length(scree.factors))\n    println(\"Factor $j: $(round(scree.explained_variance[j]*100, digits=2))% \",\n            \"(cumulative: $(round(scree.cumulative_variance[j]*100, digits=2))%)\")\nend\n\n","category":"section"},{"location":"factormodels/#Model-Diagnostics","page":"Factor Models","title":"Model Diagnostics","text":"","category":"section"},{"location":"factormodels/#R-squared-for-Each-Variable","page":"Factor Models","title":"R-squared for Each Variable","text":"The R^2 measures how much of variable i's variation is explained by the common factors:\n\nR^2_i = 1 - fracsum_t hate_it^2sum_t (x_it - barx_i)^2\n\nVariables with low R^2 are mainly driven by idiosyncratic shocks.","category":"section"},{"location":"factormodels/#Julia-Implementation-4","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\nmodel = estimate_factors(X, r)\n\n# R² for each variable\nr2_values = r2(model)\n\n# Summary statistics\nprintln(\"Mean R²: \", round(mean(r2_values), digits=3))\nprintln(\"Median R²: \", round(median(r2_values), digits=3))\nprintln(\"Min R²: \", round(minimum(r2_values), digits=3))\nprintln(\"Max R²: \", round(maximum(r2_values), digits=3))\n\n# Variables well-explained by factors\nwell_explained = findall(r2_values .> 0.7)","category":"section"},{"location":"factormodels/#Fitted-Values-and-Residuals","page":"Factor Models","title":"Fitted Values and Residuals","text":"# Fitted values: X̂ = FΛ'\nX_fitted = predict(model)\n\n# Residuals: E = X - X̂\nresid = residuals(model)\n\n# Model statistics\nprintln(\"Number of observations: \", nobs(model))\nprintln(\"Degrees of freedom: \", dof(model))\n\n","category":"section"},{"location":"factormodels/#Applications","page":"Factor Models","title":"Applications","text":"","category":"section"},{"location":"factormodels/#Diffusion-Index-Forecasting","page":"Factor Models","title":"Diffusion Index Forecasting","text":"Use factors as predictors for forecasting a target variable y_t+h:\n\ny_t+h = alpha + beta hatF_t + gamma y_tt-p + varepsilon_t+h\n\nFactors summarize information from a large panel, improving forecast accuracy.\n\nReference: Stock & Watson (2002b)","category":"section"},{"location":"factormodels/#Factor-Augmented-VAR-(FAVAR)","page":"Factor Models","title":"Factor-Augmented VAR (FAVAR)","text":"Combine factors with key observable variables in a VAR:\n\nbeginbmatrix y_t  F_t endbmatrix = A_1 beginbmatrix y_t-1  F_t-1 endbmatrix + cdots + A_p beginbmatrix y_t-p  F_t-p endbmatrix + u_t\n\nThis allows structural analysis with high-dimensional information sets.\n\nReference: Bernanke, Boivin & Eliasz (2005)","category":"section"},{"location":"factormodels/#Example:-FAVAR-Setup","page":"Factor Models","title":"Example: FAVAR Setup","text":"using MacroEconometricModels\n\n# Estimate factors from large panel X\nfm = estimate_factors(X, r)\nF = fm.factors\n\n# Combine with key observables (e.g., FFR, GDP, inflation)\nY_key = Matrix(data[:, [:FFR, :GDP, :CPI]])\nY_favar = hcat(Y_key, F)\n\n# Estimate FAVAR\nfavar_model = estimate_var(Y_favar, p)\n\n# Structural analysis\nirf_favar = irf(favar_model, H; method=:cholesky)\n\n","category":"section"},{"location":"factormodels/#Asymptotic-Theory","page":"Factor Models","title":"Asymptotic Theory","text":"","category":"section"},{"location":"factormodels/#Consistency-of-Factor-Estimates","page":"Factor Models","title":"Consistency of Factor Estimates","text":"Under the assumptions of Bai & Ng (2002), as T N to infty:\n\nfrac1T sum_t=1^T hatF_t - H F_t^2 = O_pleft( frac1min(N T) right)\n\nwhere H is an r times r rotation matrix.\n\nThe factors are consistently estimated up to rotation at rate min(sqrtN sqrtT).","category":"section"},{"location":"factormodels/#Distribution-Theory","page":"Factor Models","title":"Distribution Theory","text":"For large N T, the factor estimates are asymptotically normal:\n\nsqrtT (hatF_t - H F_t) xrightarrowd N(0 V)\n\nwhere V depends on the cross-sectional and temporal dependence structure.\n\nReference: Bai (2003), Bai & Ng (2006)\n\n","category":"section"},{"location":"factormodels/#Comparison-with-Other-Methods","page":"Factor Models","title":"Comparison with Other Methods","text":"","category":"section"},{"location":"factormodels/#Static-vs.-Dynamic-Factor-Models","page":"Factor Models","title":"Static vs. Dynamic Factor Models","text":"Aspect Static FM Dynamic FM\nModel X_t = Lambda F_t + e_t X_t = Lambda(L) f_t + e_t\nFactors Contemporaneous May include lags\nEstimation PCA Spectral methods, Kalman filter\nUse case Large N, moderate T Time series dynamics important\n\nReference: Forni, Hallin, Lippi & Reichlin (2000)","category":"section"},{"location":"factormodels/#Maximum-Likelihood-Estimation","page":"Factor Models","title":"Maximum Likelihood Estimation","text":"ML estimation assumes Gaussian factors and errors:\n\nF_t sim N(0 I_r) quad e_t sim N(0 Psi)\n\nEstimated via EM algorithm. More efficient than PCA if model is correctly specified, but computationally intensive.\n\n","category":"section"},{"location":"factormodels/#Dynamic-Factor-Models","page":"Factor Models","title":"Dynamic Factor Models","text":"","category":"section"},{"location":"factormodels/#Model-Specification-2","page":"Factor Models","title":"Model Specification","text":"The dynamic factor model extends the static model by allowing factors to follow a VAR process:\n\nObservation Equation:\n\nX_t = Lambda F_t + e_t\n\nState Equation (Factor Dynamics):\n\nF_t = A_1 F_t-1 + A_2 F_t-2 + cdots + A_p F_t-p + eta_t\n\nwhere:\n\nF_t is the r times 1 vector of latent factors\nLambda is the N times r loading matrix\nA_1 ldots A_p are r times r autoregressive coefficient matrices\neta_t sim N(0 Sigma_eta) are factor innovations\ne_t sim N(0 Sigma_e) are idiosyncratic errors (typically diagonal)","category":"section"},{"location":"factormodels/#Estimation-Methods","page":"Factor Models","title":"Estimation Methods","text":"Two-Step Estimation:\n\nExtract factors using PCA (as in static model)\nEstimate VAR(p) on extracted factors\n\nEM Algorithm:\n\nIterates between E-step (Kalman smoother) and M-step (parameter updates)\nMore efficient but computationally intensive","category":"section"},{"location":"factormodels/#Julia-Implementation-5","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Estimate dynamic factor model with r factors and p lags\nmodel = estimate_dynamic_factors(X, r, p;\n    method = :twostep,      # or :em\n    standardize = true,\n    diagonal_idio = true    # Diagonal idiosyncratic covariance\n)\n\n# Access results\nF = model.factors           # T×r estimated factors\nΛ = model.loadings          # N×r loadings\nA = model.A                 # Vector of r×r AR coefficient matrices\nΣ_η = model.Sigma_eta       # r×r factor innovation covariance\nΣ_e = model.Sigma_e         # N×N idiosyncratic covariance","category":"section"},{"location":"factormodels/#Model-Selection-for-DFM","page":"Factor Models","title":"Model Selection for DFM","text":"Select the number of factors r and lag order p using information criteria:\n\n# Grid search over (r, p) combinations\nic = ic_criteria_dynamic(X, max_r, max_p;\n    method = :twostep,\n    standardize = true\n)\n\nprintln(\"AIC selects: r=$(ic.r_AIC), p=$(ic.p_AIC)\")\nprintln(\"BIC selects: r=$(ic.r_BIC), p=$(ic.p_BIC)\")\n\n# View full IC matrices\nic.AIC  # r×p matrix of AIC values\nic.BIC  # r×p matrix of BIC values","category":"section"},{"location":"factormodels/#Forecasting-with-DFM","page":"Factor Models","title":"Forecasting with DFM","text":"# Point forecasts h steps ahead\nfc = forecast(model, h)\nfc.factors      # h×r factor forecasts\nfc.observables  # h×N observable forecasts\n\n# Forecasts with confidence intervals\nfc = forecast(model, h;\n    ci_level = 0.90,\n    n_sim = 1000\n)\nfc.factors_lower, fc.factors_upper      # Factor CIs\nfc.observables_lower, fc.observables_upper  # Observable CIs","category":"section"},{"location":"factormodels/#Stationarity-Check","page":"Factor Models","title":"Stationarity Check","text":"# Check if factor dynamics are stationary\nis_stationary(model)  # true if max|eigenvalue| < 1\n\n# Get companion matrix for factor VAR\nC = companion_matrix_factors(model)\neigvals(C)  # Eigenvalues determine stability\n\nReference: Stock & Watson (2002a), Doz, Giannone & Reichlin (2011)\n\n","category":"section"},{"location":"factormodels/#Generalized-Dynamic-Factor-Model-(GDFM)","page":"Factor Models","title":"Generalized Dynamic Factor Model (GDFM)","text":"","category":"section"},{"location":"factormodels/#Theoretical-Foundation","page":"Factor Models","title":"Theoretical Foundation","text":"The Generalized Dynamic Factor Model of Forni, Hallin, Lippi & Reichlin (2000, 2005) provides a fully dynamic approach to factor analysis using spectral methods. Unlike the standard DFM which uses static PCA followed by VAR, the GDFM extracts factors directly in the frequency domain.","category":"section"},{"location":"factormodels/#Model-Specification-3","page":"Factor Models","title":"Model Specification","text":"The GDFM decomposes each observable as:\n\nx_it = chi_it + xi_it\n\nwhere:\n\nchi_it is the common component driven by q common shocks\nxi_it is the idiosyncratic component\n\nThe common component has the representation:\n\nchi_it = b_i1(L) u_1t + b_i2(L) u_2t + cdots + b_iq(L) u_qt\n\nwhere b_ij(L) are square-summable filters and u_jt are orthonormal white noise shocks.","category":"section"},{"location":"factormodels/#Spectral-Representation","page":"Factor Models","title":"Spectral Representation","text":"In the frequency domain, the spectral density of X_t decomposes as:\n\nSigma_X(omega) = Sigma_chi(omega) + Sigma_xi(omega)\n\nThe key insight is that common factors produce diverging eigenvalues (growing with N) while idiosyncratic components produce bounded eigenvalues.","category":"section"},{"location":"factormodels/#Estimation-Algorithm","page":"Factor Models","title":"Estimation Algorithm","text":"Spectral Density Estimation: Estimate hatSigma_X(omega) using kernel smoothing of the periodogram\nDynamic Eigenanalysis: Compute eigenvalue decomposition at each frequency\nFactor Extraction: Select top q eigenvectors (dynamic principal components)\nCommon Component: Reconstruct chi_t via inverse Fourier transform","category":"section"},{"location":"factormodels/#Julia-Implementation-6","page":"Factor Models","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Estimate GDFM with q dynamic factors\nmodel = estimate_gdfm(X, q;\n    standardize = true,\n    bandwidth = 0,           # Auto-select: T^(1/3)\n    kernel = :bartlett,      # :bartlett, :parzen, or :tukey\n    r = 0                    # Static factors (0 = same as q)\n)\n\n# Access results\nF = model.factors                 # T×q time-domain factors\nχ = model.common_component        # T×N common component\nξ = model.idiosyncratic           # T×N idiosyncratic component\nΛ = model.loadings_spectral       # N×q×n_freq frequency-domain loadings\n\n# Variance explained by dynamic factors\nmodel.variance_explained          # q-vector of variance shares","category":"section"},{"location":"factormodels/#Selecting-the-Number-of-Dynamic-Factors","page":"Factor Models","title":"Selecting the Number of Dynamic Factors","text":"The GDFM uses eigenvalue-based criteria rather than information criteria:\n\n# Compute selection criteria\nic = ic_criteria_gdfm(X, max_q;\n    standardize = true,\n    bandwidth = 0,\n    kernel = :bartlett\n)\n\n# Eigenvalue ratio criterion (Ahn & Horenstein 2013)\nprintln(\"Ratio criterion selects: q=$(ic.q_ratio)\")\n\n# Variance threshold criterion (90% of spectral variance)\nprintln(\"Variance criterion selects: q=$(ic.q_variance)\")\n\n# Diagnostic data\nic.eigenvalue_ratios      # λ_i / λ_{i+1} ratios\nic.cumulative_variance    # Cumulative variance explained\nic.avg_eigenvalues        # Average eigenvalues across frequencies","category":"section"},{"location":"factormodels/#Spectral-Diagnostics","page":"Factor Models","title":"Spectral Diagnostics","text":"# Get data for eigenvalue plots across frequencies\nplot_data = spectral_eigenvalue_plot_data(model)\nplot_data.frequencies     # Vector of frequencies (0 to π)\nplot_data.eigenvalues     # N×n_freq matrix of eigenvalues\n\n# First eigenvalue should dominate if one strong factor\n# Gap between q-th and (q+1)-th eigenvalue indicates factor count","category":"section"},{"location":"factormodels/#Common-Variance-Share","page":"Factor Models","title":"Common Variance Share","text":"# Fraction of variance explained by common component for each variable\nshares = common_variance_share(model)\n\n# Variables well-explained by common factors\nwell_explained = findall(shares .> 0.5)\n\n# Summary statistics\nprintln(\"Mean common variance share: \", round(mean(shares), digits=3))\nprintln(\"Variables with >50% common: \", length(well_explained))","category":"section"},{"location":"factormodels/#Forecasting-with-GDFM","page":"Factor Models","title":"Forecasting with GDFM","text":"# Forecast h steps ahead\nfc = forecast(model, h; method=:ar)\n\nfc.common   # h×N common component forecast\nfc.factors  # h×q factor forecast","category":"section"},{"location":"factormodels/#Comparison:-DFM-vs-GDFM","page":"Factor Models","title":"Comparison: DFM vs GDFM","text":"Aspect Dynamic Factor Model Generalized DFM\nApproach Time domain (PCA + VAR) Frequency domain (spectral)\nFactor dynamics Explicit VAR structure Implicit through spectral density\nEstimation Two-step or EM Kernel-smoothed periodogram\nComputational cost Moderate Higher (FFT at each frequency)\nAsymptotics T to infty N T to infty jointly\nBest for Moderate N, focus on forecasting Large N, structural decomposition","category":"section"},{"location":"factormodels/#Example:-Complete-GDFM-Workflow","page":"Factor Models","title":"Example: Complete GDFM Workflow","text":"using MacroEconometricModels\n\n# Load large macroeconomic panel (e.g., FRED-MD)\nX = load_data()  # T×N matrix\n\n# Step 1: Select number of factors\nic = ic_criteria_gdfm(X, 10)\nq = ic.q_ratio\nprintln(\"Selected q = $q dynamic factors\")\n\n# Step 2: Estimate GDFM\nmodel = estimate_gdfm(X, q; kernel=:parzen)\n\n# Step 3: Diagnostics\nprintln(\"Variance explained: \", round.(model.variance_explained, digits=3))\nprintln(\"Mean R²: \", round(mean(r2(model)), digits=3))\n\n# Step 4: Extract common component for further analysis\nχ = model.common_component  # Use in FAVAR, forecasting, etc.\n\n# Step 5: Identify variables driven by common vs idiosyncratic shocks\nshares = common_variance_share(model)\ncommon_driven = findall(shares .> 0.7)\nidio_driven = findall(shares .< 0.3)\n\nReferences:\n\nForni, M., Hallin, M., Lippi, M., & Reichlin, L. (2000). \"The Generalized Dynamic-Factor Model: Identification and Estimation.\"\nForni, M., Hallin, M., Lippi, M., & Reichlin, L. (2005). \"The Generalized Dynamic Factor Model: One-Sided Estimation and Forecasting.\"\nHallin, M., & Liška, R. (2007). \"Determining the Number of Factors in the General Dynamic Factor Model.\"\n\n","category":"section"},{"location":"factormodels/#References","page":"Factor Models","title":"References","text":"","category":"section"},{"location":"factormodels/#Core-References","page":"Factor Models","title":"Core References","text":"Bai, J. (2003). \"Inferential Theory for Factor Models of Large Dimensions.\" Econometrica, 71(1), 135-171.\nBai, J., & Ng, S. (2002). \"Determining the Number of Factors in Approximate Factor Models.\" Econometrica, 70(1), 191-221.\nBai, J., & Ng, S. (2006). \"Confidence Intervals for Diffusion Index Forecasts and Inference for Factor-Augmented Regressions.\" Econometrica, 74(4), 1133-1150.\nStock, J. H., & Watson, M. W. (2002a). \"Forecasting Using Principal Components from a Large Number of Predictors.\" Journal of the American Statistical Association, 97(460), 1167-1179.\nStock, J. H., & Watson, M. W. (2002b). \"Macroeconomic Forecasting Using Diffusion Indexes.\" Journal of Business & Economic Statistics, 20(2), 147-162.","category":"section"},{"location":"factormodels/#Dynamic-Factor-Models-2","page":"Factor Models","title":"Dynamic Factor Models","text":"Doz, C., Giannone, D., & Reichlin, L. (2011). \"A Two-Step Estimator for Large Approximate Dynamic Factor Models Based on Kalman Filtering.\" Journal of Econometrics, 164(1), 188-205.\nDoz, C., Giannone, D., & Reichlin, L. (2012). \"A Quasi-Maximum Likelihood Approach for Large, Approximate Dynamic Factor Models.\" Review of Economics and Statistics, 94(4), 1014-1024.\nForni, M., Hallin, M., Lippi, M., & Reichlin, L. (2000). \"The Generalized Dynamic-Factor Model: Identification and Estimation.\" Review of Economics and Statistics, 82(4), 540-554.\nForni, M., Hallin, M., Lippi, M., & Reichlin, L. (2005). \"The Generalized Dynamic Factor Model: One-Sided Estimation and Forecasting.\" Journal of the American Statistical Association, 100(471), 830-840.\nHallin, M., & Liška, R. (2007). \"Determining the Number of Factors in the General Dynamic Factor Model.\" Journal of the American Statistical Association, 102(478), 603-617.","category":"section"},{"location":"factormodels/#Applications-2","page":"Factor Models","title":"Applications","text":"Bernanke, B. S., Boivin, J., & Eliasz, P. (2005). \"Measuring the Effects of Monetary Policy: A Factor-Augmented Vector Autoregressive (FAVAR) Approach.\" Quarterly Journal of Economics, 120(1), 387-422.\nMcCracken, M. W., & Ng, S. (2016). \"FRED-MD: A Monthly Database for Macroeconomic Research.\" Journal of Business & Economic Statistics, 34(4), 574-589.","category":"section"},{"location":"hypothesis_tests/#Hypothesis-Tests","page":"Unit Root & Cointegration","title":"Hypothesis Tests","text":"This chapter covers statistical hypothesis tests for time series analysis, including unit root tests for stationarity detection, cointegration tests for multivariate relationships, and VAR stability diagnostics.","category":"section"},{"location":"hypothesis_tests/#Introduction","page":"Unit Root & Cointegration","title":"Introduction","text":"Before fitting dynamic models like VARs or Local Projections, it is essential to understand the stationarity properties of the data. Non-stationary series (those with unit roots) require different treatment than stationary series, as standard regression methods can lead to spurious results.\n\nMacroEconometricModels.jl provides a comprehensive suite of unit root and stationarity tests:","category":"section"},{"location":"hypothesis_tests/#Univariate-Tests","page":"Unit Root & Cointegration","title":"Univariate Tests","text":"ADF (Augmented Dickey-Fuller): Tests the null of a unit root against stationarity\nKPSS: Tests the null of stationarity against a unit root\nPhillips-Perron: Non-parametric unit root test with autocorrelation correction\nZivot-Andrews: Unit root test allowing for endogenous structural break\nNg-Perron: Modified tests with improved size properties","category":"section"},{"location":"hypothesis_tests/#Multivariate-Tests","page":"Unit Root & Cointegration","title":"Multivariate Tests","text":"Johansen Cointegration: Tests for cointegrating relationships among variables","category":"section"},{"location":"hypothesis_tests/#Model-Diagnostics","page":"Unit Root & Cointegration","title":"Model Diagnostics","text":"VAR Stationarity: Check if an estimated VAR model is stable\n\n","category":"section"},{"location":"hypothesis_tests/#Augmented-Dickey-Fuller-Test","page":"Unit Root & Cointegration","title":"Augmented Dickey-Fuller Test","text":"","category":"section"},{"location":"hypothesis_tests/#Theory","page":"Unit Root & Cointegration","title":"Theory","text":"The Augmented Dickey-Fuller (ADF) test examines whether a time series has a unit root. Consider the autoregressive model:\n\ny_t = rho y_t-1 + u_t\n\nThe null hypothesis is H_0 rho = 1 (unit root) against H_1 rho  1 (stationary).\n\nThe test is performed via the regression:\n\nDelta y_t = alpha + beta t + gamma y_t-1 + sum_j=1^p delta_j Delta y_t-j + varepsilon_t\n\nwhere:\n\ngamma = rho - 1 is the coefficient of interest\nalpha is an optional constant\nbeta t is an optional linear trend\nLagged differences are included to control for serial correlation\n\nThe ADF statistic is the t-ratio tau = hatgamma  textse(hatgamma).\n\nCritical values depend on the specification (none, constant, or trend) and are tabulated using MacKinnon (1994, 2010) response surfaces.\n\nReference: Dickey & Fuller (1979), MacKinnon (2010)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Generate a random walk (has unit root)\ny = cumsum(randn(200))\n\n# ADF test with automatic lag selection via AIC\nresult = adf_test(y; lags=:aic, regression=:constant)\n\n# The result displays with publication-quality formatting:\n# - Test statistic and significance stars\n# - Critical values at 1%, 5%, 10% levels\n# - Automatic conclusion","category":"section"},{"location":"hypothesis_tests/#Function-Signature","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Options","page":"Unit Root & Cointegration","title":"Options","text":"Argument Description Default\nlags Number of augmenting lags, or :aic/:bic/:hqic for automatic selection :aic\nmax_lags Maximum lags for automatic selection floor(12*(T/100)^0.25)\nregression Deterministic terms: :none, :constant, or :trend :constant","category":"section"},{"location":"hypothesis_tests/#Interpreting-Results","page":"Unit Root & Cointegration","title":"Interpreting Results","text":"Reject H₀ (p-value < 0.05): Evidence against unit root; series appears stationary\nFail to reject H₀ (p-value > 0.05): Cannot reject unit root; series may be non-stationary\n\n","category":"section"},{"location":"hypothesis_tests/#KPSS-Stationarity-Test","page":"Unit Root & Cointegration","title":"KPSS Stationarity Test","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-2","page":"Unit Root & Cointegration","title":"Theory","text":"The KPSS test (Kwiatkowski, Phillips, Schmidt & Shin, 1992) reverses the hypotheses of the ADF test:\n\nH_0: Series is stationary (level or trend stationary)\nH_1: Series has a unit root\n\nThis complementary approach is valuable because failure to reject in the ADF test does not confirm stationarity—it may simply reflect low power.\n\nThe test decomposes the series:\n\ny_t = xi t + r_t + varepsilon_t\n\nwhere r_t = r_t-1 + u_t is a random walk. Under H_0, the variance of u_t is zero.\n\nThe KPSS statistic is:\n\ntextKPSS = fracsum_t=1^T S_t^2T^2 hatsigma^2_LR\n\nwhere S_t = sum_s=1^t hate_s are partial sums of residuals and hatsigma^2_LR is the long-run variance estimated using a Bartlett kernel.\n\nReference: Kwiatkowski et al. (1992)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-2","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Stationary series\ny = randn(200)\nresult = kpss_test(y; regression=:constant)\n\n# For trend stationarity\nresult_trend = kpss_test(y; regression=:trend)","category":"section"},{"location":"hypothesis_tests/#Function-Signature-2","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Options-2","page":"Unit Root & Cointegration","title":"Options","text":"Argument Description Default\nregression Stationarity type: :constant (level) or :trend :constant\nbandwidth Bartlett kernel bandwidth, or :auto for Newey-West selection :auto","category":"section"},{"location":"hypothesis_tests/#Interpreting-Results-2","page":"Unit Root & Cointegration","title":"Interpreting Results","text":"Reject H₀ (p-value < 0.05): Evidence against stationarity; series has a unit root\nFail to reject H₀ (p-value > 0.05): Cannot reject stationarity","category":"section"},{"location":"hypothesis_tests/#Combining-ADF-and-KPSS","page":"Unit Root & Cointegration","title":"Combining ADF and KPSS","text":"Using both tests together provides stronger inference:\n\nADF Result KPSS Result Conclusion\nReject H₀ (stationary) Fail to reject H₀ (stationary) Stationary\nFail to reject H₀ (unit root) Reject H₀ (unit root) Unit root\nReject H₀ Reject H₀ Conflicting (possible structural break)\nFail to reject H₀ Fail to reject H₀ Inconclusive\n\n","category":"section"},{"location":"hypothesis_tests/#Phillips-Perron-Test","page":"Unit Root & Cointegration","title":"Phillips-Perron Test","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-3","page":"Unit Root & Cointegration","title":"Theory","text":"The Phillips-Perron (PP) test is a non-parametric alternative to the ADF test. Instead of augmenting with lagged differences, the PP test corrects the t-statistic for serial correlation using Newey-West standard errors.\n\nThe regression is:\n\ny_t = alpha + rho y_t-1 + u_t\n\nThe PP Z_t statistic adjusts the OLS t-ratio:\n\nZ_t = sqrtfrachatgamma_0hatlambda^2 t_rho - frachatlambda^2 - hatgamma_02hatlambda cdot textse(hatrho) cdot sqrtT\n\nwhere hatgamma_0 is the short-run variance and hatlambda^2 is the long-run variance.\n\nAdvantage: Does not require specifying the number of lags.\n\nReference: Phillips & Perron (1988)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-3","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\ny = cumsum(randn(200))\nresult = pp_test(y; regression=:constant)","category":"section"},{"location":"hypothesis_tests/#Function-Signature-3","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Options-3","page":"Unit Root & Cointegration","title":"Options","text":"Argument Description Default\nregression Deterministic terms: :none, :constant, or :trend :constant\nbandwidth Newey-West bandwidth, or :auto :auto\n\n","category":"section"},{"location":"hypothesis_tests/#Zivot-Andrews-Test","page":"Unit Root & Cointegration","title":"Zivot-Andrews Test","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-4","page":"Unit Root & Cointegration","title":"Theory","text":"The Zivot-Andrews test extends the ADF test by allowing for an endogenous structural break in the series. This is important because standard unit root tests have low power against stationary alternatives with structural breaks.\n\nThree specifications are available:\n\nBreak in intercept (:constant):\n\nDelta y_t = alpha + beta t + theta DU_t + gamma y_t-1 + sum_j delta_j Delta y_t-j + varepsilon_t\n\nBreak in trend (:trend):\n\nDelta y_t = alpha + beta t + phi DT_t + gamma y_t-1 + sum_j delta_j Delta y_t-j + varepsilon_t\n\nBreak in both (:both):\n\nDelta y_t = alpha + beta t + theta DU_t + phi DT_t + gamma y_t-1 + sum_j delta_j Delta y_t-j + varepsilon_t\n\nwhere:\n\nDU_t = 1 if t  T_B (level shift dummy)\nDT_t = t - T_B if t  T_B (trend shift dummy)\nT_B is the break point, selected to minimize the t-statistic on gamma\n\nReference: Zivot & Andrews (1992)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-4","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Series with structural break\ny = vcat(randn(100), randn(100) .+ 2)  # Level shift at t=100\nresult = za_test(y; regression=:constant)\n\n# Access break point\nprintln(\"Break detected at observation: \", result.break_index)\nprintln(\"Break location: \", result.break_fraction * 100, \"% of sample\")","category":"section"},{"location":"hypothesis_tests/#Function-Signature-4","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Options-4","page":"Unit Root & Cointegration","title":"Options","text":"Argument Description Default\nregression Break type: :constant, :trend, or :both :both\ntrim Trimming fraction for break search 0.15\nlags Augmenting lags, or :aic/:bic :aic\n\n","category":"section"},{"location":"hypothesis_tests/#Ng-Perron-Tests","page":"Unit Root & Cointegration","title":"Ng-Perron Tests","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-5","page":"Unit Root & Cointegration","title":"Theory","text":"The Ng-Perron tests (2001) are modified unit root tests with improved size and power properties, especially in small samples. They use GLS detrending and report four test statistics:\n\nMZα: Modified Phillips Zα statistic\nMZt: Modified Phillips Zt statistic (most commonly used)\nMSB: Modified Sargan-Bhargava statistic\nMPT: Modified Point-optimal statistic\n\nThe GLS detrending uses the quasi-difference:\n\ntildey_t = y_t - barcT cdot y_t-1\n\nwhere barc = -7 (constant) or barc = -135 (trend).\n\nAdvantage: Better size properties than ADF when the initial condition is far from zero.\n\nReference: Ng & Perron (2001)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-5","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\ny = cumsum(randn(100))\nresult = ngperron_test(y; regression=:constant)\n\n# All four statistics are reported\nprintln(\"MZα: \", result.MZa)\nprintln(\"MZt: \", result.MZt)\nprintln(\"MSB: \", result.MSB)\nprintln(\"MPT: \", result.MPT)","category":"section"},{"location":"hypothesis_tests/#Function-Signature-5","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Johansen-Cointegration-Test","page":"Unit Root & Cointegration","title":"Johansen Cointegration Test","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-6","page":"Unit Root & Cointegration","title":"Theory","text":"The Johansen test examines whether multiple I(1) series share common stochastic trends, i.e., are cointegrated. Consider a VAR(p) in levels:\n\ny_t = A_1 y_t-1 + cdots + A_p y_t-p + u_t\n\nThis can be rewritten in Vector Error Correction Model (VECM) form:\n\nDelta y_t = Pi y_t-1 + sum_i=1^p-1 Gamma_i Delta y_t-i + u_t\n\nwhere Pi = alpha beta is the long-run matrix:\n\nbeta: Cointegrating vectors (equilibrium relationships)\nalpha: Adjustment coefficients (speed of adjustment to equilibrium)\ntextrank(Pi) = r: Number of cointegrating relationships\n\nTwo test statistics are computed:\n\nTrace Test: Tests H_0 textrank leq r against H_1 textrank  r\n\nlambda_trace(r) = -T sum_i=r+1^n ln(1 - hatlambda_i)\n\nMaximum Eigenvalue Test: Tests H_0 textrank = r against H_1 textrank = r+1\n\nlambda_max(r) = -T ln(1 - hatlambda_r+1)\n\nReference: Johansen (1991), Osterwald-Lenum (1992)","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-6","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Generate cointegrated system\nT, n = 200, 3\nY = randn(T, n)\nY[:, 2] = Y[:, 1] + 0.1 * randn(T)  # Y2 cointegrated with Y1\nY[:, 3] = cumsum(randn(T))           # Y3 independent I(1)\n\n# Johansen test with 2 lags in VECM\nresult = johansen_test(Y, 2; deterministic=:constant)\n\n# Access results\nprintln(\"Estimated cointegration rank: \", result.rank)\nprintln(\"Cointegrating vectors:\\n\", result.eigenvectors[:, 1:result.rank])\nprintln(\"Adjustment coefficients:\\n\", result.adjustment)","category":"section"},{"location":"hypothesis_tests/#Function-Signature-6","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Options-5","page":"Unit Root & Cointegration","title":"Options","text":"Argument Description Default\np Lags in VECM representation Required\ndeterministic :none, :constant, or :trend :constant","category":"section"},{"location":"hypothesis_tests/#Interpreting-Results-3","page":"Unit Root & Cointegration","title":"Interpreting Results","text":"The test sequentially tests:\n\nH_0 r = 0 (no cointegration)\nH_0 r leq 1\nH_0 r leq 2, etc.\n\nStop at the first non-rejected hypothesis; that gives the cointegration rank.\n\n","category":"section"},{"location":"hypothesis_tests/#VAR-Stationarity-Check","page":"Unit Root & Cointegration","title":"VAR Stationarity Check","text":"","category":"section"},{"location":"hypothesis_tests/#Theory-7","page":"Unit Root & Cointegration","title":"Theory","text":"A VAR(p) model is stable (stationary) if and only if all eigenvalues of the companion matrix lie strictly inside the unit circle:\n\nF = beginbmatrix\nA_1  A_2  cdots  A_p-1  A_p \nI_n  0  cdots  0  0 \n0  I_n  cdots  0  0 \nvdots   ddots   vdots \n0  0  cdots  I_n  0\nendbmatrix\n\nStability Condition: lambda_i  1 for all eigenvalues lambda_i of F.\n\nIf violated, the VAR is explosive or contains unit roots, and standard asymptotic theory does not apply.","category":"section"},{"location":"hypothesis_tests/#Julia-Implementation-7","page":"Unit Root & Cointegration","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Estimate VAR\nY = randn(200, 3)\nmodel = fit(VARModel, Y, 2)\n\n# Check stationarity\nresult = is_stationary(model)\n\nif result.is_stationary\n    println(\"VAR is stationary\")\n    println(\"Maximum eigenvalue modulus: \", result.max_modulus)\nelse\n    println(\"WARNING: VAR is non-stationary!\")\n    println(\"Maximum eigenvalue modulus: \", result.max_modulus)\n    println(\"Consider differencing or VECM specification\")\nend","category":"section"},{"location":"hypothesis_tests/#Function-Signature-7","page":"Unit Root & Cointegration","title":"Function Signature","text":"","category":"section"},{"location":"hypothesis_tests/#Convenience-Functions","page":"Unit Root & Cointegration","title":"Convenience Functions","text":"","category":"section"},{"location":"hypothesis_tests/#Summary-of-Multiple-Tests","page":"Unit Root & Cointegration","title":"Summary of Multiple Tests","text":"using MacroEconometricModels\n\ny = cumsum(randn(200))\n\n# Run multiple tests and get summary\nsummary = unit_root_summary(y; tests=[:adf, :kpss, :pp])\n\n# Access individual results\nsummary.results[:adf]\nsummary.results[:kpss]\n\n# Overall conclusion\nprintln(summary.conclusion)","category":"section"},{"location":"hypothesis_tests/#Test-All-Variables","page":"Unit Root & Cointegration","title":"Test All Variables","text":"using MacroEconometricModels\n\nY = randn(200, 5)\nY[:, 1] = cumsum(Y[:, 1])  # Make first column non-stationary\n\n# Apply ADF test to all columns\nresults = test_all_variables(Y; test=:adf)\n\n# Check which variables have unit roots\nfor (i, r) in enumerate(results)\n    status = r.pvalue > 0.05 ? \"I(1)\" : \"I(0)\"\n    println(\"Variable $i: p=$(round(r.pvalue, digits=3)) → $status\")\nend","category":"section"},{"location":"hypothesis_tests/#Function-Signatures","page":"Unit Root & Cointegration","title":"Function Signatures","text":"","category":"section"},{"location":"hypothesis_tests/#Result-Types","page":"Unit Root & Cointegration","title":"Result Types","text":"All unit root test results inherit from AbstractUnitRootTest and implement the StatsAPI interface:\n\nusing StatsAPI\n\nresult = adf_test(y)\n\n# StatsAPI interface\nnobs(result)    # Number of observations\ndof(result)     # Degrees of freedom\npvalue(result)  # P-value","category":"section"},{"location":"hypothesis_tests/#Type-Hierarchy","page":"Unit Root & Cointegration","title":"Type Hierarchy","text":"All unit root test results inherit from AbstractUnitRootTest and implement the StatsAPI interface. See the API Reference for detailed type documentation.\n\nADFResult - Augmented Dickey-Fuller test result\nKPSSResult - KPSS stationarity test result\nPPResult - Phillips-Perron test result\nZAResult - Zivot-Andrews structural break test result\nNgPerronResult - Ng-Perron test result (MZα, MZt, MSB, MPT)\nJohansenResult - Johansen cointegration test result\nVARStationarityResult - VAR model stationarity check result\n\n","category":"section"},{"location":"hypothesis_tests/#Practical-Workflow","page":"Unit Root & Cointegration","title":"Practical Workflow","text":"","category":"section"},{"location":"hypothesis_tests/#Step-by-Step-Unit-Root-Analysis","page":"Unit Root & Cointegration","title":"Step-by-Step Unit Root Analysis","text":"using MacroEconometricModels\n\n# 1. Load/generate data\ny = your_time_series\n\n# 2. Visual inspection (plot the series)\n# Look for trends, structural breaks, etc.\n\n# 3. Test for unit root with ADF\nadf_result = adf_test(y; regression=:constant)\n\n# 4. Confirm with KPSS (opposite null)\nkpss_result = kpss_test(y; regression=:constant)\n\n# 5. If structural break suspected, use Zivot-Andrews\nza_result = za_test(y; regression=:both)\n\n# 6. For small samples, use Ng-Perron\nnp_result = ngperron_test(y; regression=:constant)\n\n# 7. Decision matrix\nif pvalue(adf_result) < 0.05 && pvalue(kpss_result) > 0.05\n    println(\"Series is stationary - proceed with VAR in levels\")\nelseif pvalue(adf_result) > 0.05 && pvalue(kpss_result) < 0.05\n    println(\"Series has unit root - consider differencing or VECM\")\nelse\n    println(\"Inconclusive - examine further or use robust methods\")\nend","category":"section"},{"location":"hypothesis_tests/#Pre-VAR-Analysis","page":"Unit Root & Cointegration","title":"Pre-VAR Analysis","text":"using MacroEconometricModels\n\n# Multi-variable dataset\nY = your_data_matrix\n\n# 1. Test each variable for unit root\nresults = test_all_variables(Y; test=:adf)\nn_nonstationary = sum(r.pvalue > 0.05 for r in results)\nprintln(\"Variables with unit roots: $n_nonstationary / $(size(Y, 2))\")\n\n# 2. If all I(1), test for cointegration\nif n_nonstationary == size(Y, 2)\n    johansen_result = johansen_test(Y, 2)\n\n    if johansen_result.rank > 0\n        println(\"Cointegration detected! Use VECM with rank=$(johansen_result.rank)\")\n    else\n        println(\"No cointegration - use VAR in first differences\")\n    end\nend\n\n# 3. If mixed I(0)/I(1), be cautious\n# Consider ARDL bounds test or transform I(1) variables\n\n","category":"section"},{"location":"hypothesis_tests/#References","page":"Unit Root & Cointegration","title":"References","text":"","category":"section"},{"location":"hypothesis_tests/#Unit-Root-Tests","page":"Unit Root & Cointegration","title":"Unit Root Tests","text":"Dickey, D. A., & Fuller, W. A. (1979). \"Distribution of the Estimators for Autoregressive Time Series with a Unit Root.\" Journal of the American Statistical Association, 74(366), 427-431.\nKwiatkowski, D., Phillips, P. C., Schmidt, P., & Shin, Y. (1992). \"Testing the Null Hypothesis of Stationarity Against the Alternative of a Unit Root.\" Journal of Econometrics, 54(1-3), 159-178.\nMacKinnon, J. G. (2010). \"Critical Values for Cointegration Tests.\" Queen's Economics Department Working Paper No. 1227.\nNg, S., & Perron, P. (2001). \"Lag Length Selection and the Construction of Unit Root Tests with Good Size and Power.\" Econometrica, 69(6), 1519-1554.\nPhillips, P. C., & Perron, P. (1988). \"Testing for a Unit Root in Time Series Regression.\" Biometrika, 75(2), 335-346.\nZivot, E., & Andrews, D. W. K. (1992). \"Further Evidence on the Great Crash, the Oil-Price Shock, and the Unit-Root Hypothesis.\" Journal of Business & Economic Statistics, 10(3), 251-270.","category":"section"},{"location":"hypothesis_tests/#Cointegration","page":"Unit Root & Cointegration","title":"Cointegration","text":"Johansen, S. (1991). \"Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models.\" Econometrica, 59(6), 1551-1580.\nJohansen, S. (1995). Likelihood-Based Inference in Cointegrated Vector Autoregressive Models. Oxford University Press.\nOsterwald-Lenum, M. (1992). \"A Note with Quantiles of the Asymptotic Distribution of the Maximum Likelihood Cointegration Rank Test Statistics.\" Oxford Bulletin of Economics and Statistics, 54(3), 461-472.","category":"section"},{"location":"hypothesis_tests/#Textbooks","page":"Unit Root & Cointegration","title":"Textbooks","text":"Hamilton, J. D. (1994). Time Series Analysis. Princeton University Press.\nLütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis. Springer.\nEnders, W. (2014). Applied Econometric Time Series (4th ed.). Wiley.","category":"section"},{"location":"hypothesis_tests/#MacroEconometricModels.adf_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.adf_test","text":"adf_test(y; lags=:aic, max_lags=nothing, regression=:constant) -> ADFResult\n\nAugmented Dickey-Fuller test for unit root.\n\nTests H₀: y has a unit root (non-stationary) against H₁: y is stationary.\n\nArguments\n\ny: Time series vector\nlags: Number of augmenting lags, or :aic/:bic/:hqic for automatic selection\nmax_lags: Maximum lags for automatic selection (default: floor(12*(T/100)^0.25))\nregression: Deterministic terms - :none, :constant (default), or :trend\n\nReturns\n\nADFResult containing test statistic, p-value, critical values, etc.\n\nExample\n\ny = cumsum(randn(200))  # Random walk (has unit root)\nresult = adf_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀\n\nReferences\n\nDickey, D. A., & Fuller, W. A. (1979). Distribution of the estimators for autoregressive time series with a unit root. JASA, 74(366), 427-431.\nMacKinnon, J. G. (2010). Critical values for cointegration tests. Queen's Economics Department Working Paper No. 1227.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.kpss_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.kpss_test","text":"kpss_test(y; regression=:constant, bandwidth=:auto) -> KPSSResult\n\nKwiatkowski-Phillips-Schmidt-Shin test for stationarity.\n\nTests H₀: y is stationary against H₁: y has a unit root.\n\nArguments\n\ny: Time series vector\nregression: :constant (level stationarity) or :trend (trend stationarity)\nbandwidth: Bartlett kernel bandwidth, or :auto for Newey-West selection\n\nReturns\n\nKPSSResult containing test statistic, p-value, critical values, etc.\n\nExample\n\ny = randn(200)  # Stationary series\nresult = kpss_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀ (stationarity)\n\nReferences\n\nKwiatkowski, D., Phillips, P. C., Schmidt, P., & Shin, Y. (1992). Testing the null hypothesis of stationarity against the alternative of a unit root. Journal of Econometrics, 54(1-3), 159-178.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.pp_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.pp_test","text":"pp_test(y; regression=:constant, bandwidth=:auto) -> PPResult\n\nPhillips-Perron test for unit root with non-parametric correction.\n\nTests H₀: y has a unit root against H₁: y is stationary.\n\nArguments\n\ny: Time series vector\nregression: :none, :constant (default), or :trend\nbandwidth: Newey-West bandwidth, or :auto for automatic selection\n\nReturns\n\nPPResult containing test statistic (Zt), p-value, critical values, etc.\n\nExample\n\ny = cumsum(randn(200))  # Random walk\nresult = pp_test(y)\nresult.pvalue > 0.05  # Should fail to reject H₀\n\nReferences\n\nPhillips, P. C., & Perron, P. (1988). Testing for a unit root in time series regression. Biometrika, 75(2), 335-346.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.za_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.za_test","text":"za_test(y; regression=:both, trim=0.15, lags=:aic, max_lags=nothing) -> ZAResult\n\nZivot-Andrews test for unit root with endogenous structural break.\n\nTests H₀: y has a unit root without break against H₁: y is stationary with break.\n\nArguments\n\ny: Time series vector\nregression: Type of break - :constant (intercept), :trend (slope), or :both\ntrim: Trimming fraction for break search (default 0.15)\nlags: Number of augmenting lags, or :aic/:bic for automatic selection\nmax_lags: Maximum lags for selection\n\nReturns\n\nZAResult containing minimum t-statistic, break point, p-value, etc.\n\nExample\n\n# Series with structural break\ny = vcat(randn(100), randn(100) .+ 2)\nresult = za_test(y; regression=:constant)\n\nReferences\n\nZivot, E., & Andrews, D. W. K. (1992). Further evidence on the great crash, the oil-price shock, and the unit-root hypothesis. JBES, 10(3), 251-270.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.ngperron_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.ngperron_test","text":"ngperron_test(y; regression=:constant) -> NgPerronResult\n\nNg-Perron unit root tests with GLS detrending (MZα, MZt, MSB, MPT).\n\nTests H₀: y has a unit root against H₁: y is stationary. These tests have better size properties than ADF/PP in small samples.\n\nArguments\n\ny: Time series vector\nregression: :constant (default) or :trend\n\nReturns\n\nNgPerronResult containing MZα, MZt, MSB, MPT statistics and critical values.\n\nExample\n\ny = cumsum(randn(100))\nresult = ngperron_test(y)\n# Check if MZt rejects at 5%\nresult.MZt < result.critical_values[:MZt][5]\n\nReferences\n\nNg, S., & Perron, P. (2001). Lag length selection and the construction of unit root tests with good size and power. Econometrica, 69(6), 1519-1554.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.johansen_test","page":"Unit Root & Cointegration","title":"MacroEconometricModels.johansen_test","text":"johansen_test(Y, p; deterministic=:constant) -> JohansenResult\n\nJohansen cointegration test for VAR system.\n\nTests for the number of cointegrating relationships among variables using trace and maximum eigenvalue tests.\n\nArguments\n\nY: Data matrix (T × n)\np: Number of lags in the VECM representation\ndeterministic: Specification for deterministic terms\n:none - No deterministic terms\n:constant - Constant in cointegrating relation (default)\n:trend - Linear trend in levels\n\nReturns\n\nJohansenResult containing trace and max-eigenvalue statistics, cointegrating vectors, adjustment coefficients, and estimated rank.\n\nExample\n\n# Generate cointegrated system\nn, T = 3, 200\nY = randn(T, n)\nY[:, 2] = Y[:, 1] + 0.1 * randn(T)  # Y2 cointegrated with Y1\n\nresult = johansen_test(Y, 2)\nresult.rank  # Should detect 1 or 2 cointegrating relations\n\nReferences\n\nJohansen, S. (1991). Estimation and hypothesis testing of cointegration vectors in Gaussian vector autoregressive models. Econometrica, 59(6), 1551-1580.\nOsterwald-Lenum, M. (1992). A note with quantiles of the asymptotic distribution of the ML cointegration rank test statistics. Oxford BEJM.\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.is_stationary","page":"Unit Root & Cointegration","title":"MacroEconometricModels.is_stationary","text":"is_stationary(model::VARModel) -> VARStationarityResult\n\nCheck if estimated VAR model is stationary.\n\nA VAR(p) is stationary if and only if all eigenvalues of the companion matrix have modulus strictly less than 1.\n\nReturns\n\nVARStationarityResult with:\n\nis_stationary: Boolean indicating stationarity\neigenvalues: Complex eigenvalues of companion matrix\nmax_modulus: Maximum eigenvalue modulus\ncompanion_matrix: The (np × np) companion form matrix\n\nExample\n\nmodel = estimate_var(Y, 2)\nresult = is_stationary(model)\nif !result.is_stationary\n    println(\"Warning: VAR is non-stationary, max modulus = \", result.max_modulus)\nend\n\n\n\n\n\nis_stationary(model::DynamicFactorModel) -> Bool\n\nCheck if factor dynamics are stationary (max |eigenvalue| < 1).\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.unit_root_summary","page":"Unit Root & Cointegration","title":"MacroEconometricModels.unit_root_summary","text":"unit_root_summary(y; tests=[:adf, :kpss, :pp], kwargs...) -> NamedTuple\n\nRun multiple unit root tests and return summary with PrettyTables output.\n\nArguments\n\ny: Time series vector\ntests: Vector of test symbols to run (default: [:adf, :kpss, :pp])\nkwargs...: Additional arguments passed to individual tests\n\nReturns\n\nNamedTuple with test results, conclusion, and summary table.\n\nExample\n\ny = cumsum(randn(200))\nsummary = unit_root_summary(y)\nsummary.conclusion  # Overall conclusion\n\n\n\n\n\n","category":"function"},{"location":"hypothesis_tests/#MacroEconometricModels.test_all_variables","page":"Unit Root & Cointegration","title":"MacroEconometricModels.test_all_variables","text":"test_all_variables(Y; test=:adf, kwargs...) -> Vector\n\nApply unit root test to each column of Y.\n\nArguments\n\nY: Data matrix (T × n)\ntest: Test to apply (:adf, :kpss, :pp, :za, :ngperron)\nkwargs...: Additional arguments passed to the test\n\nReturns\n\nVector of test results, one per variable.\n\nExample\n\nY = randn(200, 3)\nY[:, 1] = cumsum(Y[:, 1])  # Make first column non-stationary\nresults = test_all_variables(Y; test=:adf)\n[r.pvalue for r in results]  # P-values for each variable\n\n\n\n\n\n","category":"function"},{"location":"innovation_accounting/#Innovation-Accounting","page":"Innovation Accounting","title":"Innovation Accounting","text":"Innovation accounting refers to the collection of tools for analyzing the dynamic effects of structural shocks in VAR models. This includes Impulse Response Functions (IRF), Forecast Error Variance Decomposition (FEVD), and Historical Decomposition (HD).","category":"section"},{"location":"innovation_accounting/#Impulse-Response-Functions-(IRF)","page":"Innovation Accounting","title":"Impulse Response Functions (IRF)","text":"","category":"section"},{"location":"innovation_accounting/#Definition","page":"Innovation Accounting","title":"Definition","text":"The impulse response function Theta_h measures the effect of a one-unit structural shock at time t on the endogenous variables at time t+h:\n\nTheta_h = fracpartial y_t+hpartial varepsilon_t\n\nFor a VAR, the IRF at horizon h is computed recursively:\n\nTheta_h = sum_i=1^min(hp) A_i Theta_h-i\n\nwith Theta_0 = B_0 (the structural impact matrix).","category":"section"},{"location":"innovation_accounting/#Companion-Form-Representation","page":"Innovation Accounting","title":"Companion Form Representation","text":"Using the companion form, IRFs can be computed as:\n\nTheta_h = J F^h J B_0\n\nwhere J = I_n 0 ldots 0 is an n times np selection matrix and F is the companion matrix.","category":"section"},{"location":"innovation_accounting/#Cumulative-IRF","page":"Innovation Accounting","title":"Cumulative IRF","text":"The cumulative impulse response up to horizon H is:\n\nTheta^cum_H = sum_h=0^H Theta_h","category":"section"},{"location":"innovation_accounting/#Confidence-Intervals","page":"Innovation Accounting","title":"Confidence Intervals","text":"Bootstrap (Frequentist): Residual bootstrap of Kilian (1998):\n\nEstimate the VAR and save residuals hatu_t\nGenerate bootstrap sample by resampling residuals with replacement\nRe-estimate the VAR and compute IRFs\nRepeat B times to build the distribution\n\nCredible Intervals (Bayesian): For each MCMC draw, compute IRFs and report posterior quantiles (e.g., 16th and 84th percentiles for 68% intervals).","category":"section"},{"location":"innovation_accounting/#Usage","page":"Innovation Accounting","title":"Usage","text":"using MacroEconometricModels\n\nY = randn(200, 3)\nmodel = estimate_var(Y, 2)\n\n# Basic IRF (Cholesky identification)\nirf_result = irf(model, 20)\n\n# With bootstrap confidence intervals\nirf_ci = irf(model, 20; ci_type=:bootstrap, reps=1000)\n\n# Sign restrictions\nsign_constraints = [1 1 0; -1 0 0; 0 0 1]\nirf_sign = irf(model, 20; method=:sign, sign_restrictions=sign_constraints)\n\nReference: Kilian (1998), Lütkepohl (2005, Chapter 3)\n\n","category":"section"},{"location":"innovation_accounting/#Forecast-Error-Variance-Decomposition-(FEVD)","page":"Innovation Accounting","title":"Forecast Error Variance Decomposition (FEVD)","text":"","category":"section"},{"location":"innovation_accounting/#Definition-2","page":"Innovation Accounting","title":"Definition","text":"The FEVD measures the proportion of the h-step ahead forecast error variance of variable i attributable to structural shock j:\n\ntextFEVD_ij(h) = fracsum_s=0^h-1 (Theta_s)_ij^2sum_s=0^h-1 sum_k=1^n (Theta_s)_ik^2\n\nwhere (Theta_s)_ij is the (ij) element of the impulse response matrix at horizon s.","category":"section"},{"location":"innovation_accounting/#Properties","page":"Innovation Accounting","title":"Properties","text":"0 leq textFEVD_ij(h) leq 1 for all i j h\nsum_j=1^n textFEVD_ij(h) = 1 for all i h\nAs h to infty, FEVD converges to the unconditional variance decomposition","category":"section"},{"location":"innovation_accounting/#Usage-2","page":"Innovation Accounting","title":"Usage","text":"# Basic FEVD\nfevd_result = fevd(model, 20)\n\n# With bootstrap CI\nfevd_ci = fevd(model, 20; ci_type=:bootstrap, reps=500)\n\n# Access decomposition for variable 1\nfevd_var1 = fevd_result.decomposition[:, 1, :]  # horizons × shocks\n\nReference: Lütkepohl (2005, Section 2.3.3)\n\n","category":"section"},{"location":"innovation_accounting/#Historical-Decomposition-(HD)","page":"Innovation Accounting","title":"Historical Decomposition (HD)","text":"","category":"section"},{"location":"innovation_accounting/#Definition-3","page":"Innovation Accounting","title":"Definition","text":"Historical decomposition decomposes observed variable movements into contributions from individual structural shocks over time:\n\ny_t = sum_s=0^t-1 Theta_s varepsilon_t-s + textinitial conditions\n\nwhere:\n\nTheta_s = Phi_s P are structural moving average (MA) coefficients\nP = L Q is the impact matrix (Cholesky factor L times rotation Q)\nvarepsilon_t = Q L^-1 u_t are structural shocks","category":"section"},{"location":"innovation_accounting/#Contribution-of-Shock-j-to-Variable-i-at-Time-t","page":"Innovation Accounting","title":"Contribution of Shock j to Variable i at Time t","text":"textHD_ij(t) = sum_s=0^t-1 (Theta_s)_ij  varepsilon_j(t-s)\n\nThe decomposition satisfies the identity:\n\ny_t = sum_j=1^n textHD_ij(t) + textinitial_i(t)","category":"section"},{"location":"innovation_accounting/#Usage-3","page":"Innovation Accounting","title":"Usage","text":"# Basic historical decomposition\nhd = historical_decomposition(model, 198)\n\n# Verify decomposition identity\nverify_decomposition(hd)  # returns true if identity holds\n\n# Get contribution of shock 1 to variable 2\ncontrib = contribution(hd, 2, 1)\n\n# Total shock contribution (excluding initial conditions)\ntotal = total_shock_contribution(hd, 1)\n\n# With different identification\nhd_sign = historical_decomposition(model, 198; method=:sign,\n    sign_restrictions=sign_constraints)\n\nReference: Kilian & Lütkepohl (2017, Chapter 4)\n\n","category":"section"},{"location":"innovation_accounting/#Summary-Tables","page":"Innovation Accounting","title":"Summary Tables","text":"The package provides publication-quality summary tables using a unified interface with multiple dispatch.\n\nnote: Name conflict with Base.summary\nThe summary function may conflict with Base.summary. Use the fully qualified name MacroEconometricModels.summary(obj) or import explicitly with using MacroEconometricModels: summary.","category":"section"},{"location":"innovation_accounting/#Functions","page":"Innovation Accounting","title":"Functions","text":"Function Description\nsummary(obj) Print comprehensive summary to stdout\ntable(obj, ...) Extract results as a DataFrame\nprint_table(io, obj, ...) Print formatted table to IO stream","category":"section"},{"location":"innovation_accounting/#Usage-Examples","page":"Innovation Accounting","title":"Usage Examples","text":"using MacroEconometricModels\n\nY = randn(200, 3)\nmodel = estimate_var(Y, 2)\nirf_result = irf(model, 20)\nfevd_result = fevd(model, 20)\nhd_result = historical_decomposition(model, 198)\n\n# Print summaries (use fully qualified name to avoid Base.summary conflict)\nMacroEconometricModels.summary(model)\nMacroEconometricModels.summary(irf_result)\nMacroEconometricModels.summary(fevd_result)\nMacroEconometricModels.summary(hd_result)\n\n# Extract as DataFrames for further analysis\ndf_irf = table(irf_result, 1, 1)                    # response of var 1 to shock 1\ndf_irf_sel = table(irf_result, 1, 1; horizons=[1, 4, 8, 12, 20])\n\ndf_fevd = table(fevd_result, 1)                     # FEVD for variable 1\ndf_fevd_sel = table(fevd_result, 1; horizons=[1, 4, 8, 12])\n\ndf_hd = table(hd_result, 1)                         # HD for variable 1\ndf_hd_sel = table(hd_result, 1; periods=180:198)    # specific periods\n\n# Print formatted tables to stdout or file\nprint_table(stdout, irf_result, 1, 1; horizons=[1, 4, 8, 12])\nprint_table(stdout, fevd_result, 1; horizons=[1, 4, 8, 12])\nprint_table(stdout, hd_result, 1; periods=190:198)\n\n# Write to file\nopen(\"results.txt\", \"w\") do io\n    print_table(io, irf_result, 1, 1)\n    print_table(io, fevd_result, 1)\nend","category":"section"},{"location":"innovation_accounting/#String-Indexing","page":"Innovation Accounting","title":"String Indexing","text":"Variables and shocks can be indexed by name:\n\n# If variable names are set\ndf = table(irf_result, \"GDP\", \"Monetary Shock\")\ndf = table(fevd_result, \"Inflation\")\ndf = table(hd_result, \"Output\")\n\n","category":"section"},{"location":"innovation_accounting/#References","page":"Innovation Accounting","title":"References","text":"Kilian, L. (1998). \"Small-Sample Confidence Intervals for Impulse Response Functions.\" Review of Economics and Statistics, 80(2), 218-230.\nKilian, L., & Lütkepohl, H. (2017). Structural Vector Autoregressive Analysis. Cambridge University Press.\nLütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis. Springer.","category":"section"},{"location":"api_types/#api_types","page":"Types","title":"API Types","text":"This page documents all core types in MacroEconometricModels.jl.","category":"section"},{"location":"api_types/#Module","page":"Types","title":"Module","text":"","category":"section"},{"location":"api_types/#VAR-Models","page":"Types","title":"VAR Models","text":"","category":"section"},{"location":"api_types/#Impulse-Response-and-FEVD","page":"Types","title":"Impulse Response and FEVD","text":"","category":"section"},{"location":"api_types/#Historical-Decomposition","page":"Types","title":"Historical Decomposition","text":"","category":"section"},{"location":"api_types/#Factor-Models","page":"Types","title":"Factor Models","text":"","category":"section"},{"location":"api_types/#Local-Projections","page":"Types","title":"Local Projections","text":"","category":"section"},{"location":"api_types/#GMM-Types","page":"Types","title":"GMM Types","text":"","category":"section"},{"location":"api_types/#Prior-Types","page":"Types","title":"Prior Types","text":"","category":"section"},{"location":"api_types/#Unit-Root-Test-Types","page":"Types","title":"Unit Root Test Types","text":"","category":"section"},{"location":"api_types/#SVAR-Identification-Types","page":"Types","title":"SVAR Identification Types","text":"","category":"section"},{"location":"api_types/#Type-Hierarchy","page":"Types","title":"Type Hierarchy","text":"AbstractVARModel\n└── VARModel{T}\n\nAbstractImpulseResponse\n├── ImpulseResponse{T}\n├── BayesianImpulseResponse{T}\n└── AbstractLPImpulseResponse\n    └── LPImpulseResponse{T}\n\nAbstractFEVD\n├── FEVD{T}\n└── BayesianFEVD{T}\n\nAbstractHistoricalDecomposition\n├── HistoricalDecomposition{T}\n└── BayesianHistoricalDecomposition{T}\n\nAbstractFactorModel\n├── FactorModel{T}\n├── DynamicFactorModel{T}\n└── GeneralizedDynamicFactorModel{T}\n\nAbstractLPModel\n├── LPModel{T}\n├── LPIVModel{T}\n├── SmoothLPModel{T}\n├── StateLPModel{T}\n└── PropensityLPModel{T}\n\nAbstractCovarianceEstimator\n├── NeweyWestEstimator{T}\n├── WhiteEstimator\n└── DriscollKraayEstimator{T}\n\nAbstractGMMModel\n└── GMMModel{T}\n\nAbstractPrior\n└── MinnesotaHyperparameters{T}\n\nAbstractUnitRootTest <: StatsAPI.HypothesisTest\n├── ADFResult{T}\n├── KPSSResult{T}\n├── PPResult{T}\n├── ZAResult{T}\n├── NgPerronResult{T}\n└── JohansenResult{T}\n\nVARStationarityResult{T}","category":"section"},{"location":"api_types/#MacroEconometricModels.MacroEconometricModels","page":"Types","title":"MacroEconometricModels.MacroEconometricModels","text":"MacroEconometricModels\n\nA Julia package for macroeconomic time series analysis, providing tools for:\n\nVector Autoregression (VAR) estimation\nBayesian VAR (BVAR) with Minnesota priors\nStructural identification (Cholesky, sign restrictions, narrative, long-run)\nImpulse Response Functions (IRF)\nForecast Error Variance Decomposition (FEVD)\nFactor models via Principal Component Analysis\nLocal Projections (LP) with various extensions:\nHAC standard errors (Jordà 2005)\nInstrumental Variables (Stock & Watson 2018)\nSmooth IRF via B-splines (Barnichon & Brownlees 2019)\nState-dependent LP (Auerbach & Gorodnichenko 2013)\nPropensity Score Matching (Angrist et al. 2018)\nARIMA/ARMA model estimation, forecasting, and order selection\nGeneralized Method of Moments (GMM) estimation\n\nQuick Start\n\nusing MacroEconometricModels\n\n# Estimate a VAR model\nY = randn(100, 3)\nmodel = estimate_var(Y, 2)\n\n# Compute IRFs with bootstrap confidence intervals\nirf_result = irf(model, 20; ci_type=:bootstrap)\n\n# Local Projection IRFs with HAC standard errors\nlp_result = estimate_lp(Y, 1, 20; cov_type=:newey_west)\nlp_irf_result = lp_irf(lp_result)\n\n# Bayesian estimation\nchain = estimate_bvar(Y, 2; prior=:minnesota)\n\nReferences\n\nBańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions.\nLütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis.\nRubio-Ramírez, J. F., Waggoner, D. F., & Zha, T. (2010). Structural vector autoregressions.\nJordà, Ò. (2005). Estimation and Inference of Impulse Responses by Local Projections.\nStock, J. H., & Watson, M. W. (2018). Identification and Estimation of Dynamic Causal Effects.\nBarnichon, R., & Brownlees, C. (2019). Impulse Response Estimation by Smooth Local Projections.\nAuerbach, A. J., & Gorodnichenko, Y. (2013). Fiscal Multipliers in Recession and Expansion.\nAngrist, J. D., Jordà, Ò., & Kuersteiner, G. M. (2018). Semiparametric Estimates of Monetary Policy Effects.\n\n\n\n\n\n","category":"module"},{"location":"api_types/#MacroEconometricModels.VARModel","page":"Types","title":"MacroEconometricModels.VARModel","text":"VARModel{T} <: AbstractVARModel\n\nVAR model estimated via OLS.\n\nFields: Y (data), p (lags), B (coefficients), U (residuals), Sigma (covariance), aic, bic, hqic.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractVARModel","page":"Types","title":"MacroEconometricModels.AbstractVARModel","text":"Abstract supertype for Vector Autoregression models.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.ImpulseResponse","page":"Types","title":"MacroEconometricModels.ImpulseResponse","text":"ImpulseResponse{T} <: AbstractImpulseResponse\n\nIRF results with optional confidence intervals.\n\nFields: values (H×n×n), cilower, ciupper, horizon, variables, shocks, ci_type.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.BayesianImpulseResponse","page":"Types","title":"MacroEconometricModels.BayesianImpulseResponse","text":"BayesianImpulseResponse{T} <: AbstractImpulseResponse\n\nBayesian IRF with posterior quantiles.\n\nFields: quantiles (H×n×n×q), mean (H×n×n), horizon, variables, shocks, quantile_levels.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractImpulseResponse","page":"Types","title":"MacroEconometricModels.AbstractImpulseResponse","text":"Abstract supertype for impulse response function results.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.FEVD","page":"Types","title":"MacroEconometricModels.FEVD","text":"FEVD results: decomposition (n×n×H) and proportions.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.BayesianFEVD","page":"Types","title":"MacroEconometricModels.BayesianFEVD","text":"Bayesian FEVD with posterior quantiles.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractFEVD","page":"Types","title":"MacroEconometricModels.AbstractFEVD","text":"Abstract supertype for forecast error variance decomposition results.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.HistoricalDecomposition","page":"Types","title":"MacroEconometricModels.HistoricalDecomposition","text":"HistoricalDecomposition{T} <: AbstractHistoricalDecomposition\n\nFrequentist historical decomposition result.\n\nFields:\n\ncontributions: Shock contributions (Teff × nvars × n_shocks)\ninitial_conditions: Initial condition component (Teff × nvars)\nactual: Actual data values (Teff × nvars)\nshocks: Structural shocks (Teff × nshocks)\nT_eff: Effective number of time periods\nvariables: Variable names\nshock_names: Shock names\nmethod: Identification method used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.BayesianHistoricalDecomposition","page":"Types","title":"MacroEconometricModels.BayesianHistoricalDecomposition","text":"BayesianHistoricalDecomposition{T} <: AbstractHistoricalDecomposition\n\nBayesian historical decomposition with posterior quantiles.\n\nFields:\n\nquantiles: Contribution quantiles (Teff × nvars × nshocks × nquantiles)\nmean: Mean contributions (Teff × nvars × n_shocks)\ninitial_quantiles: Initial condition quantiles (Teff × nvars × n_quantiles)\ninitial_mean: Mean initial conditions (Teff × nvars)\nshocks_mean: Mean structural shocks (Teff × nshocks)\nactual: Actual data values (Teff × nvars)\nT_eff: Effective number of time periods\nvariables: Variable names\nshock_names: Shock names\nquantile_levels: Quantile levels (e.g., [0.16, 0.5, 0.84])\nmethod: Identification method used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractHistoricalDecomposition","page":"Types","title":"MacroEconometricModels.AbstractHistoricalDecomposition","text":"Abstract supertype for historical decomposition results.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.FactorModel","page":"Types","title":"MacroEconometricModels.FactorModel","text":"FactorModel{T} <: AbstractFactorModel\n\nStatic factor model via PCA: Xₜ = Λ Fₜ + eₜ.\n\nFields: X, factors, loadings, eigenvalues, explainedvariance, cumulativevariance, r, standardized.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.DynamicFactorModel","page":"Types","title":"MacroEconometricModels.DynamicFactorModel","text":"DynamicFactorModel{T} <: AbstractFactorModel\n\nDynamic factor model: Xₜ = Λ Fₜ + eₜ, Fₜ = Σᵢ Aᵢ Fₜ₋ᵢ + ηₜ.\n\nFields: X, factors, loadings, A (VAR coefficients), factorresiduals, Sigmaeta, Sigmae, eigenvalues, explainedvariance, cumulative_variance, r, p, method, standardized, converged, iterations, loglik.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.GeneralizedDynamicFactorModel","page":"Types","title":"MacroEconometricModels.GeneralizedDynamicFactorModel","text":"GeneralizedDynamicFactorModel{T} <: AbstractFactorModel\n\nGDFM with frequency-dependent loadings: Xₜ = χₜ + ξₜ.\n\nFields: X, factors, commoncomponent, idiosyncratic, loadingsspectral, spectraldensityX, spectraldensitychi, eigenvaluesspectral, frequencies, q (dynamic factors), r (static factors), bandwidth, kernel, standardized, varianceexplained.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractFactorModel","page":"Types","title":"MacroEconometricModels.AbstractFactorModel","text":"Abstract supertype for factor models (static and dynamic).\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractLPImpulseResponse","page":"Types","title":"MacroEconometricModels.AbstractLPImpulseResponse","text":"Abstract supertype for LP impulse response results.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractLPModel","page":"Types","title":"MacroEconometricModels.AbstractLPModel","text":"Abstract supertype for Local Projection models.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.BSplineBasis","page":"Types","title":"MacroEconometricModels.BSplineBasis","text":"BSplineBasis{T} <: Any\n\nB-spline basis for smooth LP (Barnichon & Brownlees 2019).\n\nFields:\n\ndegree: Spline degree (typically 3 for cubic)\nninteriorknots: Number of interior knots\nknots: Full knot vector including boundary knots\nbasismatrix: Precomputed basis matrix at horizon points (H+1 × nbasis)\nhorizons: Horizon points where basis is evaluated\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.LPIVModel","page":"Types","title":"MacroEconometricModels.LPIVModel","text":"LPIVModel{T} <: AbstractLPModel\n\nLocal Projection with Instrumental Variables (Stock & Watson 2018). Uses 2SLS estimation at each horizon.\n\nFields:\n\nY: Response data matrix\nshock_var: Index of endogenous shock variable\nresponse_vars: Indices of response variables\ninstruments: Instrument matrix (T × n_instruments)\nhorizon: Maximum horizon\nlags: Number of control lags\nB: 2SLS coefficient matrices per horizon\nresiduals: Residuals per horizon\nvcov: Robust covariance matrices per horizon\nfirststageF: First-stage F-statistics per horizon (for weak IV test)\nfirststagecoef: First-stage coefficients per horizon\nT_eff: Effective sample sizes\ncov_estimator: Covariance estimator used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.LPImpulseResponse","page":"Types","title":"MacroEconometricModels.LPImpulseResponse","text":"LPImpulseResponse{T} <: AbstractLPImpulseResponse\n\nLP-based impulse response function with confidence intervals from robust standard errors.\n\nFields:\n\nvalues: Point estimates (H+1 × n_response)\nci_lower: Lower CI bounds\nci_upper: Upper CI bounds\nse: Standard errors\nhorizon: Maximum horizon\nresponse_vars: Names of response variables\nshock_var: Name of shock variable\ncov_type: Covariance estimator type\nconf_level: Confidence level used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.LPModel","page":"Types","title":"MacroEconometricModels.LPModel","text":"LPModel{T} <: AbstractLPModel\n\nLocal Projection model estimated via OLS with robust standard errors (Jordà 2005).\n\nThe LP regression for horizon h:     y{t+h} = αh + βh * shockt + Γh * controlst + ε_{t+h}\n\nFields:\n\nY: Response data matrix (Tobs × nvars)\nshock_var: Index of shock variable in Y\nresponse_vars: Indices of response variables (default: all)\nhorizon: Maximum IRF horizon H\nlags: Number of control lags included\nB: Vector of coefficient matrices, one per horizon h=0,...,H\nresiduals: Vector of residual matrices per horizon\nvcov: Vector of robust covariance matrices per horizon\nT_eff: Effective sample sizes per horizon\ncov_estimator: Covariance estimator used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.PropensityLPModel","page":"Types","title":"MacroEconometricModels.PropensityLPModel","text":"PropensityLPModel{T} <: AbstractLPModel\n\nLocal Projection with Inverse Propensity Weighting (Angrist et al. 2018).\n\nEstimates Average Treatment Effect (ATE) at each horizon using IPW.\n\nFields:\n\nY: Response data matrix\ntreatment: Binary treatment indicator vector\nresponse_vars: Response variable indices\ncovariates: Covariate matrix for propensity model\nhorizon: Maximum horizon\npropensity_scores: Estimated propensity scores P(D=1|X)\nipw_weights: Inverse propensity weights\nB: IPW-weighted regression coefficients per horizon\nresiduals: Residuals per horizon\nvcov: Robust covariance matrices per horizon\nate: Average treatment effects per horizon (for each response var)\nate_se: Standard errors of ATE\nconfig: Propensity score configuration\nT_eff: Effective sample sizes\ncov_estimator: Covariance estimator used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.PropensityScoreConfig","page":"Types","title":"MacroEconometricModels.PropensityScoreConfig","text":"PropensityScoreConfig{T} <: Any\n\nConfiguration for propensity score estimation and IPW.\n\nFields:\n\nmethod: Propensity model (:logit, :probit)\ntrimming: (lower, upper) bounds for propensity scores\nnormalize: Normalize weights to sum to 1 within groups\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.SmoothLPModel","page":"Types","title":"MacroEconometricModels.SmoothLPModel","text":"SmoothLPModel{T} <: AbstractLPModel\n\nSmooth Local Projection with B-spline basis (Barnichon & Brownlees 2019).\n\nThe IRF is parameterized as: β(h) = Σj θj Bj(h) where Bj are B-spline basis functions.\n\nFields:\n\nY: Response data matrix\nshock_var: Shock variable index\nresponse_vars: Response variable indices\nhorizon: Maximum horizon\nlags: Number of control lags\nspline_basis: B-spline basis configuration\ntheta: Spline coefficients (nbasis × nresponse)\nvcov_theta: Covariance of theta (vectorized)\nlambda: Smoothing penalty parameter\nirfvalues: Smoothed IRF point estimates (H+1 × nresponse)\nirf_se: Standard errors of smoothed IRF\nresiduals: Pooled residuals\nT_eff: Effective sample size\ncov_estimator: Covariance estimator used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.StateLPModel","page":"Types","title":"MacroEconometricModels.StateLPModel","text":"StateLPModel{T} <: AbstractLPModel\n\nState-dependent Local Projection (Auerbach & Gorodnichenko 2013).\n\nModel: y{t+h} = F(zt)[αE + βE * shockt + ...] + (1-F(zt))[αR + βR * shock_t + ...]\n\nF(z) is a smooth transition function, typically logistic. State E = expansion (high z), State R = recession (low z).\n\nFields:\n\nY: Response data matrix\nshock_var: Shock variable index\nresponse_vars: Response variable indices\nhorizon: Maximum horizon\nlags: Number of control lags\nstate: StateTransition configuration\nB_expansion: Coefficients in expansion state (per horizon)\nB_recession: Coefficients in recession state (per horizon)\nresiduals: Residuals per horizon\nvcov_expansion: Covariance in expansion (per horizon)\nvcov_recession: Covariance in recession (per horizon)\nvcov_diff: Covariance of difference (per horizon)\nT_eff: Effective sample sizes\ncov_estimator: Covariance estimator used\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.StateTransition","page":"Types","title":"MacroEconometricModels.StateTransition","text":"StateTransition{T} <: Any\n\nSmooth state transition function for state-dependent LP.\n\nF(zt) = exp(-γ(zt - c)) / (1 + exp(-γ(z_t - c)))\n\nFields:\n\nstate_var: State variable values (standardized)\ngamma: Transition smoothness parameter (higher = sharper)\nthreshold: Transition threshold c\nmethod: Transition function type (:logistic, :exponential, :indicator)\nF_values: Precomputed transition function values\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractGMMModel","page":"Types","title":"MacroEconometricModels.AbstractGMMModel","text":"Abstract supertype for GMM models.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.GMMModel","page":"Types","title":"MacroEconometricModels.GMMModel","text":"GMMModel{T} <: AbstractGMMModel\n\nGeneralized Method of Moments estimator.\n\nMinimizes: g(θ)'W g(θ) where g(θ) = (1/n) Σᵢ gᵢ(θ)\n\nFields:\n\ntheta: Parameter estimates\nvcov: Asymptotic covariance matrix\nn_moments: Number of moment conditions\nn_params: Number of parameters\nn_obs: Number of observations\nweighting: Weighting specification\nW: Final weighting matrix\ng_bar: Sample moment vector at solution\nJ_stat: Hansen's J-test statistic\nJ_pvalue: p-value for J-test\nconverged: Convergence flag\niterations: Number of iterations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.GMMWeighting","page":"Types","title":"MacroEconometricModels.GMMWeighting","text":"GMMWeighting{T} <: Any\n\nGMM weighting matrix specification.\n\nFields:\n\nmethod: Weighting method (:identity, :optimal, :two_step, :iterated)\nmax_iter: Maximum iterations for iterated GMM\ntol: Convergence tolerance\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.MinnesotaHyperparameters","page":"Types","title":"MacroEconometricModels.MinnesotaHyperparameters","text":"MinnesotaHyperparameters{T} <: AbstractPrior\n\nMinnesota prior hyperparameters: tau (tightness), decay, lambda (sum-of-coef), mu (co-persistence), omega (covariance).\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractPrior","page":"Types","title":"MacroEconometricModels.AbstractPrior","text":"Abstract supertype for Bayesian prior specifications.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AbstractUnitRootTest","page":"Types","title":"MacroEconometricModels.AbstractUnitRootTest","text":"Abstract supertype for all unit root test results.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.ADFResult","page":"Types","title":"MacroEconometricModels.ADFResult","text":"ADFResult{T} <: AbstractUnitRootTest\n\nAugmented Dickey-Fuller test result.\n\nFields:\n\nstatistic: ADF test statistic (t-ratio on γ)\npvalue: Approximate p-value (MacKinnon 1994, 2010)\nlags: Number of augmenting lags used\nregression: Regression specification (:none, :constant, :trend)\ncritical_values: Critical values at 1%, 5%, 10% levels\nnobs: Effective number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.KPSSResult","page":"Types","title":"MacroEconometricModels.KPSSResult","text":"KPSSResult{T} <: AbstractUnitRootTest\n\nKPSS stationarity test result.\n\nFields:\n\nstatistic: KPSS test statistic\npvalue: Approximate p-value\nregression: Regression specification (:constant, :trend)\ncritical_values: Critical values at 1%, 5%, 10% levels\nbandwidth: Bartlett kernel bandwidth used\nnobs: Number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.PPResult","page":"Types","title":"MacroEconometricModels.PPResult","text":"PPResult{T} <: AbstractUnitRootTest\n\nPhillips-Perron test result.\n\nFields:\n\nstatistic: PP test statistic (Zt or Zα)\npvalue: Approximate p-value\nregression: Regression specification (:none, :constant, :trend)\ncritical_values: Critical values at 1%, 5%, 10% levels\nbandwidth: Newey-West bandwidth used\nnobs: Effective number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.ZAResult","page":"Types","title":"MacroEconometricModels.ZAResult","text":"ZAResult{T} <: AbstractUnitRootTest\n\nZivot-Andrews structural break unit root test result.\n\nFields:\n\nstatistic: Minimum t-statistic across all break points\npvalue: Approximate p-value\nbreak_index: Index of estimated structural break\nbreak_fraction: Break point as fraction of sample\nregression: Break specification (:constant, :trend, :both)\ncritical_values: Critical values at 1%, 5%, 10% levels\nlags: Number of augmenting lags\nnobs: Effective number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.NgPerronResult","page":"Types","title":"MacroEconometricModels.NgPerronResult","text":"NgPerronResult{T} <: AbstractUnitRootTest\n\nNg-Perron unit root test result (MZα, MZt, MSB, MPT).\n\nFields:\n\nMZa: Modified Zα statistic\nMZt: Modified Zt statistic\nMSB: Modified Sargan-Bhargava statistic\nMPT: Modified Point-optimal statistic\nregression: Regression specification (:constant, :trend)\ncritical_values: Dict mapping statistic name to critical values\nnobs: Effective number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.JohansenResult","page":"Types","title":"MacroEconometricModels.JohansenResult","text":"JohansenResult{T} <: AbstractUnitRootTest\n\nJohansen cointegration test result.\n\nFields:\n\ntrace_stats: Trace test statistics for each rank\ntrace_pvalues: P-values for trace tests\nmax_eigen_stats: Maximum eigenvalue test statistics\nmax_eigen_pvalues: P-values for max eigenvalue tests\nrank: Estimated cointegration rank (at 5% level)\neigenvectors: Cointegrating vectors (β), columns are vectors\nadjustment: Adjustment coefficients (α)\neigenvalues: Eigenvalues from reduced rank regression\ncritical_values_trace: Critical values for trace test (rows: ranks, cols: 10%, 5%, 1%)\ncritical_values_max: Critical values for max eigenvalue test\ndeterministic: Deterministic specification\nlags: Number of lags in VECM\nnobs: Effective number of observations\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.VARStationarityResult","page":"Types","title":"MacroEconometricModels.VARStationarityResult","text":"VARStationarityResult{T}\n\nVAR model stationarity check result.\n\nFields:\n\nis_stationary: true if all eigenvalues have modulus < 1\neigenvalues: Eigenvalues of companion matrix (may be real or complex)\nmax_modulus: Maximum eigenvalue modulus\ncompanion_matrix: The companion form matrix F\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.ZeroRestriction","page":"Types","title":"MacroEconometricModels.ZeroRestriction","text":"Zero restriction: variable doesn't respond to shock at horizon.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.SignRestriction","page":"Types","title":"MacroEconometricModels.SignRestriction","text":"Sign restriction: variable response to shock has required sign at horizon.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.SVARRestrictions","page":"Types","title":"MacroEconometricModels.SVARRestrictions","text":"Container for SVAR restrictions.\n\n\n\n\n\n","category":"type"},{"location":"api_types/#MacroEconometricModels.AriasSVARResult","page":"Types","title":"MacroEconometricModels.AriasSVARResult","text":"Result from Arias et al. (2018) identification.\n\n\n\n\n\n","category":"type"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"This chapter provides comprehensive worked examples demonstrating the main functionality of MacroEconometricModels.jl. Each example includes complete code, economic interpretation, and best practices.","category":"section"},{"location":"examples/#Example-1:-Three-Variable-VAR-Analysis","page":"Examples","title":"Example 1: Three-Variable VAR Analysis","text":"This example walks through a complete analysis of a macroeconomic VAR with GDP growth, inflation, and the federal funds rate.","category":"section"},{"location":"examples/#Setup-and-Data-Generation","page":"Examples","title":"Setup and Data Generation","text":"using MacroEconometricModels\nusing Random\nusing LinearAlgebra\nusing Statistics\n\nRandom.seed!(42)\n\n# Generate realistic macro data from a VAR(1) DGP\nT = 200\nn = 3\np = 2\n\n# True VAR(1) coefficients (persistent, cross-correlated)\nA_true = [0.85 0.10 -0.15;   # GDP responds to own lag, inflation, rate\n          0.05 0.70  0.00;   # Inflation mainly AR\n          0.10 0.20  0.80]   # Rate responds to GDP and inflation\n\n# Shock covariance (correlated shocks)\nΣ_true = [1.00 0.50 0.20;\n          0.50 0.80 0.10;\n          0.20 0.10 0.60]\n\n# Generate data\nY = zeros(T, n)\nY[1, :] = randn(n)\nchol_Σ = cholesky(Σ_true).L\n\nfor t in 2:T\n    Y[t, :] = A_true * Y[t-1, :] + chol_Σ * randn(n)\nend\n\nvar_names = [\"GDP Growth\", \"Inflation\", \"Fed Funds Rate\"]\nprintln(\"Data: T=$T observations, n=$n variables\")","category":"section"},{"location":"examples/#Frequentist-VAR-Estimation","page":"Examples","title":"Frequentist VAR Estimation","text":"# Estimate VAR(2) model via OLS\nmodel = fit(VARModel, Y, p)\n\n# Model diagnostics\nprintln(\"Log-likelihood: \", loglikelihood(model))\nprintln(\"AIC: \", aic(model))\nprintln(\"BIC: \", bic(model))\n\n# Check stability (eigenvalues inside unit circle)\nF = companion_matrix(model.B, n, p)\neigenvalues = eigvals(F)\nprintln(\"Max eigenvalue modulus: \", maximum(abs.(eigenvalues)))\nprintln(\"Stable: \", maximum(abs.(eigenvalues)) < 1)","category":"section"},{"location":"examples/#Cholesky-Identified-IRF","page":"Examples","title":"Cholesky-Identified IRF","text":"# Compute 20-period IRF with Cholesky identification\n# Ordering: GDP → Inflation → Rate (contemporaneous causality)\nH = 20\nirfs = irf(model, H; method=:cholesky)\n\n# Display impact responses (horizon 0)\nprintln(\"\\nImpact responses (B₀):\")\nprintln(\"  GDP shock → GDP: \", round(irfs.irf[1, 1, 1], digits=3))\nprintln(\"  GDP shock → Inflation: \", round(irfs.irf[1, 2, 1], digits=3))\nprintln(\"  GDP shock → Rate: \", round(irfs.irf[1, 3, 1], digits=3))\n\n# Long-run responses (horizon H)\nprintln(\"\\nLong-run responses (h=$H):\")\nprintln(\"  GDP shock → GDP: \", round(irfs.irf[H+1, 1, 1], digits=3))","category":"section"},{"location":"examples/#Sign-Restriction-Identification","page":"Examples","title":"Sign Restriction Identification","text":"# Sign restrictions: Demand shock raises GDP and inflation on impact\nfunction check_demand_shock(irf_array)\n    # irf_array is (H+1) × n × n\n    # Check: Shock 1 → Variable 1 (GDP) positive\n    #        Shock 1 → Variable 2 (Inflation) positive\n    return irf_array[1, 1, 1] > 0 && irf_array[1, 2, 1] > 0\nend\n\n# Estimate with sign restrictions\nirfs_sign = irf(model, H; method=:sign, check_func=check_demand_shock, n_draws=1000)\n\nprintln(\"\\nSign-identified demand shock:\")\nprintln(\"  GDP response: \", round(irfs_sign.irf[1, 1, 1], digits=3))\nprintln(\"  Inflation response: \", round(irfs_sign.irf[1, 2, 1], digits=3))","category":"section"},{"location":"examples/#Forecast-Error-Variance-Decomposition","page":"Examples","title":"Forecast Error Variance Decomposition","text":"# Compute FEVD\nfevd_result = fevd(model, H; method=:cholesky)\n\n# Variance decomposition at horizon 1, 4, and 20\nfor h in [1, 4, 20]\n    println(\"\\nFEVD at horizon $h:\")\n    for i in 1:n\n        println(\"  $(var_names[i]):\")\n        for j in 1:n\n            pct = round(fevd_result.fevd[h, i, j] * 100, digits=1)\n            println(\"    Shock $j: $pct%\")\n        end\n    end\nend\n\n","category":"section"},{"location":"examples/#Example-2:-Bayesian-VAR-with-Minnesota-Prior","page":"Examples","title":"Example 2: Bayesian VAR with Minnesota Prior","text":"This example demonstrates Bayesian estimation with automatic hyperparameter optimization.","category":"section"},{"location":"examples/#Hyperparameter-Optimization","page":"Examples","title":"Hyperparameter Optimization","text":"using MacroEconometricModels\n\n# Find optimal shrinkage using marginal likelihood (Giannone et al. 2015)\nprintln(\"Optimizing hyperparameters...\")\nbest_hyper = optimize_hyperparameters(Y, p; grid_size=20)\n\nprintln(\"Optimal hyperparameters:\")\nprintln(\"  τ (overall tightness): \", round(best_hyper.tau, digits=4))\nprintln(\"  d (lag decay): \", best_hyper.d)","category":"section"},{"location":"examples/#BVAR-Estimation-with-MCMC","page":"Examples","title":"BVAR Estimation with MCMC","text":"# Estimate BVAR with optimized Minnesota prior\nprintln(\"\\nEstimating BVAR with MCMC...\")\nchain = estimate_bvar(Y, p;\n    n_samples = 2000,\n    n_adapts = 500,\n    prior = :minnesota,\n    hyper = best_hyper\n)\n\n# Posterior summary (coefficients from first equation)\nprintln(\"\\nPosterior summary for GDP equation:\")\n# Access posterior draws and compute statistics","category":"section"},{"location":"examples/#Bayesian-IRF-with-Credible-Intervals","page":"Examples","title":"Bayesian IRF with Credible Intervals","text":"# Bayesian IRF with Cholesky identification\nbirf_chol = irf(chain, p, n, H; method=:cholesky)\n\n# Extract median and 68% credible intervals\n# birf_chol.quantiles is (H+1) × n × n × 3 array\n# [:, :, :, 1] = 16th percentile\n# [:, :, :, 2] = median\n# [:, :, :, 3] = 84th percentile\n\nprintln(\"\\nBayesian IRF of GDP to own shock:\")\nfor h in [0, 4, 8, 12, 20]\n    med = round(birf_chol.quantiles[h+1, 1, 1, 2], digits=3)\n    lo = round(birf_chol.quantiles[h+1, 1, 1, 1], digits=3)\n    hi = round(birf_chol.quantiles[h+1, 1, 1, 3], digits=3)\n    println(\"  h=$h: $med [$lo, $hi]\")\nend","category":"section"},{"location":"examples/#Bayesian-Sign-Restrictions","page":"Examples","title":"Bayesian Sign Restrictions","text":"# Bayesian IRF with sign restrictions\nbirf_sign = irf(chain, p, n, H;\n    method = :sign,\n    check_func = check_demand_shock\n)\n\nprintln(\"\\nBayesian sign-restricted demand shock → GDP:\")\nfor h in [0, 4, 8, 12]\n    med = round(birf_sign.quantiles[h+1, 1, 1, 2], digits=3)\n    lo = round(birf_sign.quantiles[h+1, 1, 1, 1], digits=3)\n    hi = round(birf_sign.quantiles[h+1, 1, 1, 3], digits=3)\n    println(\"  h=$h: $med [$lo, $hi]\")\nend\n\n","category":"section"},{"location":"examples/#Example-3:-Local-Projections","page":"Examples","title":"Example 3: Local Projections","text":"This example demonstrates various LP methods for estimating impulse responses.","category":"section"},{"location":"examples/#Standard-Local-Projection","page":"Examples","title":"Standard Local Projection","text":"using MacroEconometricModels\n\n# Estimate LP-IRF with Newey-West standard errors\nH = 20\nshock_var = 1  # GDP as the shock variable\n\nlp_model = estimate_lp(Y, shock_var, H;\n    lags = 4,\n    cov_type = :newey_west,\n    bandwidth = 0  # Automatic bandwidth selection\n)\n\n# Extract IRF with confidence intervals\nlp_result = lp_irf(lp_model; conf_level = 0.95)\n\nprintln(\"LP-IRF of shock to variable 1 → variable 1:\")\nfor h in 0:4:H\n    val = round(lp_result.values[h+1, 1], digits=3)\n    se = round(lp_result.se[h+1, 1], digits=3)\n    println(\"  h=$h: $val (SE: $se)\")\nend","category":"section"},{"location":"examples/#LP-with-Instrumental-Variables","page":"Examples","title":"LP with Instrumental Variables","text":"# Generate external instrument (e.g., monetary policy shock proxy)\nRandom.seed!(123)\nZ = 0.5 * Y[:, 3] + randn(T, 1)  # Correlated with rate but exogenous\n\n# Estimate LP-IV\nshock_var = 3  # Instrument for rate shock\nlpiv_model = estimate_lp_iv(Y, shock_var, Z, H;\n    lags = 4,\n    cov_type = :newey_west\n)\n\n# Check instrument strength\nweak_test = weak_instrument_test(lpiv_model; threshold = 10.0)\nprintln(\"\\nFirst-stage F-statistics by horizon:\")\nfor h in 0:4:H\n    F = round(weak_test.F_stats[h+1], digits=2)\n    status = F > 10 ? \"✓\" : \"⚠ weak\"\n    println(\"  h=$h: F=$F $status\")\nend\nprintln(\"All horizons pass F>10: \", weak_test.passes_threshold)\n\n# Extract IRF\nlpiv_result = lp_iv_irf(lpiv_model)","category":"section"},{"location":"examples/#Smooth-Local-Projection","page":"Examples","title":"Smooth Local Projection","text":"# Estimate smooth LP with B-splines\nsmooth_model = estimate_smooth_lp(Y, 1, H;\n    degree = 3,      # Cubic splines\n    n_knots = 4,     # Interior knots\n    lambda = 1.0,    # Smoothing parameter\n    lags = 4\n)\n\n# Cross-validate lambda\noptimal_lambda = cross_validate_lambda(Y, 1, H;\n    lambda_grid = 10.0 .^ (-4:0.5:2),\n    k_folds = 5\n)\nprintln(\"\\nOptimal smoothing parameter: \", round(optimal_lambda, digits=4))\n\n# Compare standard vs smooth LP\ncomparison = compare_smooth_lp(Y, 1, H; lambda = optimal_lambda)\nprintln(\"Variance reduction ratio: \", round(comparison.variance_reduction, digits=3))","category":"section"},{"location":"examples/#State-Dependent-Local-Projection","page":"Examples","title":"State-Dependent Local Projection","text":"# Construct state variable (moving average of GDP growth)\ngdp_level = cumsum(Y[:, 1])  # Integrate growth to get level\ngdp_growth = [NaN; diff(gdp_level)]\n\n# 4-period moving average, standardized\nstate_var = zeros(T)\nfor t in 4:T\n    state_var[t] = mean(Y[t-3:t, 1])\nend\nstate_var = (state_var .- mean(state_var[4:end])) ./ std(state_var[4:end])\n\n# Estimate state-dependent LP\nstate_model = estimate_state_lp(Y, 1, state_var, H;\n    gamma = 1.5,           # Transition speed\n    threshold = :median,    # Threshold at median\n    lags = 4\n)\n\n# Extract regime-specific IRFs\nirf_both = state_irf(state_model; regime = :both)\n\nprintln(\"\\nState-dependent IRFs (shock 1 → variable 1):\")\nprintln(\"Expansion vs Recession comparison:\")\nfor h in [0, 4, 8, 12]\n    exp_val = round(irf_both.expansion.values[h+1, 1], digits=3)\n    rec_val = round(irf_both.recession.values[h+1, 1], digits=3)\n    diff = round(exp_val - rec_val, digits=3)\n    println(\"  h=$h: Expansion=$exp_val, Recession=$rec_val, Diff=$diff\")\nend\n\n# Test for regime differences\ndiff_test = test_regime_difference(state_model)\nprintln(\"\\nJoint test for regime differences:\")\nprintln(\"  Average |t|: \", round(diff_test.joint_test.avg_t_stat, digits=2))\nprintln(\"  p-value: \", round(diff_test.joint_test.p_value, digits=4))\n\n","category":"section"},{"location":"examples/#Example-4:-Factor-Model-for-Large-Panels","page":"Examples","title":"Example 4: Factor Model for Large Panels","text":"This example demonstrates factor extraction and selection from a large macroeconomic panel.","category":"section"},{"location":"examples/#Simulate-Large-Panel-Data","page":"Examples","title":"Simulate Large Panel Data","text":"using MacroEconometricModels\nusing Random\nusing Statistics\n\nRandom.seed!(42)\n\n# Panel dimensions\nT = 150   # Time periods\nN = 50    # Variables\nr_true = 3  # True number of factors\n\n# Generate true factors (with persistence)\nF_true = zeros(T, r_true)\nfor j in 1:r_true\n    F_true[1, j] = randn()\n    for t in 2:T\n        F_true[t, j] = 0.8 * F_true[t-1, j] + 0.3 * randn()\n    end\nend\n\n# Factor loadings (sparse structure)\nΛ_true = randn(N, r_true)\n# Make first 15 vars load strongly on factor 1, etc.\nΛ_true[1:15, 1] .*= 2\nΛ_true[16:30, 2] .*= 2\nΛ_true[31:45, 3] .*= 2\n\n# Generate panel\nX = F_true * Λ_true' + 0.5 * randn(T, N)\n\nprintln(\"Panel: T=$T, N=$N, true r=$r_true\")","category":"section"},{"location":"examples/#Determine-Number-of-Factors","page":"Examples","title":"Determine Number of Factors","text":"# Bai-Ng information criteria\nr_max = 10\nic = ic_criteria(X, r_max)\n\nprintln(\"\\nBai-Ng information criteria:\")\nprintln(\"  IC1 selects: \", ic.r_IC1, \" factors\")\nprintln(\"  IC2 selects: \", ic.r_IC2, \" factors\")\nprintln(\"  IC3 selects: \", ic.r_IC3, \" factors\")\nprintln(\"  (True: $r_true factors)\")\n\n# IC values for each r\nprintln(\"\\nIC values by number of factors:\")\nfor r in 1:r_max\n    println(\"  r=$r: IC1=$(round(ic.IC1[r], digits=4)), IC2=$(round(ic.IC2[r], digits=4))\")\nend","category":"section"},{"location":"examples/#Estimate-Factor-Model","page":"Examples","title":"Estimate Factor Model","text":"# Use IC2's recommendation\nr_opt = ic.r_IC2\n\n# Estimate factor model\nfm = estimate_factors(X, r_opt; standardize = true)\n\nprintln(\"\\nEstimated factor model:\")\nprintln(\"  Number of factors: \", fm.r)\nprintln(\"  Factors dimension: \", size(fm.factors))\nprintln(\"  Loadings dimension: \", size(fm.loadings))\n\n# Variance explained\nprintln(\"\\nVariance explained:\")\nfor j in 1:r_opt\n    pct = round(fm.explained_variance[j] * 100, digits=1)\n    cum = round(fm.cumulative_variance[j] * 100, digits=1)\n    println(\"  Factor $j: $pct% (cumulative: $cum%)\")\nend","category":"section"},{"location":"examples/#Model-Diagnostics","page":"Examples","title":"Model Diagnostics","text":"# R² for each variable\nr2_vals = r2(fm)\n\nprintln(\"\\nR² statistics:\")\nprintln(\"  Mean: \", round(mean(r2_vals), digits=3))\nprintln(\"  Median: \", round(median(r2_vals), digits=3))\nprintln(\"  Min: \", round(minimum(r2_vals), digits=3))\nprintln(\"  Max: \", round(maximum(r2_vals), digits=3))\n\n# Variables well-explained (R² > 0.5)\nwell_explained = sum(r2_vals .> 0.5)\nprintln(\"  Variables with R² > 0.5: $well_explained / $N\")\n\n# Factor-true factor correlation (up to rotation)\nprintln(\"\\nFactor recovery (correlation with true factors):\")\nfor j in 1:r_opt\n    cors = [abs(cor(fm.factors[:, j], F_true[:, k])) for k in 1:r_true]\n    best_match = argmax(cors)\n    println(\"  Estimated factor $j matches true factor $best_match: r=$(round(cors[best_match], digits=3))\")\nend\n\n","category":"section"},{"location":"examples/#Example-5:-GMM-Estimation","page":"Examples","title":"Example 5: GMM Estimation","text":"This example demonstrates GMM estimation of a simple model with moment conditions.","category":"section"},{"location":"examples/#Define-Moment-Conditions","page":"Examples","title":"Define Moment Conditions","text":"using MacroEconometricModels\n\n# Example: IV regression via GMM\n# Model: y = x'β + ε\n# Moment conditions: E[z(y - x'β)] = 0\n\n# Generate data with endogeneity\nRandom.seed!(42)\nn_obs = 500\nn_params = 2\n\n# Instruments\nZ = randn(n_obs, 3)\n\n# Endogenous regressor (correlated with error)\nu = randn(n_obs)\nX = hcat(ones(n_obs), Z[:, 1] + 0.5 * u + 0.2 * randn(n_obs))\n\n# Outcome\nβ_true = [1.0, 2.0]\nY = X * β_true + u\n\n# Data bundle\ndata = (Y = Y, X = X, Z = hcat(ones(n_obs), Z))\n\n# Moment function: E[Z'(Y - Xβ)] = 0\nfunction moment_conditions(theta, data)\n    residuals = data.Y - data.X * theta\n    data.Z .* residuals  # n_obs × n_moments matrix\nend","category":"section"},{"location":"examples/#GMM-Estimation","page":"Examples","title":"GMM Estimation","text":"# Initial values\ntheta0 = zeros(n_params)\n\n# Two-step efficient GMM\ngmm_result = estimate_gmm(moment_conditions, theta0, data;\n    weighting = :two_step,\n    hac = true\n)\n\nprintln(\"GMM Estimation Results:\")\nprintln(\"  True β: \", β_true)\nprintln(\"  Estimated β: \", round.(gmm_result.theta, digits=4))\nprintln(\"  Converged: \", gmm_result.converged)\nprintln(\"  Iterations: \", gmm_result.iterations)\n\n# Standard errors\nse = sqrt.(diag(gmm_result.vcov))\nprintln(\"\\n  Standard errors: \", round.(se, digits=4))\n\n# Confidence intervals\nz = 1.96\nfor i in 1:n_params\n    lo = round(gmm_result.theta[i] - z * se[i], digits=4)\n    hi = round(gmm_result.theta[i] + z * se[i], digits=4)\n    println(\"  β[$i]: 95% CI = [$lo, $hi]\")\nend","category":"section"},{"location":"examples/#J-Test-for-Overidentification","page":"Examples","title":"J-Test for Overidentification","text":"# Test overidentifying restrictions\nj_result = j_test(gmm_result)\n\nprintln(\"\\nHansen J-test:\")\nprintln(\"  J-statistic: \", round(j_result.J_stat, digits=4))\nprintln(\"  Degrees of freedom: \", j_result.df)\nprintln(\"  p-value: \", round(j_result.p_value, digits=4))\nprintln(\"  Reject at 5%: \", j_result.reject_05)\n\n","category":"section"},{"location":"examples/#Example-6:-Complete-Workflow","page":"Examples","title":"Example 6: Complete Workflow","text":"This example shows a complete empirical workflow combining multiple techniques.\n\nusing MacroEconometricModels\nusing Random\nusing Statistics\n\nRandom.seed!(2024)\n\n# === Step 1: Data Preparation ===\nT, n = 200, 4\nY = randn(T, n)\nfor t in 2:T\n    Y[t, :] = 0.6 * Y[t-1, :] + 0.3 * randn(n)\nend\nvar_names = [\"Output\", \"Inflation\", \"Rate\", \"Exchange Rate\"]\n\n# === Step 2: Lag Selection ===\nprintln(\"=\"^50)\nprintln(\"Step 1: Lag Selection\")\nprintln(\"=\"^50)\n\naics = Float64[]\nbics = Float64[]\nfor p in 1:8\n    m = fit(VARModel, Y, p)\n    push!(aics, aic(m))\n    push!(bics, bic(m))\nend\np_aic = argmin(aics)\np_bic = argmin(bics)\nprintln(\"AIC selects p=$p_aic, BIC selects p=$p_bic\")\np = p_bic  # Use BIC's conservative choice\n\n# === Step 3: VAR Estimation ===\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"Step 2: VAR Estimation\")\nprintln(\"=\"^50)\n\nmodel = fit(VARModel, Y, p)\nprintln(\"Estimated VAR($p)\")\nprintln(\"Log-likelihood: \", round(loglikelihood(model), digits=2))\n\n# === Step 4: Frequentist IRF ===\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"Step 3: Impulse Response Analysis\")\nprintln(\"=\"^50)\n\nH = 20\nirfs = irf(model, H; method=:cholesky)\nfevd_res = fevd(model, H; method=:cholesky)\n\n# === Step 5: Bayesian Estimation ===\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"Step 4: Bayesian Analysis\")\nprintln(\"=\"^50)\n\n# Optimize priors\nbest_hyper = optimize_hyperparameters(Y, p; grid_size=15)\nprintln(\"Optimal τ: \", round(best_hyper.tau, digits=4))\n\n# BVAR with MCMC\nchain = estimate_bvar(Y, p; n_samples=1000, n_adapts=300,\n                      prior=:minnesota, hyper=best_hyper)\n\n# Bayesian IRF\nbirf = irf(chain, p, n, H; method=:cholesky)\n\n# === Step 6: Local Projections Comparison ===\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"Step 5: LP vs VAR Comparison\")\nprintln(\"=\"^50)\n\nlp_model = estimate_lp(Y, 1, H; lags=p, cov_type=:newey_west)\nlp_result = lp_irf(lp_model)\n\nprintln(\"IRF(1→1) at h=0:\")\nprintln(\"  VAR: \", round(irfs.irf[1, 1, 1], digits=3))\nprintln(\"  LP: \", round(lp_result.values[1, 1], digits=3))\n\nprintln(\"\\nIRF(1→1) at h=8:\")\nprintln(\"  VAR: \", round(irfs.irf[9, 1, 1], digits=3))\nprintln(\"  LP: \", round(lp_result.values[9, 1], digits=3))\n\n# === Step 7: Robustness Check with Smooth LP ===\nsmooth_lp = estimate_smooth_lp(Y, 1, H; lambda=1.0, lags=p)\nsmooth_result = smooth_lp_irf(smooth_lp)\n\nprintln(\"\\nSmooth LP variance reduction: \",\n        round(mean(smooth_result.se.^2) / mean(lp_result.se.^2), digits=3))\n\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"Analysis Complete!\")\nprintln(\"=\"^50)\n\n","category":"section"},{"location":"examples/#Example-7:-Unit-Root-Testing-and-Pre-Estimation-Analysis","page":"Examples","title":"Example 7: Unit Root Testing and Pre-Estimation Analysis","text":"This example demonstrates comprehensive unit root testing before fitting VAR models.","category":"section"},{"location":"examples/#Individual-Unit-Root-Tests","page":"Examples","title":"Individual Unit Root Tests","text":"using MacroEconometricModels\nusing Random\nusing Statistics\n\nRandom.seed!(42)\n\n# Generate data: mix of I(0) and I(1) series\nT = 200\ny_stationary = randn(T)                      # I(0): stationary\ny_random_walk = cumsum(randn(T))             # I(1): unit root\ny_trend_stat = 0.1 .* (1:T) .+ randn(T)      # Trend stationary\ny_with_break = vcat(randn(100), randn(100) .+ 2)  # Structural break\n\n# === ADF Test ===\nprintln(\"=\"^60)\nprintln(\"ADF Test (H₀: unit root)\")\nprintln(\"=\"^60)\n\nadf_stat = adf_test(y_stationary; lags=:aic, regression=:constant)\nprintln(\"\\nStationary series:\")\nprintln(\"  Statistic: \", round(adf_stat.statistic, digits=3))\nprintln(\"  P-value: \", round(adf_stat.pvalue, digits=4))\nprintln(\"  Lags: \", adf_stat.lags)\n\nadf_rw = adf_test(y_random_walk; lags=:aic, regression=:constant)\nprintln(\"\\nRandom walk:\")\nprintln(\"  Statistic: \", round(adf_rw.statistic, digits=3))\nprintln(\"  P-value: \", round(adf_rw.pvalue, digits=4))","category":"section"},{"location":"examples/#KPSS-Complementary-Test","page":"Examples","title":"KPSS Complementary Test","text":"# === KPSS Test ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"KPSS Test (H₀: stationarity)\")\nprintln(\"=\"^60)\n\nkpss_stat = kpss_test(y_stationary; regression=:constant)\nprintln(\"\\nStationary series:\")\nprintln(\"  Statistic: \", round(kpss_stat.statistic, digits=4))\nprintln(\"  P-value: \", kpss_stat.pvalue > 0.10 ? \">0.10\" : round(kpss_stat.pvalue, digits=4))\nprintln(\"  Bandwidth: \", kpss_stat.bandwidth)\n\nkpss_rw = kpss_test(y_random_walk; regression=:constant)\nprintln(\"\\nRandom walk:\")\nprintln(\"  Statistic: \", round(kpss_rw.statistic, digits=4))\nprintln(\"  P-value: \", kpss_rw.pvalue < 0.01 ? \"<0.01\" : round(kpss_rw.pvalue, digits=4))","category":"section"},{"location":"examples/#Combining-ADF-and-KPSS-for-Robust-Inference","page":"Examples","title":"Combining ADF and KPSS for Robust Inference","text":"# === Combined Analysis ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Combined ADF + KPSS Analysis\")\nprintln(\"=\"^60)\n\nfunction unit_root_decision(y; name=\"Series\")\n    adf = adf_test(y; lags=:aic)\n    kpss = kpss_test(y)\n\n    adf_reject = adf.pvalue < 0.05  # Reject unit root\n    kpss_reject = kpss.pvalue < 0.05  # Reject stationarity\n\n    decision = if adf_reject && !kpss_reject\n        \"I(0) - Stationary\"\n    elseif !adf_reject && kpss_reject\n        \"I(1) - Unit root\"\n    elseif adf_reject && kpss_reject\n        \"Conflicting (possible structural break)\"\n    else\n        \"Inconclusive\"\n    end\n\n    println(\"\\n$name:\")\n    println(\"  ADF p-value: \", round(adf.pvalue, digits=4))\n    println(\"  KPSS p-value: \", round(kpss.pvalue, digits=4))\n    println(\"  Decision: $decision\")\n\n    return decision\nend\n\nunit_root_decision(y_stationary; name=\"Stationary series\")\nunit_root_decision(y_random_walk; name=\"Random walk\")\nunit_root_decision(y_trend_stat; name=\"Trend stationary\")","category":"section"},{"location":"examples/#Testing-for-Structural-Breaks","page":"Examples","title":"Testing for Structural Breaks","text":"# === Zivot-Andrews Test ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Zivot-Andrews Test (H₀: unit root without break)\")\nprintln(\"=\"^60)\n\nza_result = za_test(y_with_break; regression=:constant, trim=0.15)\nprintln(\"\\nSeries with structural break:\")\nprintln(\"  Minimum t-stat: \", round(za_result.statistic, digits=3))\nprintln(\"  P-value: \", round(za_result.pvalue, digits=4))\nprintln(\"  Break index: \", za_result.break_index)\nprintln(\"  Break at: \", round(za_result.break_fraction * 100, digits=1), \"% of sample\")\n\n# Compare with standard ADF\nadf_break = adf_test(y_with_break)\nprintln(\"\\n  ADF (ignoring break): p=\", round(adf_break.pvalue, digits=4))\nprintln(\"  ZA (allowing break): p=\", round(za_result.pvalue, digits=4))","category":"section"},{"location":"examples/#Ng-Perron-Tests-for-Small-Samples","page":"Examples","title":"Ng-Perron Tests for Small Samples","text":"# === Ng-Perron Tests ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Ng-Perron Tests (improved size properties)\")\nprintln(\"=\"^60)\n\n# Generate smaller sample\ny_small = cumsum(randn(80))\nnp_result = ngperron_test(y_small; regression=:constant)\n\nprintln(\"\\nSmall sample (n=80):\")\nprintln(\"  MZα: \", round(np_result.MZa, digits=3),\n        \" (5% CV: \", np_result.critical_values[:MZa][5], \")\")\nprintln(\"  MZt: \", round(np_result.MZt, digits=3),\n        \" (5% CV: \", np_result.critical_values[:MZt][5], \")\")\nprintln(\"  MSB: \", round(np_result.MSB, digits=4),\n        \" (5% CV: \", np_result.critical_values[:MSB][5], \")\")\nprintln(\"  MPT: \", round(np_result.MPT, digits=3),\n        \" (5% CV: \", np_result.critical_values[:MPT][5], \")\")","category":"section"},{"location":"examples/#Johansen-Cointegration-Test","page":"Examples","title":"Johansen Cointegration Test","text":"# === Johansen Cointegration Test ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Johansen Cointegration Test\")\nprintln(\"=\"^60)\n\n# Generate cointegrated system\nT_coint = 200\nu1, u2, u3 = cumsum(randn(T_coint)), cumsum(randn(T_coint)), randn(T_coint)\nY_coint = hcat(\n    u1 + 0.1*randn(T_coint),           # I(1)\n    u1 + 0.5*u2 + 0.1*randn(T_coint),  # Cointegrated with first\n    u2 + 0.1*randn(T_coint)            # I(1)\n)\n\njohansen = johansen_test(Y_coint, 2; deterministic=:constant)\n\nprintln(\"\\nCointegrated system (3 variables):\")\nprintln(\"  Estimated rank: \", johansen.rank)\nprintln(\"\\n  Trace test:\")\nfor r in 0:2\n    stat = round(johansen.trace_stats[r+1], digits=2)\n    cv = round(johansen.critical_values_trace[r+1, 2], digits=2)\n    reject = stat > cv ? \"Reject\" : \"Fail to reject\"\n    println(\"    H₀: r ≤ $r: stat=$stat, 5% CV=$cv → $reject\")\nend\n\nprintln(\"\\n  Eigenvalues: \", round.(johansen.eigenvalues, digits=4))\n\nif johansen.rank > 0\n    println(\"\\n  Cointegrating vector(s):\")\n    for i in 1:johansen.rank\n        println(\"    β$i: \", round.(johansen.eigenvectors[:, i], digits=3))\n    end\nend","category":"section"},{"location":"examples/#Testing-All-Variables-Before-VAR","page":"Examples","title":"Testing All Variables Before VAR","text":"# === Multi-Variable Pre-VAR Analysis ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Pre-VAR Unit Root Analysis\")\nprintln(\"=\"^60)\n\n# Typical macro dataset\nY_macro = hcat(\n    cumsum(randn(T)),           # GDP (I(1))\n    0.8*cumsum(randn(T)[1:T]),  # Inflation (I(1))\n    cumsum(randn(T)),           # Interest rate (I(1))\n    randn(T)                    # Output gap (I(0))\n)\nvar_names = [\"GDP\", \"Inflation\", \"Rate\", \"Output Gap\"]\n\n# Test all variables\nresults = test_all_variables(Y_macro; test=:adf)\n\nprintln(\"\\nUnit root test results:\")\nprintln(\"-\"^50)\nn_i1 = 0\nfor (i, r) in enumerate(results)\n    status = r.pvalue > 0.05 ? \"I(1)\" : \"I(0)\"\n    n_i1 += r.pvalue > 0.05\n    println(\"  $(var_names[i]): p=$(round(r.pvalue, digits=3)) → $status\")\nend\n\nprintln(\"\\nSummary: $n_i1 of $(size(Y_macro, 2)) variables appear I(1)\")\n\n# Recommendation\nif n_i1 == size(Y_macro, 2)\n    println(\"\\nRecommendation: All variables I(1)\")\n    println(\"  → Test for cointegration\")\n    println(\"  → If cointegrated: use VECM\")\n    println(\"  → If not: use VAR in first differences\")\nelseif n_i1 == 0\n    println(\"\\nRecommendation: All variables I(0)\")\n    println(\"  → Use VAR in levels\")\nelse\n    println(\"\\nRecommendation: Mixed I(0)/I(1)\")\n    println(\"  → Consider ARDL bounds test\")\n    println(\"  → Or difference I(1) variables\")\nend","category":"section"},{"location":"examples/#Complete-Pre-Estimation-Workflow","page":"Examples","title":"Complete Pre-Estimation Workflow","text":"# === Complete Workflow ===\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"Complete Pre-Estimation Workflow\")\nprintln(\"=\"^60)\n\nfunction pre_estimation_analysis(Y; var_names=nothing, α=0.05)\n    T, n = size(Y)\n    var_names = isnothing(var_names) ? [\"Var$i\" for i in 1:n] : var_names\n\n    println(\"\\n1. Individual Unit Root Tests\")\n    println(\"-\"^40)\n\n    integration_orders = zeros(Int, n)\n    for i in 1:n\n        adf = adf_test(Y[:, i]; lags=:aic)\n        kpss = kpss_test(Y[:, i])\n\n        if adf.pvalue < α && kpss.pvalue > α\n            integration_orders[i] = 0\n            status = \"I(0)\"\n        elseif adf.pvalue > α && kpss.pvalue < α\n            integration_orders[i] = 1\n            status = \"I(1)\"\n        else\n            integration_orders[i] = -1  # Inconclusive\n            status = \"Inconclusive\"\n        end\n        println(\"  $(var_names[i]): $status (ADF p=$(round(adf.pvalue, digits=3)), KPSS p=$(round(kpss.pvalue, digits=3)))\")\n    end\n\n    n_i1 = sum(integration_orders .== 1)\n    n_i0 = sum(integration_orders .== 0)\n\n    println(\"\\n2. Summary\")\n    println(\"-\"^40)\n    println(\"  I(0) variables: $n_i0\")\n    println(\"  I(1) variables: $n_i1\")\n    println(\"  Inconclusive: $(n - n_i0 - n_i1)\")\n\n    # Cointegration test if all I(1)\n    if n_i1 >= 2\n        println(\"\\n3. Cointegration Test\")\n        println(\"-\"^40)\n        joh = johansen_test(Y, 2)\n        println(\"  Estimated cointegration rank: \", joh.rank)\n\n        if joh.rank > 0\n            println(\"  → Cointegration detected\")\n            println(\"  → Recommendation: VECM with rank=$(joh.rank)\")\n        else\n            println(\"  → No cointegration\")\n            println(\"  → Recommendation: VAR in first differences\")\n        end\n    elseif n_i0 == n\n        println(\"\\n3. Recommendation\")\n        println(\"-\"^40)\n        println(\"  All series stationary → VAR in levels\")\n    end\n\n    return (integration_orders=integration_orders, n_i0=n_i0, n_i1=n_i1)\nend\n\n# Run complete analysis\nresult = pre_estimation_analysis(Y_macro; var_names=var_names)\n\n","category":"section"},{"location":"examples/#Best-Practices","page":"Examples","title":"Best Practices","text":"","category":"section"},{"location":"examples/#Data-Preparation","page":"Examples","title":"Data Preparation","text":"Stationarity: Test for unit roots using ADF and KPSS together\nBoth fail to reject → inconclusive, consider structural breaks\nADF rejects, KPSS doesn't → stationary (I(0))\nADF doesn't reject, KPSS rejects → unit root (I(1))\nStructural Breaks: Use Zivot-Andrews test if visual inspection suggests breaks\nCointegration: For I(1) variables, test for cointegration before differencing\nOutliers: Check for and handle outliers\nMissing data: Factor models can handle some missing data; VARs require complete data\nScaling: For factor models, standardize variables","category":"section"},{"location":"examples/#Model-Selection","page":"Examples","title":"Model Selection","text":"Lag length: Use information criteria (BIC is more conservative)\nNumber of factors: Use Bai-Ng criteria; prefer IC2 or IC3\nPrior tightness: Optimize via marginal likelihood for large models","category":"section"},{"location":"examples/#Identification","page":"Examples","title":"Identification","text":"Economic theory: Base restrictions on economic reasoning\nRobustness: Try multiple identification schemes\nNarrative: Use historical knowledge when available","category":"section"},{"location":"examples/#Inference","page":"Examples","title":"Inference","text":"HAC standard errors: Always use for LP at horizons > 0\nCredible intervals: Report 68% and 90% bands for Bayesian\nBootstrap: Use for frequentist VAR confidence intervals","category":"section"},{"location":"examples/#Reporting","page":"Examples","title":"Reporting","text":"Present both: VAR and LP estimates as robustness check\nHorizon selection: Focus on economically meaningful horizons\nFEVD: Report at multiple horizons (short, medium, long-run)","category":"section"},{"location":"lp/#Local-Projections","page":"Local Projections","title":"Local Projections","text":"This chapter provides a comprehensive treatment of Local Projection (LP) methods for estimating impulse response functions, an alternative to the VAR-based approach that offers greater robustness and flexibility.","category":"section"},{"location":"lp/#Introduction","page":"Local Projections","title":"Introduction","text":"Local Projections, introduced by Jordà (2005), estimate impulse responses by running a series of predictive regressions at each forecast horizon. Unlike VARs, which derive IRFs from a single estimated dynamic system, LPs directly estimate the response at each horizon without imposing the dynamic restrictions inherent in VAR specifications.","category":"section"},{"location":"lp/#Key-Advantages-of-Local-Projections","page":"Local Projections","title":"Key Advantages of Local Projections","text":"Robustness to Misspecification: LPs do not impose the lag structure of VARs, making them robust to dynamic misspecification\nFlexibility: Easy to incorporate nonlinearities, state-dependence, and instrumental variables\nTransparency: Each horizon's estimate is independent, making the source of identification transparent\nInference: Standard regression-based inference applies (with HAC corrections)\n\nReference: Jordà (2005), Plagborg-Møller & Wolf (2021)\n\n","category":"section"},{"location":"lp/#Standard-Local-Projections","page":"Local Projections","title":"Standard Local Projections","text":"","category":"section"},{"location":"lp/#The-LP-Regression","page":"Local Projections","title":"The LP Regression","text":"For each horizon h = 0 1 ldots H, we estimate:\n\ny_it+h = alpha_ih + beta_ih x_t + gamma_ih w_t + varepsilon_it+h\n\nwhere:\n\ny_it+h is the response variable i at time t+h\nx_t is the shock/treatment variable at time t\nw_t is a vector of controls (typically lagged y and x)\nbeta_ih is the impulse response of variable i to shock x at horizon h","category":"section"},{"location":"lp/#Control-Variables","page":"Local Projections","title":"Control Variables","text":"Standard controls include lags of all endogenous variables:\n\nw_t = (y_t-1 y_t-2 ldots y_t-p x_t-1 ldots x_t-p)\n\nThe number of lags p is typically selected using information criteria or set to match the VAR lag order.","category":"section"},{"location":"lp/#Estimation","page":"Local Projections","title":"Estimation","text":"At each horizon h, OLS yields:\n\nhatbeta_h = (XX)^-1 XY_h\n\nwhere Y_h is the matrix of responses at horizon h and X contains the shock variable and controls.","category":"section"},{"location":"lp/#HAC-Standard-Errors","page":"Local Projections","title":"HAC Standard Errors","text":"Since varepsilon_t+h is serially correlated (at least MA(h-1) under the null), we use Newey-West standard errors:\n\nhatV_NW = (XX)^-1 hatS (XX)^-1\n\nwith bandwidth typically set to h + 1 or determined automatically.\n\nReference: Jordà (2005), Newey & West (1987)","category":"section"},{"location":"lp/#Julia-Implementation","page":"Local Projections","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Data: Y is T×n matrix of variables\n# shock_var is the index of the shock variable\n# Estimate LP-IRF up to horizon H\n\nlp_model = estimate_lp(Y, shock_var, H;\n    lags = 4,                  # Control lags\n    cov_type = :newey_west,    # HAC standard errors\n    bandwidth = 0              # 0 = automatic bandwidth\n)\n\n# Extract IRF with confidence intervals\nirf_result = lp_irf(lp_model; conf_level = 0.95)\n\n","category":"section"},{"location":"lp/#Local-Projections-with-Instrumental-Variables-(LP-IV)","page":"Local Projections","title":"Local Projections with Instrumental Variables (LP-IV)","text":"","category":"section"},{"location":"lp/#Motivation","page":"Local Projections","title":"Motivation","text":"When the shock variable x_t is endogenous or measured with error, we need external instruments for identification. Stock & Watson (2018) develop the LP-IV methodology for using external instruments in a local projection framework.","category":"section"},{"location":"lp/#The-LP-IV-Model","page":"Local Projections","title":"The LP-IV Model","text":"We use two-stage least squares (2SLS) at each horizon:\n\nFirst Stage: Regress the endogenous shock on instruments and controls:\n\nx_t = pi_0 + pi_1 z_t + pi_2 w_t + v_t\n\nSecond Stage: Use fitted values in the LP regression:\n\ny_it+h = alpha_ih + beta_ih hatx_t + gamma_ih w_t + varepsilon_it+h\n\nwhere z_t is the vector of external instruments.","category":"section"},{"location":"lp/#Identification-Assumptions","page":"Local Projections","title":"Identification Assumptions","text":"Relevance: Ez_t x_t neq 0 (instruments predict the shock)\nExogeneity: Ez_t varepsilon_t+h = 0 (instruments are uncorrelated with structural errors)","category":"section"},{"location":"lp/#First-Stage-F-Statistic","page":"Local Projections","title":"First-Stage F-Statistic","text":"The first-stage F-statistic tests instrument relevance:\n\nF = frac(hatpi_1 hatV_pi^-1 hatpi_1)q\n\nwhere q is the number of instruments. A rule of thumb is F  10 for strong instruments (Stock & Yogo, 2005).","category":"section"},{"location":"lp/#Weak-Instrument-Robust-Inference","page":"Local Projections","title":"Weak Instrument Robust Inference","text":"When instruments are weak, standard 2SLS inference is unreliable. Options include:\n\nAnderson-Rubin confidence sets\nConditional likelihood ratio tests\nWeak-instrument robust standard errors\n\nReference: Stock & Watson (2018), Stock & Yogo (2005)","category":"section"},{"location":"lp/#Julia-Implementation-2","page":"Local Projections","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Y: T×n data matrix\n# shock_var: index of endogenous shock variable\n# Z: T×q matrix of external instruments\n\nlpiv_model = estimate_lp_iv(Y, shock_var, Z, H;\n    lags = 4,\n    cov_type = :newey_west\n)\n\n# Check first-stage strength\nweak_test = weak_instrument_test(lpiv_model; threshold = 10.0)\nprintln(\"Minimum F-statistic: \", weak_test.min_F)\nprintln(\"All horizons pass: \", weak_test.passes_threshold)\n\n# Extract IRF\nirf_iv = lp_iv_irf(lpiv_model)\n\n","category":"section"},{"location":"lp/#Smooth-Local-Projections","page":"Local Projections","title":"Smooth Local Projections","text":"","category":"section"},{"location":"lp/#Motivation-2","page":"Local Projections","title":"Motivation","text":"Standard LPs can produce noisy, erratic impulse responses because each horizon is estimated independently. Barnichon & Brownlees (2019) propose Smooth Local Projections that parameterize the IRF as a smooth function of the horizon using B-spline basis functions.","category":"section"},{"location":"lp/#B-Spline-Representation","page":"Local Projections","title":"B-Spline Representation","text":"The impulse response is modeled as:\n\nbeta(h) = sum_j=1^J theta_j B_j(h)\n\nwhere B_j(h) are B-spline basis functions and theta_j are spline coefficients.","category":"section"},{"location":"lp/#Cubic-B-Splines","page":"Local Projections","title":"Cubic B-Splines","text":"For degree d = 3 (cubic splines), the basis functions are computed recursively using the Cox-de Boor formula:\n\nB_i0(x) = begincases 1  textif  t_i leq x  t_i+1  0  textotherwise endcases\n\nB_id(x) = fracx - t_it_i+d - t_i B_id-1(x) + fract_i+d+1 - xt_i+d+1 - t_i+1 B_i+1d-1(x)","category":"section"},{"location":"lp/#Smoothness-Penalty","page":"Local Projections","title":"Smoothness Penalty","text":"To enforce smoothness, we add a roughness penalty on the second derivative:\n\nmin_theta sum_h=0^H left( hatbeta_h - B(h)theta right)^2 + lambda int left( beta(h) right)^2 dh\n\nThe penalty is computed as theta R theta where:\n\nR_ij = int B_i(x) B_j(x) dx","category":"section"},{"location":"lp/#Two-Step-Estimation","page":"Local Projections","title":"Two-Step Estimation","text":"Estimate standard LP to get hatbeta_h and textVar(hatbeta_h)\nFit weighted penalized spline:\n\nhattheta = left( BWB + lambda R right)^-1 BW hatbeta\n\nwhere W = textdiag(1textVar(hatbeta_h))","category":"section"},{"location":"lp/#Cross-Validation-for-λ-Selection","page":"Local Projections","title":"Cross-Validation for λ Selection","text":"The smoothing parameter lambda can be selected by k-fold cross-validation to minimize out-of-sample prediction error.\n\nReference: Barnichon & Brownlees (2019)","category":"section"},{"location":"lp/#Julia-Implementation-3","page":"Local Projections","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Smooth LP with cubic splines\nsmooth_model = estimate_smooth_lp(Y, shock_var, H;\n    degree = 3,           # Cubic splines\n    n_knots = 4,          # Interior knots\n    lambda = 1.0,         # Smoothing penalty\n    lags = 4\n)\n\n# Automatic lambda selection via CV\noptimal_lambda = cross_validate_lambda(Y, shock_var, H;\n    lambda_grid = 10.0 .^ (-4:0.5:2),\n    k_folds = 5\n)\n\n# Compare smooth vs standard LP\ncomparison = compare_smooth_lp(Y, shock_var, H; lambda = optimal_lambda)\nprintln(\"Variance reduction: \", comparison.variance_reduction)\n\n","category":"section"},{"location":"lp/#State-Dependent-Local-Projections","page":"Local Projections","title":"State-Dependent Local Projections","text":"","category":"section"},{"location":"lp/#Motivation-3","page":"Local Projections","title":"Motivation","text":"Economic responses may differ across states of the economy (e.g., recessions vs. expansions). Auerbach & Gorodnichenko (2012, 2013) develop state-dependent LPs using smooth transition functions.","category":"section"},{"location":"lp/#The-State-Dependent-Model","page":"Local Projections","title":"The State-Dependent Model","text":"y_t+h = F(z_t) left alpha_E + beta_E x_t + gamma_E w_t right + (1 - F(z_t)) left alpha_R + beta_R x_t + gamma_R w_t right + varepsilon_t+h\n\nwhere:\n\nF(z_t) is the smooth transition function\nz_t is the state variable (e.g., moving average of GDP growth)\nSubscript E denotes \"expansion\" regime (F to 0)\nSubscript R denotes \"recession\" regime (F to 1)","category":"section"},{"location":"lp/#Logistic-Transition-Function","page":"Local Projections","title":"Logistic Transition Function","text":"The standard specification uses a logistic function:\n\nF(z_t) = fracexp(-gamma(z_t - c))1 + exp(-gamma(z_t - c))\n\nwhere:\n\ngamma  0 controls the transition speed (higher = sharper)\nc is the threshold (often set to 0 for standardized z_t)\n\nProperties:\n\nF(z) to 1 as z to -infty (deep recession)\nF(z) to 0 as z to +infty (strong expansion)\nF(c) = 05 (neutral state)","category":"section"},{"location":"lp/#State-Variable-Construction","page":"Local Projections","title":"State Variable Construction","text":"Following Auerbach & Gorodnichenko, the state variable is typically:\n\nz_t = frac1k sum_j=0^k-1 Delta y_t-j\n\nA k = 7 quarter moving average of GDP growth is common, then standardized to have zero mean and unit variance.","category":"section"},{"location":"lp/#Estimation-2","page":"Local Projections","title":"Estimation","text":"The model is estimated by nonlinear least squares or by treating it as a linear regression in the interaction terms. The parameters (gamma c) can be:\n\nFixed based on prior research\nEstimated via grid search or NLS\nSelected to maximize fit","category":"section"},{"location":"lp/#Testing-for-Regime-Differences","page":"Local Projections","title":"Testing for Regime Differences","text":"Test whether responses differ across regimes:\n\nH_0 beta_E - beta_R = 0\n\nusing a t-test with HAC standard errors:\n\nt = frachatbeta_E - hatbeta_RsqrttextVar(hatbeta_E) + textVar(hatbeta_R) - 2textCov(hatbeta_E hatbeta_R)\n\nReference: Auerbach & Gorodnichenko (2012, 2013), Ramey & Zubairy (2018)","category":"section"},{"location":"lp/#Julia-Implementation-4","page":"Local Projections","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# Construct state variable (e.g., 7-quarter MA of GDP growth)\ngdp_growth = diff(log.(Y[:, 1]))\nstate_var = [mean(gdp_growth[max(1, t-6):t]) for t in 1:length(gdp_growth)]\nstate_var = (state_var .- mean(state_var)) ./ std(state_var)\n\n# Estimate state-dependent LP\nstate_model = estimate_state_lp(Y, shock_var, state_var, H;\n    gamma = :estimate,      # Estimate transition speed\n    threshold = :median,    # Set threshold at median\n    lags = 4\n)\n\n# Extract regime-specific IRFs\nirf_both = state_irf(state_model; regime = :both)\nirf_expansion = state_irf(state_model; regime = :expansion)\nirf_recession = state_irf(state_model; regime = :recession)\n\n# Test for regime differences\ndiff_test = test_regime_difference(state_model)\n\n","category":"section"},{"location":"lp/#Propensity-Score-Local-Projections","page":"Local Projections","title":"Propensity Score Local Projections","text":"","category":"section"},{"location":"lp/#Motivation-4","page":"Local Projections","title":"Motivation","text":"When the shock is a discrete treatment (e.g., policy intervention), selection bias may confound causal inference. Angrist, Jordà & Kuersteiner (2018) develop LP with inverse propensity weighting (IPW) to address selection.","category":"section"},{"location":"lp/#The-Setup","page":"Local Projections","title":"The Setup","text":"Let D_t in 0 1 be a binary treatment indicator. We want to estimate the Average Treatment Effect (ATE):\n\ntextATE_h = Ey_t+h(1) - y_t+h(0)\n\nwhere y_t+h(d) is the potential outcome under treatment status d.","category":"section"},{"location":"lp/#Propensity-Score","page":"Local Projections","title":"Propensity Score","text":"The propensity score is the probability of treatment given covariates:\n\np(X_t) = P(D_t = 1  X_t)\n\nestimated via logit or probit:\n\np(X_t) = frac11 + exp(-X_tbeta)","category":"section"},{"location":"lp/#Inverse-Propensity-Weighting-(IPW)","page":"Local Projections","title":"Inverse Propensity Weighting (IPW)","text":"The IPW estimator weights observations by the inverse of their selection probability:\n\nTreated: weight = 1p(X_t)\nControl: weight = 1(1-p(X_t))\n\nThis reweighting creates a pseudo-population where treatment is independent of covariates.","category":"section"},{"location":"lp/#IPW-LP-Estimation","page":"Local Projections","title":"IPW-LP Estimation","text":"At each horizon h:\n\nhattextATE_h = frac1n sum_t D_t=1 fracy_t+hhatp(X_t) - frac1n sum_t D_t=0 fracy_t+h1-hatp(X_t)\n\nOr via weighted regression:\n\ny_t+h = alpha_h + beta_h D_t + gamma_h X_t + varepsilon_t+h\n\nestimated by WLS with IPW weights.","category":"section"},{"location":"lp/#Doubly-Robust-Estimation","page":"Local Projections","title":"Doubly Robust Estimation","text":"The doubly robust (DR) estimator combines IPW with outcome regression:\n\nhattextATE^DR_h = frac1n sum_t left fracD_t(y_t+h - mu_1(X_t))hatp(X_t) + mu_1(X_t) right - frac1n sum_t left frac(1-D_t)(y_t+h - mu_0(X_t))1-hatp(X_t) + mu_0(X_t) right\n\nwhere mu_d(X_t) = Ey_t+h  D_t = d X_t is the outcome regression.\n\nProperty: DR is consistent if either the propensity score or the outcome model is correctly specified.","category":"section"},{"location":"lp/#Practical-Considerations","page":"Local Projections","title":"Practical Considerations","text":"Trimming: Propensity scores near 0 or 1 lead to extreme weights. Trim at [0.01, 0.99].\nOverlap: Verify that treated and control groups have overlapping covariate distributions.\nBalance: Check that covariates are balanced after reweighting (standardized mean differences < 0.1).\n\nReference: Angrist, Jordà & Kuersteiner (2018), Hirano, Imbens & Ridder (2003)","category":"section"},{"location":"lp/#Julia-Implementation-5","page":"Local Projections","title":"Julia Implementation","text":"using MacroEconometricModels\n\n# treatment: Bool vector of treatment indicators\n# covariates: matrix of selection-relevant covariates\n\n# IPW estimation\nprop_model = estimate_propensity_lp(Y, treatment, covariates, H;\n    ps_method = :logit,\n    trimming = (0.01, 0.99),\n    lags = 4\n)\n\n# Doubly robust estimation\ndr_model = doubly_robust_lp(Y, treatment, covariates, H)\n\n# Extract ATE impulse response\nate_irf = propensity_irf(prop_model)\n\n# Diagnostics\ndiagnostics = propensity_diagnostics(prop_model)\nprintln(\"Propensity score overlap: \", diagnostics.overlap)\nprintln(\"Max covariate imbalance: \", diagnostics.balance.max_weighted)\n\n","category":"section"},{"location":"lp/#Comparing-LP-and-VAR","page":"Local Projections","title":"Comparing LP and VAR","text":"","category":"section"},{"location":"lp/#LP-vs.-VAR-Trade-offs","page":"Local Projections","title":"LP vs. VAR Trade-offs","text":"Aspect VAR Local Projections\nEfficiency More efficient if correctly specified Less efficient, but robust\nBias Biased if dynamics misspecified Consistent under weak conditions\nLong horizons Compounds specification error Each horizon estimated directly\nNonlinearities Requires extensions Easy to incorporate\nExternal instruments SVAR-IV LP-IV","category":"section"},{"location":"lp/#Asymptotic-Equivalence","page":"Local Projections","title":"Asymptotic Equivalence","text":"Plagborg-Møller & Wolf (2021) show that under correct specification, LP and VAR IRFs are asymptotically equivalent:\n\nsqrtT(hatbeta_h^LP - beta_h) xrightarrowd N(0 V^LP)\n\nsqrtT(hattheta_h^VAR - theta_h) xrightarrowd N(0 V^VAR)\n\nwith V^LP geq V^VAR (VAR is weakly more efficient).","category":"section"},{"location":"lp/#When-to-Use-LP","page":"Local Projections","title":"When to Use LP","text":"Concerned about VAR misspecification\nNeed to incorporate external instruments\nInterested in nonlinear/state-dependent responses\nWorking with discrete treatments\nLong horizons where VAR error compounds\n\nReference: Plagborg-Møller & Wolf (2021)\n\n","category":"section"},{"location":"lp/#References","page":"Local Projections","title":"References","text":"","category":"section"},{"location":"lp/#Local-Projections-Core","page":"Local Projections","title":"Local Projections - Core","text":"Jordà, Ò. (2005). \"Estimation and Inference of Impulse Responses by Local Projections.\" American Economic Review, 95(1), 161-182.\nPlagborg-Møller, M., & Wolf, C. K. (2021). \"Local Projections and VARs Estimate the Same Impulse Responses.\" Econometrica, 89(2), 955-980.","category":"section"},{"location":"lp/#LP-IV","page":"Local Projections","title":"LP-IV","text":"Stock, J. H., & Watson, M. W. (2018). \"Identification and Estimation of Dynamic Causal Effects in Macroeconomics Using External Instruments.\" The Economic Journal, 128(610), 917-948.\nStock, J. H., & Yogo, M. (2005). \"Testing for Weak Instruments in Linear IV Regression.\" In Identification and Inference for Econometric Models.","category":"section"},{"location":"lp/#Smooth-LP","page":"Local Projections","title":"Smooth LP","text":"Barnichon, R., & Brownlees, C. (2019). \"Impulse Response Estimation by Smooth Local Projections.\" Review of Economics and Statistics, 101(3), 522-530.","category":"section"},{"location":"lp/#State-Dependent-LP","page":"Local Projections","title":"State-Dependent LP","text":"Auerbach, A. J., & Gorodnichenko, Y. (2012). \"Measuring the Output Responses to Fiscal Policy.\" American Economic Journal: Economic Policy, 4(2), 1-27.\nAuerbach, A. J., & Gorodnichenko, Y. (2013). \"Fiscal Multipliers in Recession and Expansion.\" In Fiscal Policy after the Financial Crisis.\nRamey, V. A., & Zubairy, S. (2018). \"Government Spending Multipliers in Good Times and in Bad: Evidence from US Historical Data.\" Journal of Political Economy, 126(2), 850-901.","category":"section"},{"location":"lp/#Propensity-Score-Methods","page":"Local Projections","title":"Propensity Score Methods","text":"Angrist, J. D., Jordà, Ò., & Kuersteiner, G. M. (2018). \"Semiparametric Estimates of Monetary Policy Effects: String Theory Revisited.\" Journal of Business & Economic Statistics, 36(3), 371-387.\nHirano, K., Imbens, G. W., & Ridder, G. (2003). \"Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score.\" Econometrica, 71(4), 1161-1189.","category":"section"},{"location":"lp/#Inference","page":"Local Projections","title":"Inference","text":"Newey, W. K., & West, K. D. (1987). \"A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix.\" Econometrica, 55(3), 703-708.","category":"section"},{"location":"#MacroEconometricModels.jl","page":"Home","title":"MacroEconometricModels.jl","text":"A comprehensive Julia package for macroeconometric research and analysis","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"MacroEconometricModels.jl provides a unified, high-performance framework for estimating and analyzing macroeconometric models in Julia. The package implements state-of-the-art methods for Vector Autoregression (VAR), Bayesian VAR (BVAR), Local Projections (LP), Factor Models, and Generalized Method of Moments (GMM) estimation.","category":"section"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"Vector Autoregression (VAR): OLS estimation with comprehensive diagnostics, impulse response functions (IRFs), and forecast error variance decomposition (FEVD)\nStructural Identification: Multiple identification schemes including Cholesky, sign restrictions, long-run (Blanchard-Quah), and narrative restrictions\nBayesian VAR: Minnesota/Litterman prior with automatic hyperparameter optimization via marginal likelihood (Giannone, Lenza & Primiceri, 2015)\nLocal Projections: Jordà (2005) methodology with extensions for IV (Stock & Watson, 2018), smooth LP (Barnichon & Brownlees, 2019), state-dependence (Auerbach & Gorodnichenko, 2013), and propensity score methods (Angrist, Jordà & Kuersteiner, 2018)\nFactor Models: Static, dynamic, and generalized dynamic factor models with Bai & Ng (2002) information criteria\nHypothesis Tests: Comprehensive unit root tests (ADF, KPSS, Phillips-Perron, Zivot-Andrews, Ng-Perron) and Johansen cointegration test\nGMM Estimation: Flexible GMM framework with one-step, two-step, and iterated estimation\nRobust Inference: Newey-West, White, and Driscoll-Kraay HAC standard errors with automatic bandwidth selection","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"MacroEconometricModels\")\n\nOr from the Julia REPL package mode:\n\n] add MacroEconometricModels","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"#Basic-VAR-Estimation","page":"Home","title":"Basic VAR Estimation","text":"using MacroEconometricModels\nusing Random\n\n# Generate synthetic macroeconomic data\nRandom.seed!(42)\nT, n = 200, 3  # 200 observations, 3 variables\nY = randn(T, n)\nfor t in 2:T\n    Y[t, :] = 0.5 * Y[t-1, :] + 0.3 * randn(3)\nend\n\n# Estimate VAR(2) model\nmodel = fit(VARModel, Y, 2)\n\n# Compute impulse responses (20 periods ahead)\nirfs = irf(model, 20; method=:cholesky)\n\n# Forecast error variance decomposition\ndecomp = fevd(model, 20; method=:cholesky)","category":"section"},{"location":"#Bayesian-VAR-with-Minnesota-Prior","page":"Home","title":"Bayesian VAR with Minnesota Prior","text":"using MacroEconometricModels\n\n# Set hyperparameters (or use optimize_hyperparameters)\nhyper = MinnesotaHyperparameters(\n    τ = 0.5,      # Overall tightness\n    d = 2.0,      # Lag decay\n    ω_own = 1.0,  # Own-lag variance\n    ω_cross = 1.0, # Cross-lag variance\n    ω_det = 1.0   # Deterministic terms\n)\n\n# Estimate BVAR with MCMC\nchain = estimate_bvar(Y, 2; n_samples=2000, n_adapts=500,\n                      prior=:minnesota, hyper=hyper)\n\n# Bayesian IRF with credible intervals\nbirf = irf(chain, 2, 3, 20; method=:cholesky)","category":"section"},{"location":"#Local-Projections","page":"Home","title":"Local Projections","text":"using MacroEconometricModels\n\n# Standard Local Projection (Jordà 2005)\nlp_model = estimate_lp(Y, 1, 20; lags=4, cov_type=:newey_west)\nlp_irfs = lp_irf(lp_model)\n\n# LP with Instrumental Variables (Stock & Watson 2018)\nZ = randn(T, 1)  # External instrument\nlpiv_model = estimate_lp_iv(Y, 1, Z, 20; lags=4)\nlpiv_irfs = lp_iv_irf(lpiv_model)","category":"section"},{"location":"#Factor-Models","page":"Home","title":"Factor Models","text":"using MacroEconometricModels\n\n# Large panel: T observations, N variables\nX = randn(200, 100)\n\n# Determine optimal number of factors (Bai & Ng 2002)\nic = ic_criteria(X, 10)\nr_optimal = ic.r_IC2\n\n# Estimate static factor model\nfm = estimate_factors(X, r_optimal)\n\n# Extract factors for use in FAVAR\nfactors = fm.factors","category":"section"},{"location":"#Unit-Root-Tests","page":"Home","title":"Unit Root Tests","text":"using MacroEconometricModels\n\n# Test for unit root\ny = cumsum(randn(200))  # Random walk (has unit root)\n\n# Augmented Dickey-Fuller test\nadf_result = adf_test(y; lags=:aic, regression=:constant)\n\n# KPSS stationarity test (opposite null hypothesis)\nkpss_result = kpss_test(y; regression=:constant)\n\n# Johansen cointegration test for multivariate data\nY = randn(200, 3)\njohansen_result = johansen_test(Y, 2; deterministic=:constant)","category":"section"},{"location":"#Package-Structure","page":"Home","title":"Package Structure","text":"The package is organized into the following modules:\n\nModule Description\ntypes.jl Core type definitions for VAR, BVAR, IRF, FEVD results\nestimation.jl VAR/BVAR estimation via OLS and MCMC\nbayesian.jl Bayesian inference with Turing.jl\npriors.jl Minnesota prior and hyperparameter optimization\nidentification.jl Structural identification schemes\nirf.jl Impulse response function computation\nfevd.jl Forecast error variance decomposition\nhd.jl Historical decomposition\nsummary.jl Publication-quality summary tables\nlp_*.jl Local Projections suite\nfactormodels.jl Static, dynamic, and generalized dynamic factor models\nunitroot.jl Unit root and cointegration tests (ADF, KPSS, PP, ZA, Ng-Perron, Johansen)\ngmm.jl Generalized Method of Moments\nutils.jl Numerical utilities","category":"section"},{"location":"#Mathematical-Notation","page":"Home","title":"Mathematical Notation","text":"Throughout this documentation, we use the following notation conventions:\n\nSymbol Description\ny_t n times 1 vector of endogenous variables at time t\nY T times n data matrix\np Number of lags in VAR\nA_i n times n coefficient matrix for lag i\nSigma n times n reduced-form error covariance\nB_0 n times n contemporaneous impact matrix\nvarepsilon_t n times 1 structural shocks\nu_t n times n reduced-form residuals\nh Forecast/impulse response horizon\nH Maximum horizon","category":"section"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"#Core-Methodology","page":"Home","title":"Core Methodology","text":"Blanchard, O. J., & Quah, D. (1989). \"The Dynamic Effects of Aggregate Demand and Supply Disturbances.\" American Economic Review, 79(4), 655-673.\nHamilton, J. D. (1994). Time Series Analysis. Princeton University Press.\nKilian, L., & Lütkepohl, H. (2017). Structural Vector Autoregressive Analysis. Cambridge University Press.\nLütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis. Springer.\nSims, C. A. (1980). \"Macroeconomics and Reality.\" Econometrica, 48(1), 1-48.","category":"section"},{"location":"#Bayesian-Methods","page":"Home","title":"Bayesian Methods","text":"Doan, T., Litterman, R., & Sims, C. (1984). \"Forecasting and Conditional Projection Using Realistic Prior Distributions.\" Econometric Reviews, 3(1), 1-100.\nGiannone, D., Lenza, M., & Primiceri, G. E. (2015). \"Prior Selection for Vector Autoregressions.\" Review of Economics and Statistics, 97(2), 436-451.\nLitterman, R. B. (1986). \"Forecasting with Bayesian Vector Autoregressions—Five Years of Experience.\" Journal of Business & Economic Statistics, 4(1), 25-38.","category":"section"},{"location":"#Local-Projections-2","page":"Home","title":"Local Projections","text":"Angrist, J. D., Jordà, Ò., & Kuersteiner, G. M. (2018). \"Semiparametric Estimates of Monetary Policy Effects: String Theory Revisited.\" Journal of Business & Economic Statistics, 36(3), 371-387.\nAuerbach, A. J., & Gorodnichenko, Y. (2013). \"Fiscal Multipliers in Recession and Expansion.\" In Fiscal Policy after the Financial Crisis.\nBarnichon, R., & Brownlees, C. (2019). \"Impulse Response Estimation by Smooth Local Projections.\" Review of Economics and Statistics, 101(3), 522-530.\nJordà, Ò. (2005). \"Estimation and Inference of Impulse Responses by Local Projections.\" American Economic Review, 95(1), 161-182.\nStock, J. H., & Watson, M. W. (2018). \"Identification and Estimation of Dynamic Causal Effects in Macroeconomics Using External Instruments.\" The Economic Journal, 128(610), 917-948.","category":"section"},{"location":"#Factor-Models-2","page":"Home","title":"Factor Models","text":"Bai, J., & Ng, S. (2002). \"Determining the Number of Factors in Approximate Factor Models.\" Econometrica, 70(1), 191-221.\nStock, J. H., & Watson, M. W. (2002). \"Forecasting Using Principal Components from a Large Number of Predictors.\" Journal of the American Statistical Association, 97(460), 1167-1179.","category":"section"},{"location":"#Robust-Inference","page":"Home","title":"Robust Inference","text":"Andrews, D. W. K. (1991). \"Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation.\" Econometrica, 59(3), 817-858.\nHansen, L. P. (1982). \"Large Sample Properties of Generalized Method of Moments Estimators.\" Econometrica, 50(4), 1029-1054.\nNewey, W. K., & West, K. D. (1987). \"A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix.\" Econometrica, 55(3), 703-708.\nNewey, W. K., & West, K. D. (1994). \"Automatic Lag Selection in Covariance Matrix Estimation.\" Review of Economic Studies, 61(4), 631-653.","category":"section"},{"location":"#License","page":"Home","title":"License","text":"This package is released under the MIT License.","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"Contributions are welcome! Please see the GitHub repository for contribution guidelines.","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"Pages = [\"manual.md\", \"lp.md\", \"factormodels.md\", \"bayesian.md\", \"innovation_accounting.md\", \"hypothesis_tests.md\", \"api.md\", \"examples.md\"]\nDepth = 2","category":"section"}]
}
