<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian VAR · MacroEconometricModels.jl</title><meta name="title" content="Bayesian VAR · MacroEconometricModels.jl"/><meta property="og:title" content="Bayesian VAR · MacroEconometricModels.jl"/><meta property="twitter:title" content="Bayesian VAR · MacroEconometricModels.jl"/><meta name="description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:description" content="Documentation for MacroEconometricModels.jl."/><meta property="twitter:description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:url" content="https://chung9207.github.io/MacroEconometricModels.jl/bayesian/"/><meta property="twitter:url" content="https://chung9207.github.io/MacroEconometricModels.jl/bayesian/"/><link rel="canonical" href="https://chung9207.github.io/MacroEconometricModels.jl/bayesian/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MacroEconometricModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Frequentist Models</span><ul><li><a class="tocitem" href="../manual/">VAR</a></li><li><a class="tocitem" href="../lp/">Local Projections</a></li><li><a class="tocitem" href="../factormodels/">Factor Models</a></li></ul></li><li><span class="tocitem">Bayesian Models</span><ul><li class="is-active"><a class="tocitem" href>Bayesian VAR</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Bayesian-Framework"><span>Bayesian Framework</span></a></li><li><a class="tocitem" href="#The-Minnesota-Prior"><span>The Minnesota Prior</span></a></li><li><a class="tocitem" href="#Dummy-Observations-Approach"><span>Dummy Observations Approach</span></a></li><li><a class="tocitem" href="#Hyperparameter-Optimization"><span>Hyperparameter Optimization</span></a></li><li><a class="tocitem" href="#MCMC-Estimation-with-Turing.jl"><span>MCMC Estimation with Turing.jl</span></a></li><li><a class="tocitem" href="#Bayesian-Impulse-Response-Functions"><span>Bayesian Impulse Response Functions</span></a></li><li><a class="tocitem" href="#Bayesian-FEVD"><span>Bayesian FEVD</span></a></li><li><a class="tocitem" href="#Information-Criteria"><span>Information Criteria</span></a></li><li><a class="tocitem" href="#Complete-Example"><span>Complete Example</span></a></li><li><a class="tocitem" href="#Large-BVAR"><span>Large BVAR</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li><li><span class="tocitem">Hypothesis Tests</span><ul><li><a class="tocitem" href="../hypothesis_tests/">Unit Root &amp; Cointegration</a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../api/">Overview</a></li><li><a class="tocitem" href="../api_types/">Types</a></li><li><a class="tocitem" href="../api_functions/">Functions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Bayesian Models</a></li><li class="is-active"><a href>Bayesian VAR</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian VAR</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/chung9207/MacroEconometricModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/chung9207/MacroEconometricModels.jl/blob/main/docs/src/bayesian.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Bayesian-VAR-(BVAR)"><a class="docs-heading-anchor" href="#Bayesian-VAR-(BVAR)">Bayesian VAR (BVAR)</a><a id="Bayesian-VAR-(BVAR)-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-VAR-(BVAR)" title="Permalink"></a></h1><p>This chapter covers Bayesian estimation methods for Vector Autoregression models, including the Minnesota prior, hyperparameter optimization, and MCMC inference.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>Bayesian VAR (BVAR) estimation addresses the curse of dimensionality in VAR models by incorporating prior information to shrink coefficient estimates. This is particularly valuable when:</p><ol><li>The number of parameters is large relative to sample size</li><li>Prior economic knowledge should influence estimation</li><li>Uncertainty quantification via posterior distributions is desired</li><li>Forecasting performance is paramount</li></ol><p><strong>Key References</strong>: Litterman (1986), Doan, Litterman &amp; Sims (1984), Giannone, Lenza &amp; Primiceri (2015)</p><hr/><h2 id="Bayesian-Framework"><a class="docs-heading-anchor" href="#Bayesian-Framework">Bayesian Framework</a><a id="Bayesian-Framework-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Framework" title="Permalink"></a></h2><h3 id="The-Prior-Likelihood-Posterior-Paradigm"><a class="docs-heading-anchor" href="#The-Prior-Likelihood-Posterior-Paradigm">The Prior-Likelihood-Posterior Paradigm</a><a id="The-Prior-Likelihood-Posterior-Paradigm-1"></a><a class="docs-heading-anchor-permalink" href="#The-Prior-Likelihood-Posterior-Paradigm" title="Permalink"></a></h3><p>In the Bayesian approach, we treat the VAR parameters as random variables and update our beliefs using Bayes&#39; theorem:</p><p class="math-container">\[p(B, \Sigma | Y) \propto p(Y | B, \Sigma) \cdot p(B, \Sigma)\]</p><p>where:</p><ul><li><span>$p(Y | B, \Sigma)$</span> is the likelihood</li><li><span>$p(B, \Sigma)$</span> is the prior</li><li><span>$p(B, \Sigma | Y)$</span> is the posterior</li></ul><h3 id="Natural-Conjugate-Prior"><a class="docs-heading-anchor" href="#Natural-Conjugate-Prior">Natural Conjugate Prior</a><a id="Natural-Conjugate-Prior-1"></a><a class="docs-heading-anchor-permalink" href="#Natural-Conjugate-Prior" title="Permalink"></a></h3><p>For computational convenience, we use the Normal-Inverse-Wishart conjugate prior:</p><p class="math-container">\[\Sigma \sim \text{IW}(\nu_0, S_0)\]</p><p class="math-container">\[\text{vec}(B) | \Sigma \sim N(\text{vec}(B_0), \Sigma \otimes \Omega_0)\]</p><p>This yields a closed-form posterior of the same family.</p><hr/><h2 id="The-Minnesota-Prior"><a class="docs-heading-anchor" href="#The-Minnesota-Prior">The Minnesota Prior</a><a id="The-Minnesota-Prior-1"></a><a class="docs-heading-anchor-permalink" href="#The-Minnesota-Prior" title="Permalink"></a></h2><h3 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h3><p>The <strong>Minnesota prior</strong> (Litterman, 1986; Doan, Litterman &amp; Sims, 1984) shrinks VAR coefficients toward a random walk prior. This reflects the empirical observation that many macroeconomic variables are well-approximated by random walks, especially at short horizons.</p><h3 id="Prior-Specification"><a class="docs-heading-anchor" href="#Prior-Specification">Prior Specification</a><a id="Prior-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Specification" title="Permalink"></a></h3><p><strong>Prior Mean</strong>: Each variable follows a random walk:</p><p class="math-container">\[E[A_{1,ii}] = 1, \quad E[A_{1,ij}] = 0 \text{ for } i \neq j, \quad E[A_l] = 0 \text{ for } l &gt; 1\]</p><p><strong>Prior Variance</strong>: The prior variance for coefficient <span>$(i,j)$</span> at lag <span>$l$</span> is:</p><p class="math-container">\[\text{Var}(A_{l,ij}) = \begin{cases}
\frac{\tau^2}{l^d} &amp; \text{if } i = j \text{ (own lag)} \\
\frac{\tau^2 \omega^2}{l^d} \cdot \frac{\sigma_i^2}{\sigma_j^2} &amp; \text{if } i \neq j \text{ (cross lag)}
\end{cases}\]</p><p>where:</p><ul><li><span>$\tau$</span> is the <strong>overall tightness</strong> (shrinkage intensity)</li><li><span>$d$</span> is the <strong>lag decay</strong> (typically <span>$d = 2$</span>)</li><li><span>$\omega$</span> controls <strong>cross-variable shrinkage</strong> (typically <span>$\omega &lt; 1$</span>)</li><li><span>$\sigma_i^2$</span> is the residual variance from a univariate AR(1) for variable <span>$i$</span></li></ul><h3 id="Interpretation-of-Hyperparameters"><a class="docs-heading-anchor" href="#Interpretation-of-Hyperparameters">Interpretation of Hyperparameters</a><a id="Interpretation-of-Hyperparameters-1"></a><a class="docs-heading-anchor-permalink" href="#Interpretation-of-Hyperparameters" title="Permalink"></a></h3><table><tr><th style="text-align: right">Parameter</th><th style="text-align: right">Effect</th><th style="text-align: right">Typical Values</th></tr><tr><td style="text-align: right"><span>$\tau$</span></td><td style="text-align: right">Overall shrinkage (lower = more shrinkage)</td><td style="text-align: right">0.01 – 1.0</td></tr><tr><td style="text-align: right"><span>$d$</span></td><td style="text-align: right">Lag decay (higher = faster decay)</td><td style="text-align: right">1, 2, 3</td></tr><tr><td style="text-align: right"><span>$\omega$</span></td><td style="text-align: right">Cross-variable penalty (lower = more penalty)</td><td style="text-align: right">0.5 – 1.0</td></tr></table><h3 id="Julia-Implementation"><a class="docs-heading-anchor" href="#Julia-Implementation">Julia Implementation</a><a id="Julia-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-Implementation" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MacroEconometricModels

# Define hyperparameters
hyper = MinnesotaHyperparameters(
    τ = 0.5,      # Overall tightness
    d = 2.0,      # Lag decay
    ω_own = 1.0,  # Own-lag variance scaling
    ω_cross = 1.0, # Cross-lag variance scaling
    ω_det = 1.0   # Deterministic terms scaling
)

# Use in BVAR estimation
chain = estimate_bvar(Y, 2; n_samples=2000, n_adapts=500,
                      prior=:minnesota, hyper=hyper)</code></pre><hr/><h2 id="Dummy-Observations-Approach"><a class="docs-heading-anchor" href="#Dummy-Observations-Approach">Dummy Observations Approach</a><a id="Dummy-Observations-Approach-1"></a><a class="docs-heading-anchor-permalink" href="#Dummy-Observations-Approach" title="Permalink"></a></h2><h3 id="Implementation-via-Augmented-Regression"><a class="docs-heading-anchor" href="#Implementation-via-Augmented-Regression">Implementation via Augmented Regression</a><a id="Implementation-via-Augmented-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-via-Augmented-Regression" title="Permalink"></a></h3><p>We implement the Minnesota prior using dummy observations (Theil-Goldberger mixed estimation). The augmented data matrices are:</p><p><strong>Prior on coefficients</strong> (tightness dummies):</p><p class="math-container">\[Y_d = \begin{bmatrix}
\text{diag}(\sigma_1, \ldots, \sigma_n) / \tau \\
0_{n(p-1) \times n} \\
\text{diag}(\sigma_1, \ldots, \sigma_n) \\
0_{1 \times n}
\end{bmatrix}, \quad
X_d = \begin{bmatrix}
0_{n \times 1} &amp; J_p \otimes \text{diag}(\sigma_1, \ldots, \sigma_n) / \tau \\
0_{n(p-1) \times 1} &amp; I_{p-1} \otimes \text{diag}(\sigma_1, \ldots, \sigma_n) \\
0_{n \times 1} &amp; 0_{n \times np} \\
c &amp; 0_{1 \times np}
\end{bmatrix}\]</p><p>where <span>$J_p = \text{diag}(1, 2^d, \ldots, p^d)$</span>.</p><p>The posterior is then computed as OLS on the augmented data <span>$[Y; Y_d]$</span> and <span>$[X; X_d]$</span>.</p><p><strong>Reference</strong>: Litterman (1986), Kadiyala &amp; Karlsson (1997), Bańbura, Giannone &amp; Reichlin (2010)</p><h3 id="Julia-Implementation-2"><a class="docs-heading-anchor" href="#Julia-Implementation-2">Julia Implementation</a><a class="docs-heading-anchor-permalink" href="#Julia-Implementation-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MacroEconometricModels

# Generate dummy observations for Minnesota prior
Y_dummy, X_dummy = gen_dummy_obs(Y, p, hyper)

# Augment data
Y_aug = vcat(Y_actual, Y_dummy)
X_aug = vcat(X_actual, X_dummy)

# Posterior via OLS on augmented data
B_post = (X_aug&#39;X_aug) \ (X_aug&#39;Y_aug)</code></pre><hr/><h2 id="Hyperparameter-Optimization"><a class="docs-heading-anchor" href="#Hyperparameter-Optimization">Hyperparameter Optimization</a><a id="Hyperparameter-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Hyperparameter-Optimization" title="Permalink"></a></h2><h3 id="Marginal-Likelihood"><a class="docs-heading-anchor" href="#Marginal-Likelihood">Marginal Likelihood</a><a id="Marginal-Likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-Likelihood" title="Permalink"></a></h3><p>Rather than selecting <span>$\tau$</span> subjectively, we can optimize it by maximizing the marginal likelihood (Giannone, Lenza &amp; Primiceri, 2015):</p><p class="math-container">\[p(Y | \tau) = \int p(Y | B, \Sigma) p(B, \Sigma | \tau) \, dB \, d\Sigma\]</p><p>For the Normal-Inverse-Wishart prior with dummy observations, the log marginal likelihood has an analytical form:</p><p class="math-container">\[\log p(Y | \tau) = c + \frac{T-k}{2} \log|\tilde{S}^{-1}| - \frac{T_d}{2} \log|\tilde{S}_d^{-1}| + \log \frac{\Gamma_n(\frac{T+T_d - k}{2})}{\Gamma_n(\frac{T_d - k}{2})}\]</p><p>where <span>$\tilde{S}$</span> and <span>$\tilde{S}_d$</span> are the residual sum of squares from the augmented and dummy-only regressions.</p><p><strong>Reference</strong>: Giannone, Lenza &amp; Primiceri (2015), Carriero, Clark &amp; Marcellino (2015)</p><h3 id="Julia-Implementation-3"><a class="docs-heading-anchor" href="#Julia-Implementation-3">Julia Implementation</a><a class="docs-heading-anchor-permalink" href="#Julia-Implementation-3" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MacroEconometricModels

# Find optimal shrinkage using marginal likelihood
best_hyper = optimize_hyperparameters(Y, p; grid_size=20)

println(&quot;Optimal hyperparameters:&quot;)
println(&quot;  τ (overall tightness): &quot;, round(best_hyper.tau, digits=4))
println(&quot;  d (lag decay): &quot;, best_hyper.d)

# Compute log marginal likelihood
lml = log_marginal_likelihood(Y, p, hyper)</code></pre><h3 id="Grid-Search-Options"><a class="docs-heading-anchor" href="#Grid-Search-Options">Grid Search Options</a><a id="Grid-Search-Options-1"></a><a class="docs-heading-anchor-permalink" href="#Grid-Search-Options" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Custom optimization grid
best_hyper = optimize_hyperparameters(Y, p;
    grid_size = 30,           # Number of grid points
    tau_range = (0.01, 2.0),  # Range for τ
    d_values = [1, 2, 3]      # Values for d
)</code></pre><hr/><h2 id="MCMC-Estimation-with-Turing.jl"><a class="docs-heading-anchor" href="#MCMC-Estimation-with-Turing.jl">MCMC Estimation with Turing.jl</a><a id="MCMC-Estimation-with-Turing.jl-1"></a><a class="docs-heading-anchor-permalink" href="#MCMC-Estimation-with-Turing.jl" title="Permalink"></a></h2><h3 id="The-BVAR-Model"><a class="docs-heading-anchor" href="#The-BVAR-Model">The BVAR Model</a><a id="The-BVAR-Model-1"></a><a class="docs-heading-anchor-permalink" href="#The-BVAR-Model" title="Permalink"></a></h3><p>For more flexible priors or non-conjugate settings, we use MCMC via Turing.jl with the NUTS sampler:</p><pre><code class="language-julia hljs">@model function bvar_model(Y, X, prior_mean, prior_var, ν₀, S₀)
    n = size(Y, 2)
    k = size(X, 2)

    # Prior on error covariance
    Σ ~ InverseWishart(ν₀, S₀)

    # Prior on coefficients
    B ~ MatrixNormal(prior_mean, prior_var, Σ)

    # Likelihood
    for t in axes(Y, 1)
        Y[t, :] ~ MvNormal(X[t, :]&#39; * B, Σ)
    end
end</code></pre><h3 id="Julia-Implementation-4"><a class="docs-heading-anchor" href="#Julia-Implementation-4">Julia Implementation</a><a class="docs-heading-anchor-permalink" href="#Julia-Implementation-4" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MacroEconometricModels

# Estimate BVAR with MCMC
chain = estimate_bvar(Y, p;
    n_samples = 2000,     # Posterior samples
    n_adapts = 500,       # Adaptation samples
    prior = :minnesota,   # Prior type
    hyper = best_hyper    # Hyperparameters
)

# Access posterior draws
# chain.samples contains the MCMC draws</code></pre><h3 id="Convergence-Diagnostics"><a class="docs-heading-anchor" href="#Convergence-Diagnostics">Convergence Diagnostics</a><a id="Convergence-Diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence-Diagnostics" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Extract chain parameters
params = extract_chain_parameters(chain)

# Check R-hat statistics
# Check effective sample sizes
# Trace plots for visual inspection</code></pre><p><strong>Reference</strong>: Gelman et al. (2013), Hoffman &amp; Gelman (2014)</p><hr/><h2 id="Bayesian-Impulse-Response-Functions"><a class="docs-heading-anchor" href="#Bayesian-Impulse-Response-Functions">Bayesian Impulse Response Functions</a><a id="Bayesian-Impulse-Response-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Impulse-Response-Functions" title="Permalink"></a></h2><h3 id="Posterior-IRF-Distribution"><a class="docs-heading-anchor" href="#Posterior-IRF-Distribution">Posterior IRF Distribution</a><a id="Posterior-IRF-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-IRF-Distribution" title="Permalink"></a></h3><p>For each MCMC draw, we compute impulse responses, yielding a posterior distribution over IRFs. We report:</p><ul><li><strong>Posterior median</strong>: Point estimate</li><li><strong>Credible intervals</strong>: 68% (16th-84th percentile) or 90% (5th-95th percentile)</li></ul><h3 id="Cholesky-Identification"><a class="docs-heading-anchor" href="#Cholesky-Identification">Cholesky Identification</a><a id="Cholesky-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Cholesky-Identification" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MacroEconometricModels

# Bayesian IRF with Cholesky identification
H = 20  # Horizon
birf_chol = irf(chain, p, n, H; method=:cholesky)

# birf_chol.quantiles is (H+1) × n × n × 3 array
# [:, :, :, 1] = 16th percentile
# [:, :, :, 2] = median
# [:, :, :, 3] = 84th percentile

println(&quot;Bayesian IRF of GDP to own shock:&quot;)
for h in [0, 4, 8, 12, 20]
    med = round(birf_chol.quantiles[h+1, 1, 1, 2], digits=3)
    lo = round(birf_chol.quantiles[h+1, 1, 1, 1], digits=3)
    hi = round(birf_chol.quantiles[h+1, 1, 1, 3], digits=3)
    println(&quot;  h=$h: $med [$lo, $hi]&quot;)
end</code></pre><h3 id="Sign-Restrictions"><a class="docs-heading-anchor" href="#Sign-Restrictions">Sign Restrictions</a><a id="Sign-Restrictions-1"></a><a class="docs-heading-anchor-permalink" href="#Sign-Restrictions" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Define sign restriction check function
function check_demand_shock(irf_array)
    # Demand shock: positive GDP and inflation on impact
    return irf_array[1, 1, 1] &gt; 0 &amp;&amp; irf_array[1, 2, 1] &gt; 0
end

# Bayesian IRF with sign restrictions
birf_sign = irf(chain, p, n, H;
    method = :sign,
    check_func = check_demand_shock
)

println(&quot;Bayesian sign-restricted demand shock → GDP:&quot;)
for h in [0, 4, 8, 12]
    med = round(birf_sign.quantiles[h+1, 1, 1, 2], digits=3)
    lo = round(birf_sign.quantiles[h+1, 1, 1, 1], digits=3)
    hi = round(birf_sign.quantiles[h+1, 1, 1, 3], digits=3)
    println(&quot;  h=$h: $med [$lo, $hi]&quot;)
end</code></pre><hr/><h2 id="Bayesian-FEVD"><a class="docs-heading-anchor" href="#Bayesian-FEVD">Bayesian FEVD</a><a id="Bayesian-FEVD-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-FEVD" title="Permalink"></a></h2><h3 id="Posterior-FEVD-Distribution"><a class="docs-heading-anchor" href="#Posterior-FEVD-Distribution">Posterior FEVD Distribution</a><a id="Posterior-FEVD-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-FEVD-Distribution" title="Permalink"></a></h3><p>Similarly, forecast error variance decomposition can be computed for each posterior draw:</p><pre><code class="language-julia hljs">using MacroEconometricModels

# Bayesian FEVD
bfevd = fevd(chain, p, n, H; method=:cholesky)

# Report median and credible intervals
for h in [1, 4, 12, 20]
    println(&quot;FEVD at h=$h:&quot;)
    med = round(bfevd.quantiles[h, 1, 1, 2] * 100, digits=1)
    lo = round(bfevd.quantiles[h, 1, 1, 1] * 100, digits=1)
    hi = round(bfevd.quantiles[h, 1, 1, 3] * 100, digits=1)
    println(&quot;  Shock 1 → Var 1: $med% [$lo%, $hi%]&quot;)
end</code></pre><hr/><h2 id="Information-Criteria"><a class="docs-heading-anchor" href="#Information-Criteria">Information Criteria</a><a id="Information-Criteria-1"></a><a class="docs-heading-anchor-permalink" href="#Information-Criteria" title="Permalink"></a></h2><h3 id="Log-Likelihood"><a class="docs-heading-anchor" href="#Log-Likelihood">Log-Likelihood</a><a id="Log-Likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Log-Likelihood" title="Permalink"></a></h3><p>For a Gaussian VAR, the log-likelihood is:</p><p class="math-container">\[\log L = -\frac{T \cdot n}{2} \log(2\pi) - \frac{T}{2} \log|\Sigma| - \frac{1}{2} \sum_{t=1}^{T} u_t&#39; \Sigma^{-1} u_t\]</p><h3 id="Marginal-Likelihood-(Bayesian)"><a class="docs-heading-anchor" href="#Marginal-Likelihood-(Bayesian)">Marginal Likelihood (Bayesian)</a><a id="Marginal-Likelihood-(Bayesian)-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-Likelihood-(Bayesian)" title="Permalink"></a></h3><p>For Bayesian model comparison, we use the marginal likelihood (also called evidence):</p><p class="math-container">\[p(Y | \mathcal{M}) = \int p(Y | \theta, \mathcal{M}) p(\theta | \mathcal{M}) \, d\theta\]</p><p>Models with higher marginal likelihood better balance fit and complexity.</p><hr/><h2 id="Complete-Example"><a class="docs-heading-anchor" href="#Complete-Example">Complete Example</a><a id="Complete-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-Example" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MacroEconometricModels
using Random

Random.seed!(42)

# Generate data
T, n, p = 200, 3, 2
Y = randn(T, n)
for t in 2:T
    Y[t, :] = 0.5 * Y[t-1, :] + 0.3 * randn(n)
end

# Step 1: Optimize hyperparameters
println(&quot;Optimizing hyperparameters...&quot;)
best_hyper = optimize_hyperparameters(Y, p; grid_size=20)
println(&quot;Optimal τ: &quot;, round(best_hyper.tau, digits=4))

# Step 2: Estimate BVAR
println(&quot;\nEstimating BVAR with MCMC...&quot;)
chain = estimate_bvar(Y, p;
    n_samples = 2000,
    n_adapts = 500,
    prior = :minnesota,
    hyper = best_hyper
)

# Step 3: Compute Bayesian IRF
H = 20
birf = irf(chain, p, n, H; method=:cholesky)

# Step 4: Report results
println(&quot;\nBayesian IRF (shock 1 → variable 1):&quot;)
for h in [0, 4, 8, 12, 20]
    med = round(birf.quantiles[h+1, 1, 1, 2], digits=3)
    lo = round(birf.quantiles[h+1, 1, 1, 1], digits=3)
    hi = round(birf.quantiles[h+1, 1, 1, 3], digits=3)
    println(&quot;  h=$h: $med [$lo, $hi]&quot;)
end</code></pre><hr/><h2 id="Large-BVAR"><a class="docs-heading-anchor" href="#Large-BVAR">Large BVAR</a><a id="Large-BVAR-1"></a><a class="docs-heading-anchor-permalink" href="#Large-BVAR" title="Permalink"></a></h2><h3 id="Handling-High-Dimensional-Systems"><a class="docs-heading-anchor" href="#Handling-High-Dimensional-Systems">Handling High-Dimensional Systems</a><a id="Handling-High-Dimensional-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Handling-High-Dimensional-Systems" title="Permalink"></a></h3><p>For large VAR systems (many variables), the Minnesota prior becomes essential:</p><pre><code class="language-julia hljs">using MacroEconometricModels

# Large system: 20 variables
n = 20
p = 4

# Stronger shrinkage for large systems
hyper_large = MinnesotaHyperparameters(
    τ = 0.1,      # Tighter prior
    d = 2.0,
    ω_own = 1.0,
    ω_cross = 0.5, # Penalize cross-variable coefficients
    ω_det = 1.0
)

# Or optimize automatically
best_hyper = optimize_hyperparameters(Y_large, p)</code></pre><p><strong>Reference</strong>: Bańbura, Giannone &amp; Reichlin (2010)</p><hr/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><h3 id="Minnesota-Prior-and-BVAR"><a class="docs-heading-anchor" href="#Minnesota-Prior-and-BVAR">Minnesota Prior and BVAR</a><a id="Minnesota-Prior-and-BVAR-1"></a><a class="docs-heading-anchor-permalink" href="#Minnesota-Prior-and-BVAR" title="Permalink"></a></h3><ul><li>Bańbura, M., Giannone, D., &amp; Reichlin, L. (2010). &quot;Large Bayesian Vector Auto Regressions.&quot; <em>Journal of Applied Econometrics</em>, 25(1), 71-92.</li><li>Carriero, A., Clark, T. E., &amp; Marcellino, M. (2015). &quot;Bayesian VARs: Specification Choices and Forecast Accuracy.&quot; <em>Journal of Applied Econometrics</em>, 30(1), 46-73.</li><li>Doan, T., Litterman, R., &amp; Sims, C. (1984). &quot;Forecasting and Conditional Projection Using Realistic Prior Distributions.&quot; <em>Econometric Reviews</em>, 3(1), 1-100.</li><li>Giannone, D., Lenza, M., &amp; Primiceri, G. E. (2015). &quot;Prior Selection for Vector Autoregressions.&quot; <em>Review of Economics and Statistics</em>, 97(2), 436-451.</li><li>Kadiyala, K. R., &amp; Karlsson, S. (1997). &quot;Numerical Methods for Estimation and Inference in Bayesian VAR-Models.&quot; <em>Journal of Applied Econometrics</em>, 12(2), 99-132.</li><li>Litterman, R. B. (1986). &quot;Forecasting with Bayesian Vector Autoregressions—Five Years of Experience.&quot; <em>Journal of Business &amp; Economic Statistics</em>, 4(1), 25-38.</li></ul><h3 id="MCMC-and-Bayesian-Inference"><a class="docs-heading-anchor" href="#MCMC-and-Bayesian-Inference">MCMC and Bayesian Inference</a><a id="MCMC-and-Bayesian-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#MCMC-and-Bayesian-Inference" title="Permalink"></a></h3><ul><li>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). <em>Bayesian Data Analysis</em> (3rd ed.). CRC Press.</li><li>Hoffman, M. D., &amp; Gelman, A. (2014). &quot;The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.&quot; <em>Journal of Machine Learning Research</em>, 15(1), 1593-1623.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../factormodels/">« Factor Models</a><a class="docs-footer-nextpage" href="../hypothesis_tests/">Unit Root &amp; Cointegration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 2 February 2026 18:23">Monday 2 February 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
