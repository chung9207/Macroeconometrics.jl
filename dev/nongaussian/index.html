<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Non-Gaussian Structural Identification · MacroEconometricModels.jl</title><meta name="title" content="Non-Gaussian Structural Identification · MacroEconometricModels.jl"/><meta property="og:title" content="Non-Gaussian Structural Identification · MacroEconometricModels.jl"/><meta property="twitter:title" content="Non-Gaussian Structural Identification · MacroEconometricModels.jl"/><meta name="description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:description" content="Documentation for MacroEconometricModels.jl."/><meta property="twitter:description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:url" content="https://chung9207.github.io/MacroEconometricModels.jl/nongaussian/"/><meta property="twitter:url" content="https://chung9207.github.io/MacroEconometricModels.jl/nongaussian/"/><link rel="canonical" href="https://chung9207.github.io/MacroEconometricModels.jl/nongaussian/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MacroEconometricModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Univariate Models</span><ul><li><a class="tocitem" href="../arima/">ARIMA</a></li><li><a class="tocitem" href="../volatility/">Volatility Models</a></li></ul></li><li><span class="tocitem">Frequentist Models</span><ul><li><a class="tocitem" href="../manual/">VAR</a></li><li><a class="tocitem" href="../lp/">Local Projections</a></li><li><a class="tocitem" href="../factormodels/">Factor Models</a></li></ul></li><li><span class="tocitem">Bayesian Models</span><ul><li><a class="tocitem" href="../bayesian/">Bayesian VAR</a></li></ul></li><li><a class="tocitem" href="../innovation_accounting/">Innovation Accounting</a></li><li class="is-active"><a class="tocitem" href>Non-Gaussian Structural Identification</a><ul class="internal"><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#Multivariate-Normality-Tests"><span>Multivariate Normality Tests</span></a></li><li><a class="tocitem" href="#ICA-based-SVAR-Identification"><span>ICA-based SVAR Identification</span></a></li><li><a class="tocitem" href="#Non-Gaussian-Maximum-Likelihood"><span>Non-Gaussian Maximum Likelihood</span></a></li><li><a class="tocitem" href="#Heteroskedasticity-Based-Identification"><span>Heteroskedasticity-Based Identification</span></a></li><li><a class="tocitem" href="#Identifiability-and-Specification-Tests"><span>Identifiability and Specification Tests</span></a></li><li><a class="tocitem" href="#Integration-with-IRF-Pipeline"><span>Integration with IRF Pipeline</span></a></li><li><a class="tocitem" href="#Complete-Example"><span>Complete Example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><span class="tocitem">Hypothesis Tests</span><ul><li><a class="tocitem" href="../hypothesis_tests/">Unit Root &amp; Cointegration</a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../api/">Overview</a></li><li><a class="tocitem" href="../api_types/">Types</a></li><li><a class="tocitem" href="../api_functions/">Functions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Non-Gaussian Structural Identification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Non-Gaussian Structural Identification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/chung9207/MacroEconometricModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/chung9207/MacroEconometricModels.jl/blob/main/docs/src/nongaussian.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Non-Gaussian-Structural-Identification"><a class="docs-heading-anchor" href="#Non-Gaussian-Structural-Identification">Non-Gaussian Structural Identification</a><a id="Non-Gaussian-Structural-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussian-Structural-Identification" title="Permalink"></a></h1><p>This page covers identification of structural VAR models using non-Gaussian distributional assumptions, heteroskedasticity, and ICA methods. These methods provide identification without requiring the recursive ordering of Cholesky or the a priori sign/zero restrictions of traditional SVAR.</p><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MacroEconometricModels

# Multivariate normality tests (diagnostics)
suite = normality_test_suite(model)                # Run all 7 tests
jb = jarque_bera_test(model)                       # Multivariate Jarque-Bera

# ICA-based SVAR identification
ica = identify_fastica(model)                      # FastICA (Hyvärinen 1999)
jade = identify_jade(model)                        # JADE (Cardoso 1993)

# Non-Gaussian ML identification
ml = identify_student_t(model)                     # Student-t shocks
ml = identify_nongaussian_ml(model; distribution=:mixture_normal)

# Heteroskedasticity identification
ms = identify_markov_switching(model; n_regimes=2) # Markov-switching (Lanne &amp; Lütkepohl 2008)
ev = identify_external_volatility(model, regime)   # Known volatility regimes (Rigobon 2003)

# Identifiability tests
test_shock_gaussianity(ica)                        # Are shocks non-Gaussian?
test_gaussian_vs_nongaussian(model)                # LR test: Gaussian vs non-Gaussian
test_shock_independence(ica)                       # Are shocks independent?

# Integration with existing IRF pipeline
irfs = irf(model, 20; method=:fastica)             # Works automatically via compute_Q</code></pre><hr/><h2 id="Multivariate-Normality-Tests"><a class="docs-heading-anchor" href="#Multivariate-Normality-Tests">Multivariate Normality Tests</a><a id="Multivariate-Normality-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-Normality-Tests" title="Permalink"></a></h2><p>Before applying non-Gaussian SVAR methods, it is essential to verify that the VAR residuals are indeed non-Gaussian. If residuals are Gaussian, non-Gaussian identification will not work (the problem is unidentified).</p><h3 id="Multivariate-Jarque-Bera-Test"><a class="docs-heading-anchor" href="#Multivariate-Jarque-Bera-Test">Multivariate Jarque-Bera Test</a><a id="Multivariate-Jarque-Bera-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-Jarque-Bera-Test" title="Permalink"></a></h3><p>The multivariate Jarque-Bera test extends the univariate JB test to vector residuals. Under the null hypothesis of multivariate normality, the test statistic is:</p><p class="math-container">\[JB = T \cdot \frac{b_{1,k}}{6} + T \cdot \frac{(b_{2,k} - k(k+2))^2}{24k}\]</p><p>where <span>$b_{1,k}$</span> is the multivariate skewness measure and <span>$b_{2,k}$</span> is the multivariate kurtosis measure (Lütkepohl 2005, §4.5).</p><pre><code class="language-julia hljs">using MacroEconometricModels, Random
Random.seed!(42)
Y = randn(300, 3)
model = estimate_var(Y, 2)

# Joint test
jb = jarque_bera_test(model)
println(&quot;Statistic: $(round(jb.statistic, digits=4)), p-value: $(round(jb.pvalue, digits=4))&quot;)

# Component-wise test on standardized residuals
jb_comp = jarque_bera_test(model; method=:component)
println(&quot;Component p-values: &quot;, round.(jb_comp.component_pvalues, digits=4))</code></pre><p>With Gaussian data, we expect p-values above 0.05 — failure to reject normality.</p><h3 id="Mardia&#39;s-Tests"><a class="docs-heading-anchor" href="#Mardia&#39;s-Tests">Mardia&#39;s Tests</a><a id="Mardia&#39;s-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Mardia&#39;s-Tests" title="Permalink"></a></h3><p>Mardia (1970) proposed separate tests for multivariate skewness and kurtosis:</p><p class="math-container">\[b_{1,k} = \frac{1}{T^2} \sum_{i,j} (u_i&#39; \Sigma^{-1} u_j)^3 \quad \text{(skewness)}\]</p><p class="math-container">\[b_{2,k} = \frac{1}{T} \sum_i (u_i&#39; \Sigma^{-1} u_i)^2 \quad \text{(kurtosis)}\]</p><p>Under H₀: <span>$T \cdot b_{1,k}/6 \sim \chi^2(k(k+1)(k+2)/6)$</span> and <span>$(b_{2,k} - k(k+2)) / \sqrt{8k(k+2)/T} \sim N(0,1)$</span>.</p><pre><code class="language-julia hljs">skew_test = mardia_test(model; type=:skewness)
kurt_test = mardia_test(model; type=:kurtosis)
both_test = mardia_test(model; type=:both)</code></pre><p>The <code>:both</code> option combines both tests into a single chi-squared statistic.</p><p><strong>Reference</strong>: Mardia (1970)</p><h3 id="Doornik-Hansen-Test"><a class="docs-heading-anchor" href="#Doornik-Hansen-Test">Doornik-Hansen Test</a><a id="Doornik-Hansen-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Doornik-Hansen-Test" title="Permalink"></a></h3><p>The Doornik-Hansen (2008) omnibus test applies the Bowman-Shenton transformation to each component&#39;s skewness and kurtosis, producing approximately standard normal transforms <span>$z_1$</span> and <span>$z_2$</span>. The test statistic is:</p><p class="math-container">\[DH = \sum_{j=1}^k (z_{1j}^2 + z_{2j}^2) \sim \chi^2(2k)\]</p><pre><code class="language-julia hljs">dh = doornik_hansen_test(model)</code></pre><h3 id="Henze-Zirkler-Test"><a class="docs-heading-anchor" href="#Henze-Zirkler-Test">Henze-Zirkler Test</a><a id="Henze-Zirkler-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Henze-Zirkler-Test" title="Permalink"></a></h3><p>The Henze-Zirkler (1990) test is based on the empirical characteristic function and is consistent against all alternatives. The test statistic uses a smoothing parameter <span>$\beta$</span> that depends on the sample size and dimension.</p><pre><code class="language-julia hljs">hz = henze_zirkler_test(model)</code></pre><h3 id="Normality-Test-Suite"><a class="docs-heading-anchor" href="#Normality-Test-Suite">Normality Test Suite</a><a id="Normality-Test-Suite-1"></a><a class="docs-heading-anchor-permalink" href="#Normality-Test-Suite" title="Permalink"></a></h3><p>Run all tests at once with <code>normality_test_suite</code>:</p><pre><code class="language-julia hljs">suite = normality_test_suite(model)
println(suite)</code></pre><p>This runs 7 tests: multivariate JB, component-wise JB, Mardia skewness, Mardia kurtosis, Mardia combined, Doornik-Hansen, and Henze-Zirkler.</p><h3 id="Return-Values"><a class="docs-heading-anchor" href="#Return-Values">Return Values</a><a id="Return-Values-1"></a><a class="docs-heading-anchor-permalink" href="#Return-Values" title="Permalink"></a></h3><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>test_name</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Test identifier</td></tr><tr><td style="text-align: right"><code>statistic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Test statistic value</td></tr><tr><td style="text-align: right"><code>pvalue</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">p-value</td></tr><tr><td style="text-align: right"><code>df</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Degrees of freedom</td></tr><tr><td style="text-align: right"><code>n_vars</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of variables</td></tr><tr><td style="text-align: right"><code>n_obs</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of observations</td></tr><tr><td style="text-align: right"><code>components</code></td><td style="text-align: right"><code>Vector{T}</code> or <code>nothing</code></td><td style="text-align: right">Per-component statistics</td></tr><tr><td style="text-align: right"><code>component_pvalues</code></td><td style="text-align: right"><code>Vector{T}</code> or <code>nothing</code></td><td style="text-align: right">Per-component p-values</td></tr></table><hr/><h2 id="ICA-based-SVAR-Identification"><a class="docs-heading-anchor" href="#ICA-based-SVAR-Identification">ICA-based SVAR Identification</a><a id="ICA-based-SVAR-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#ICA-based-SVAR-Identification" title="Permalink"></a></h2><p>Independent Component Analysis (ICA) identifies the structural impact matrix <span>$B_0$</span> by finding the rotation <span>$Q$</span> that makes the recovered shocks <span>$\varepsilon_t = (B_0)^{-1} u_t$</span> maximally independent and non-Gaussian.</p><h3 id="Model-Specification"><a class="docs-heading-anchor" href="#Model-Specification">Model Specification</a><a id="Model-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Specification" title="Permalink"></a></h3><p>The structural VAR has the decomposition:</p><p class="math-container">\[u_t = B_0 \varepsilon_t, \quad \Sigma = B_0 B_0&#39;\]</p><p>where</p><ul><li><span>$u_t$</span> is the <span>$n \times 1$</span> vector of reduced-form residuals</li><li><span>$\varepsilon_t$</span> is the <span>$n \times 1$</span> vector of structural shocks, assumed mutually independent and non-Gaussian</li><li><span>$B_0 = L Q$</span> where <span>$L = \text{chol}(\Sigma)$</span> and <span>$Q$</span> is orthogonal</li></ul><p><strong>Identification condition</strong>: At most one structural shock may be Gaussian (Lanne, Meitz &amp; Saikkonen 2017). If all shocks are non-Gaussian, <span>$B_0$</span> is unique up to column permutation and sign.</p><h3 id="FastICA"><a class="docs-heading-anchor" href="#FastICA">FastICA</a><a id="FastICA-1"></a><a class="docs-heading-anchor-permalink" href="#FastICA" title="Permalink"></a></h3><p>FastICA (Hyvärinen 1999) finds the unmixing matrix by maximizing a measure of non-Gaussianity (negentropy) via a fixed-point algorithm.</p><pre><code class="language-julia hljs"># Default: logcosh contrast, deflation approach
ica = identify_fastica(model)

# Symmetric approach with exponential contrast
ica = identify_fastica(model; approach=:symmetric, contrast=:exp)</code></pre><p>Three contrast functions are available:</p><ul><li><code>:logcosh</code> (default) — robust, good general-purpose choice: <span>$G(u) = \log\cosh(u)$</span></li><li><code>:exp</code> — better for super-Gaussian sources: <span>$G(u) = -\exp(-u^2/2)$</span></li><li><code>:kurtosis</code> — classical kurtosis-based: <span>$G(u) = u^4/4$</span></li></ul><p>Two extraction approaches:</p><ul><li><code>:deflation</code> — extracts components one at a time (deflation approach)</li><li><code>:symmetric</code> — extracts all components simultaneously</li></ul><p><strong>Reference</strong>: Hyvärinen (1999)</p><h3 id="JADE"><a class="docs-heading-anchor" href="#JADE">JADE</a><a id="JADE-1"></a><a class="docs-heading-anchor-permalink" href="#JADE" title="Permalink"></a></h3><p>JADE (Joint Approximate Diagonalization of Eigenmatrices) uses fourth-order cumulant matrices and joint diagonalization via Jacobi rotations.</p><pre><code class="language-julia hljs">jade = identify_jade(model)</code></pre><p>JADE computes the fourth-order cumulant matrices <span>$C_{ij}[k,l] = \text{cum}(z_k, z_l, z_i, z_j)$</span> and finds the orthogonal matrix that simultaneously diagonalizes all of them.</p><p><strong>Reference</strong>: Cardoso &amp; Souloumiac (1993)</p><h3 id="SOBI"><a class="docs-heading-anchor" href="#SOBI">SOBI</a><a id="SOBI-1"></a><a class="docs-heading-anchor-permalink" href="#SOBI" title="Permalink"></a></h3><p>SOBI (Second-Order Blind Identification) exploits temporal structure via autocovariance matrices at multiple lags.</p><pre><code class="language-julia hljs">sobi = identify_sobi(model; lags=1:12)</code></pre><p>Unlike FastICA and JADE which use higher-order statistics, SOBI only uses second-order statistics (autocovariances), making it suitable when temporal dependence is the main source of identifiability.</p><p><strong>Reference</strong>: Belouchrani et al. (1997)</p><h3 id="Distance-Covariance"><a class="docs-heading-anchor" href="#Distance-Covariance">Distance Covariance</a><a id="Distance-Covariance-1"></a><a class="docs-heading-anchor-permalink" href="#Distance-Covariance" title="Permalink"></a></h3><p>Minimizes the sum of pairwise distance covariances between recovered shocks. Distance covariance (Székely et al. 2007) is zero if and only if variables are independent.</p><pre><code class="language-julia hljs">dcov = identify_dcov(model)</code></pre><p><strong>Reference</strong>: Matteson &amp; Tsay (2017)</p><h3 id="HSIC"><a class="docs-heading-anchor" href="#HSIC">HSIC</a><a id="HSIC-1"></a><a class="docs-heading-anchor-permalink" href="#HSIC" title="Permalink"></a></h3><p>Minimizes the Hilbert-Schmidt Independence Criterion using a Gaussian kernel. Like distance covariance, HSIC with a characteristic kernel is zero iff variables are independent.</p><pre><code class="language-julia hljs">hsic = identify_hsic(model; sigma=1.0)</code></pre><p>The bandwidth parameter <span>$\sigma$</span> defaults to the median pairwise distance heuristic.</p><p><strong>Reference</strong>: Gretton et al. (2005)</p><h3 id="ICA-Result-Fields"><a class="docs-heading-anchor" href="#ICA-Result-Fields">ICA Result Fields</a><a id="ICA-Result-Fields-1"></a><a class="docs-heading-anchor-permalink" href="#ICA-Result-Fields" title="Permalink"></a></h3><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix (<span>$n \times n$</span>)</td></tr><tr><td style="text-align: right"><code>W</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Unmixing matrix: <span>$\varepsilon_t = W u_t$</span></td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix: <span>$B_0 = L Q$</span></td></tr><tr><td style="text-align: right"><code>shocks</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Recovered structural shocks (<span>$T \times n$</span>)</td></tr><tr><td style="text-align: right"><code>method</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Method used</td></tr><tr><td style="text-align: right"><code>converged</code></td><td style="text-align: right"><code>Bool</code></td><td style="text-align: right">Whether the algorithm converged</td></tr><tr><td style="text-align: right"><code>iterations</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of iterations</td></tr><tr><td style="text-align: right"><code>objective</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Final objective value</td></tr></table><hr/><h2 id="Non-Gaussian-Maximum-Likelihood"><a class="docs-heading-anchor" href="#Non-Gaussian-Maximum-Likelihood">Non-Gaussian Maximum Likelihood</a><a id="Non-Gaussian-Maximum-Likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussian-Maximum-Likelihood" title="Permalink"></a></h2><p>Instead of the two-step ICA approach, ML methods estimate <span>$B_0$</span> and the shock distribution parameters jointly by maximizing the log-likelihood.</p><h3 id="Model-Specification-2"><a class="docs-heading-anchor" href="#Model-Specification-2">Model Specification</a><a class="docs-heading-anchor-permalink" href="#Model-Specification-2" title="Permalink"></a></h3><p>The log-likelihood under non-Gaussian shocks is:</p><p class="math-container">\[\ell(\theta) = \sum_{t=1}^T \left[ \log|\det(B_0^{-1})| + \sum_{j=1}^n \log f_j(\varepsilon_{j,t}; \theta_j) \right]\]</p><p>where</p><ul><li><span>$\varepsilon_t = B_0^{-1} u_t$</span> are the structural shocks</li><li><span>$f_j(\cdot; \theta_j)$</span> is the marginal density of shock <span>$j$</span></li><li><span>$\theta_j$</span> are distribution-specific parameters (e.g., degrees of freedom for Student-t)</li></ul><h3 id="Student-t-Shocks"><a class="docs-heading-anchor" href="#Student-t-Shocks">Student-t Shocks</a><a id="Student-t-Shocks-1"></a><a class="docs-heading-anchor-permalink" href="#Student-t-Shocks" title="Permalink"></a></h3><p>Assumes each shock follows a (standardized) Student-t distribution with shock-specific degrees of freedom <span>$\nu_j$</span>:</p><pre><code class="language-julia hljs">ml = identify_student_t(model)
println(&quot;Degrees of freedom: &quot;, ml.dist_params[:nu])</code></pre><p>Low <span>$\nu$</span> indicates heavy tails. When <span>$\nu \to \infty$</span>, the shock approaches Gaussianity. Identification requires that at most one shock has <span>$\nu = \infty$</span>.</p><p><strong>Reference</strong>: Lanne, Meitz &amp; Saikkonen (2017)</p><h3 id="Mixture-of-Normals"><a class="docs-heading-anchor" href="#Mixture-of-Normals">Mixture of Normals</a><a id="Mixture-of-Normals-1"></a><a class="docs-heading-anchor-permalink" href="#Mixture-of-Normals" title="Permalink"></a></h3><p>Each shock follows a mixture of two normals: <span>$\varepsilon_j \sim p_j N(0, \sigma_{1j}^2) + (1-p_j) N(0, \sigma_{2j}^2)$</span> with the unit variance constraint <span>$p_j \sigma_{1j}^2 + (1-p_j) \sigma_{2j}^2 = 1$</span>.</p><pre><code class="language-julia hljs">ml = identify_mixture_normal(model)
println(&quot;Mixing probabilities: &quot;, ml.dist_params[:p_mix])</code></pre><p><strong>Reference</strong>: Lanne &amp; Lütkepohl (2010)</p><h3 id="Pseudo-Maximum-Likelihood-(PML)"><a class="docs-heading-anchor" href="#Pseudo-Maximum-Likelihood-(PML)">Pseudo Maximum Likelihood (PML)</a><a id="Pseudo-Maximum-Likelihood-(PML)-1"></a><a class="docs-heading-anchor-permalink" href="#Pseudo-Maximum-Likelihood-(PML)" title="Permalink"></a></h3><p>Uses Pearson Type IV distributions, allowing both skewness and excess kurtosis.</p><pre><code class="language-julia hljs">ml = identify_pml(model)</code></pre><p><strong>Reference</strong>: Herwartz (2018)</p><h3 id="Skew-Normal-Shocks"><a class="docs-heading-anchor" href="#Skew-Normal-Shocks">Skew-Normal Shocks</a><a id="Skew-Normal-Shocks-1"></a><a class="docs-heading-anchor-permalink" href="#Skew-Normal-Shocks" title="Permalink"></a></h3><p>Each shock follows a skew-normal distribution with pdf <span>$f(x) = 2\phi(x)\Phi(\alpha_j x)$</span>.</p><pre><code class="language-julia hljs">ml = identify_skew_normal(model)
println(&quot;Skewness parameters: &quot;, ml.dist_params[:alpha])</code></pre><p><strong>Reference</strong>: Azzalini (1985)</p><h3 id="Unified-Dispatcher"><a class="docs-heading-anchor" href="#Unified-Dispatcher">Unified Dispatcher</a><a id="Unified-Dispatcher-1"></a><a class="docs-heading-anchor-permalink" href="#Unified-Dispatcher" title="Permalink"></a></h3><p>Use <code>identify_nongaussian_ml</code> to select the distribution at runtime:</p><pre><code class="language-julia hljs">for dist in [:student_t, :mixture_normal, :pml, :skew_normal]
    ml = identify_nongaussian_ml(model; distribution=dist)
    println(&quot;$dist: logL=$(round(ml.loglik, digits=2)), AIC=$(round(ml.aic, digits=2))&quot;)
end</code></pre><p>Compare AIC/BIC across distributions to select the best-fitting specification.</p><h3 id="ML-Result-Fields"><a class="docs-heading-anchor" href="#ML-Result-Fields">ML Result Fields</a><a id="ML-Result-Fields-1"></a><a class="docs-heading-anchor-permalink" href="#ML-Result-Fields" title="Permalink"></a></h3><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix</td></tr><tr><td style="text-align: right"><code>shocks</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural shocks</td></tr><tr><td style="text-align: right"><code>distribution</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Distribution used</td></tr><tr><td style="text-align: right"><code>loglik</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Log-likelihood at MLE</td></tr><tr><td style="text-align: right"><code>loglik_gaussian</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Gaussian log-likelihood (for LR test)</td></tr><tr><td style="text-align: right"><code>dist_params</code></td><td style="text-align: right"><code>Dict{Symbol,Any}</code></td><td style="text-align: right">Distribution parameters</td></tr><tr><td style="text-align: right"><code>vcov</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Asymptotic covariance of parameters</td></tr><tr><td style="text-align: right"><code>se</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Standard errors for <span>$B_0$</span></td></tr><tr><td style="text-align: right"><code>converged</code></td><td style="text-align: right"><code>Bool</code></td><td style="text-align: right">Convergence status</td></tr><tr><td style="text-align: right"><code>aic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Akaike information criterion</td></tr><tr><td style="text-align: right"><code>bic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Bayesian information criterion</td></tr></table><hr/><h2 id="Heteroskedasticity-Based-Identification"><a class="docs-heading-anchor" href="#Heteroskedasticity-Based-Identification">Heteroskedasticity-Based Identification</a><a id="Heteroskedasticity-Based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroskedasticity-Based-Identification" title="Permalink"></a></h2><p>These methods identify <span>$B_0$</span> from changes in the error covariance across volatility regimes, without requiring non-Gaussianity.</p><h3 id="Eigendecomposition-Identification"><a class="docs-heading-anchor" href="#Eigendecomposition-Identification">Eigendecomposition Identification</a><a id="Eigendecomposition-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Eigendecomposition-Identification" title="Permalink"></a></h3><p>The core idea (Rigobon 2003): given two regime covariance matrices <span>$\Sigma_1$</span> and <span>$\Sigma_2$</span>, the eigendecomposition of <span>$\Sigma_1^{-1}\Sigma_2$</span> yields:</p><p class="math-container">\[\Sigma_1^{-1}\Sigma_2 = V D V^{-1}\]</p><p>where</p><ul><li><span>$V$</span> contains the eigenvectors</li><li><span>$D = \text{diag}(\lambda_1, \ldots, \lambda_n)$</span> contains the relative variance ratios</li><li><span>$B_0 = \Sigma_1^{1/2} V$</span> (with normalization)</li></ul><p><strong>Identification condition</strong>: The eigenvalues <span>$\lambda_j$</span> must be distinct.</p><h3 id="Markov-Switching-Volatility"><a class="docs-heading-anchor" href="#Markov-Switching-Volatility">Markov-Switching Volatility</a><a id="Markov-Switching-Volatility-1"></a><a class="docs-heading-anchor-permalink" href="#Markov-Switching-Volatility" title="Permalink"></a></h3><p>Estimates regime-specific covariance matrices via the Hamilton (1989) filter with EM algorithm:</p><pre><code class="language-julia hljs">ms = identify_markov_switching(model; n_regimes=2)
println(&quot;Transition matrix:&quot;)
println(round.(ms.transition_matrix, digits=3))
println(&quot;Regime probabilities (first 5 obs):&quot;)
println(round.(ms.regime_probs[1:5, :], digits=3))</code></pre><p>The EM algorithm iterates:</p><ol><li><strong>E-step</strong>: Hamilton filter (forward) + Kim smoother (backward) → regime probabilities</li><li><strong>M-step</strong>: Update regime covariances and transition matrix given probabilities</li></ol><p><strong>Reference</strong>: Lanne &amp; Lütkepohl (2008)</p><h3 id="GARCH-Based-Identification"><a class="docs-heading-anchor" href="#GARCH-Based-Identification">GARCH-Based Identification</a><a id="GARCH-Based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#GARCH-Based-Identification" title="Permalink"></a></h3><p>Uses GARCH(1,1) conditional heteroskedasticity in the structural shocks for identification:</p><p class="math-container">\[h_{j,t} = \omega_j + \alpha_j \varepsilon_{j,t-1}^2 + \beta_j h_{j,t-1}\]</p><pre><code class="language-julia hljs">garch = identify_garch(model)
println(&quot;GARCH parameters (ω, α, β):&quot;)
for j in 1:size(garch.garch_params, 1)
    println(&quot;  Shock $j: &quot;, round.(garch.garch_params[j, :], digits=4))
end</code></pre><p><strong>Reference</strong>: Normandin &amp; Phaneuf (2004)</p><h3 id="Smooth-Transition"><a class="docs-heading-anchor" href="#Smooth-Transition">Smooth Transition</a><a id="Smooth-Transition-1"></a><a class="docs-heading-anchor-permalink" href="#Smooth-Transition" title="Permalink"></a></h3><p>The covariance varies smoothly between two regimes via a logistic transition function:</p><p class="math-container">\[\Sigma_t = B_0 [I + G(s_t)(\Lambda - I)] B_0&#39;\]</p><p>where <span>$G(s_t) = 1/(1 + \exp(-\gamma(s_t - c)))$</span> is the logistic transition function.</p><pre><code class="language-julia hljs"># Use a lagged variable as the transition variable
s = Y[2:end, 1]  # first variable, lagged
st = identify_smooth_transition(model, s)
println(&quot;Transition speed γ = $(round(st.gamma, digits=3))&quot;)
println(&quot;Threshold c = $(round(st.threshold, digits=3))&quot;)</code></pre><p><strong>Reference</strong>: Lütkepohl &amp; Netšunajev (2017)</p><h3 id="External-Volatility-Instruments"><a class="docs-heading-anchor" href="#External-Volatility-Instruments">External Volatility Instruments</a><a id="External-Volatility-Instruments-1"></a><a class="docs-heading-anchor-permalink" href="#External-Volatility-Instruments" title="Permalink"></a></h3><p>When volatility regimes are known a priori (e.g., NBER recession dates, financial crisis indicators):</p><pre><code class="language-julia hljs"># Binary regime indicator
regime = vcat(fill(1, 100), fill(2, 100))  # first half = regime 1
ev = identify_external_volatility(model, regime)</code></pre><p>This is the simplest heteroskedasticity method — it just splits the sample and applies eigendecomposition identification.</p><p><strong>Reference</strong>: Rigobon (2003)</p><hr/><h2 id="Identifiability-and-Specification-Tests"><a class="docs-heading-anchor" href="#Identifiability-and-Specification-Tests">Identifiability and Specification Tests</a><a id="Identifiability-and-Specification-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Identifiability-and-Specification-Tests" title="Permalink"></a></h2><h3 id="Shock-Gaussianity-Test"><a class="docs-heading-anchor" href="#Shock-Gaussianity-Test">Shock Gaussianity Test</a><a id="Shock-Gaussianity-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Shock-Gaussianity-Test" title="Permalink"></a></h3><p>Tests whether recovered structural shocks are non-Gaussian using univariate Jarque-Bera tests on each shock. Non-Gaussian identification requires at most one Gaussian shock.</p><pre><code class="language-julia hljs">ica = identify_fastica(model)
result = test_shock_gaussianity(ica)
println(&quot;Number of Gaussian shocks: &quot;, result.details[:n_gaussian])
println(&quot;Identified: &quot;, result.identified)</code></pre><h3 id="Gaussian-vs-Non-Gaussian-LR-Test"><a class="docs-heading-anchor" href="#Gaussian-vs-Non-Gaussian-LR-Test">Gaussian vs Non-Gaussian LR Test</a><a id="Gaussian-vs-Non-Gaussian-LR-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-vs-Non-Gaussian-LR-Test" title="Permalink"></a></h3><p>Likelihood ratio test: <span>$H_0$</span>: Gaussian shocks vs <span>$H_1$</span>: non-Gaussian shocks.</p><p class="math-container">\[LR = 2(\ell_1 - \ell_0) \sim \chi^2(p)\]</p><p>where <span>$p$</span> is the number of extra distribution parameters.</p><pre><code class="language-julia hljs">lr = test_gaussian_vs_nongaussian(model; distribution=:student_t)
println(&quot;LR statistic: $(round(lr.statistic, digits=4))&quot;)
println(&quot;p-value: $(round(lr.pvalue, digits=4))&quot;)</code></pre><p>Rejecting <span>$H_0$</span> supports the use of non-Gaussian identification.</p><h3 id="Shock-Independence-Test"><a class="docs-heading-anchor" href="#Shock-Independence-Test">Shock Independence Test</a><a id="Shock-Independence-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Shock-Independence-Test" title="Permalink"></a></h3><p>Tests whether recovered shocks are mutually independent using both cross-correlation (portmanteau) and distance covariance tests, combined via Fisher&#39;s method.</p><pre><code class="language-julia hljs">result = test_shock_independence(ica; max_lag=10)
println(&quot;Independent: &quot;, result.identified)  # fail-to-reject = independent</code></pre><h3 id="Identification-Strength"><a class="docs-heading-anchor" href="#Identification-Strength">Identification Strength</a><a id="Identification-Strength-1"></a><a class="docs-heading-anchor-permalink" href="#Identification-Strength" title="Permalink"></a></h3><p>Bootstrap test of identification robustness: resamples residuals and measures the stability of the estimated <span>$B_0$</span>.</p><pre><code class="language-julia hljs">result = test_identification_strength(model; method=:fastica, n_bootstrap=499)
println(&quot;Median Procrustes distance: $(round(result.statistic, digits=4))&quot;)</code></pre><p>Small distances indicate strong identification.</p><h3 id="Overidentification-Test"><a class="docs-heading-anchor" href="#Overidentification-Test">Overidentification Test</a><a id="Overidentification-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Overidentification-Test" title="Permalink"></a></h3><p>Tests consistency of additional restrictions beyond non-Gaussianity.</p><pre><code class="language-julia hljs">result = test_overidentification(model, ica; n_bootstrap=499)
println(&quot;p-value: $(round(result.pvalue, digits=4))&quot;)</code></pre><hr/><h2 id="Integration-with-IRF-Pipeline"><a class="docs-heading-anchor" href="#Integration-with-IRF-Pipeline">Integration with IRF Pipeline</a><a id="Integration-with-IRF-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Integration-with-IRF-Pipeline" title="Permalink"></a></h2><p>All ICA and ML methods integrate seamlessly with the existing <code>irf</code>, <code>fevd</code>, and <code>historical_decomposition</code> functions via <code>compute_Q</code>:</p><pre><code class="language-julia hljs"># Any non-Gaussian method works as an irf method
irfs_ica = irf(model, 20; method=:fastica)
irfs_ml  = irf(model, 20; method=:student_t)
irfs_ms  = irf(model, 20; method=:markov_switching)

# FEVD and HD also work
decomp = fevd(model, 20; method=:fastica)</code></pre><p>Supported method symbols: <code>:fastica</code>, <code>:jade</code>, <code>:sobi</code>, <code>:dcov</code>, <code>:hsic</code>, <code>:student_t</code>, <code>:mixture_normal</code>, <code>:pml</code>, <code>:skew_normal</code>, <code>:markov_switching</code>, <code>:garch</code>.</p><hr/><h2 id="Complete-Example"><a class="docs-heading-anchor" href="#Complete-Example">Complete Example</a><a id="Complete-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-Example" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MacroEconometricModels, Random
Random.seed!(42)

# Generate VAR data
T_obs, n = 300, 3
Y = randn(T_obs, n)
for t in 3:T_obs
    Y[t, :] = 0.5 * Y[t-1, :] + 0.2 * Y[t-2, :] + 0.8 * randn(n)
end
model = estimate_var(Y, 2)

# Step 1: Test for non-Gaussianity
suite = normality_test_suite(model)
println(suite)

# Step 2: Try ICA identification
ica = identify_fastica(model)
println(&quot;\nFastICA result:&quot;)
println(&quot;  Converged: &quot;, ica.converged)
println(&quot;  Q orthogonal: &quot;, round(norm(ica.Q&#39; * ica.Q - I), digits=8))

# Step 3: Verify identification
gauss = test_shock_gaussianity(ica)
println(&quot;\nShock Gaussianity Test:&quot;)
println(&quot;  Number of Gaussian shocks: &quot;, gauss.details[:n_gaussian])
println(&quot;  JB p-values: &quot;, round.(gauss.details[:jb_pvals], digits=4))

indep = test_shock_independence(ica; max_lag=5)
println(&quot;\nShock Independence Test:&quot;)
println(&quot;  Independent: &quot;, indep.identified)
println(&quot;  Fisher p-value: &quot;, round(indep.pvalue, digits=4))

# Step 4: Compare with ML approach
ml = identify_student_t(model)
println(&quot;\nStudent-t ML:&quot;)
println(&quot;  ν = &quot;, round.(ml.dist_params[:nu], digits=2))
println(&quot;  AIC = $(round(ml.aic, digits=2)), BIC = $(round(ml.bic, digits=2))&quot;)

lr = test_gaussian_vs_nongaussian(model)
println(&quot;\nGaussian vs Non-Gaussian LR test:&quot;)
println(&quot;  LR = $(round(lr.statistic, digits=4)), p = $(round(lr.pvalue, digits=4))&quot;)

# Step 5: Compute IRFs
irfs = irf(model, 20; method=:fastica)
println(&quot;\nIRF size: &quot;, size(irfs.values))</code></pre><hr/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><h3 id="Multivariate-Normality-Tests-2"><a class="docs-heading-anchor" href="#Multivariate-Normality-Tests-2">Multivariate Normality Tests</a><a class="docs-heading-anchor-permalink" href="#Multivariate-Normality-Tests-2" title="Permalink"></a></h3><ul><li>Jarque, Carlos M., and Anil K. Bera. 1980. &quot;Efficient Tests for Normality, Homoscedasticity and Serial Independence of Regression Residuals.&quot; <em>Economics Letters</em> 6 (3): 255–259. <a href="https://doi.org/10.1016/0165-1765(80)90024-5">https://doi.org/10.1016/0165-1765(80)90024-5</a></li><li>Mardia, Kanti V. 1970. &quot;Measures of Multivariate Skewness and Kurtosis with Applications.&quot; <em>Biometrika</em> 57 (3): 519–530. <a href="https://doi.org/10.1093/biomet/57.3.519">https://doi.org/10.1093/biomet/57.3.519</a></li><li>Doornik, Jurgen A., and Henrik Hansen. 2008. &quot;An Omnibus Test for Univariate and Multivariate Normality.&quot; <em>Oxford Bulletin of Economics and Statistics</em> 70: 927–939. <a href="https://doi.org/10.1111/j.1468-0084.2008.00537.x">https://doi.org/10.1111/j.1468-0084.2008.00537.x</a></li><li>Henze, Norbert, and Bernhard Zirkler. 1990. &quot;A Class of Invariant Consistent Tests for Multivariate Normality.&quot; <em>Communications in Statistics - Theory and Methods</em> 19 (10): 3595–3617. <a href="https://doi.org/10.1080/03610929008830400">https://doi.org/10.1080/03610929008830400</a></li><li>Lütkepohl, Helmut. 2005. <em>New Introduction to Multiple Time Series Analysis</em>. Berlin: Springer. ISBN 978-3-540-40172-8.</li></ul><h3 id="ICA-based-Identification"><a class="docs-heading-anchor" href="#ICA-based-Identification">ICA-based Identification</a><a id="ICA-based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#ICA-based-Identification" title="Permalink"></a></h3><ul><li>Hyvärinen, Aapo. 1999. &quot;Fast and Robust Fixed-Point Algorithms for Independent Component Analysis.&quot; <em>IEEE Transactions on Neural Networks</em> 10 (3): 626–634. <a href="https://doi.org/10.1109/72.761722">https://doi.org/10.1109/72.761722</a></li><li>Cardoso, Jean-François, and Antoine Souloumiac. 1993. &quot;Blind Beamforming for Non-Gaussian Signals.&quot; <em>IEE Proceedings-F</em> 140 (6): 362–370. <a href="https://doi.org/10.1049/ip-f-2.1993.0054">https://doi.org/10.1049/ip-f-2.1993.0054</a></li><li>Belouchrani, Adel, Karim Abed-Meraim, Jean-François Cardoso, and Eric Moulines. 1997. &quot;A Blind Source Separation Technique Using Second-Order Statistics.&quot; <em>IEEE Transactions on Signal Processing</em> 45 (2): 434–444. <a href="https://doi.org/10.1109/78.554307">https://doi.org/10.1109/78.554307</a></li></ul><h3 id="Non-Gaussian-ML"><a class="docs-heading-anchor" href="#Non-Gaussian-ML">Non-Gaussian ML</a><a id="Non-Gaussian-ML-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussian-ML" title="Permalink"></a></h3><ul><li>Lanne, Markku, Mika Meitz, and Pentti Saikkonen. 2017. &quot;Identification and Estimation of Non-Gaussian Structural Vector Autoregressions.&quot; <em>Journal of Econometrics</em> 196 (2): 288–304. <a href="https://doi.org/10.1016/j.jeconom.2016.06.002">https://doi.org/10.1016/j.jeconom.2016.06.002</a></li><li>Lanne, Markku, and Helmut Lütkepohl. 2010. &quot;Structural Vector Autoregressions with Nonnormal Residuals.&quot; <em>Journal of Business &amp; Economic Statistics</em> 28 (1): 159–168. <a href="https://doi.org/10.1198/jbes.2009.06003">https://doi.org/10.1198/jbes.2009.06003</a></li><li>Herwartz, Helmut. 2018. &quot;Hodges-Lehmann Detection of Structural Shocks: An Analysis of Macroeconomic Dynamics in the Euro Area.&quot; <em>Oxford Bulletin of Economics and Statistics</em> 80 (4): 736–754. <a href="https://doi.org/10.1111/obes.12237">https://doi.org/10.1111/obes.12237</a></li><li>Azzalini, Adelchi. 1985. &quot;A Class of Distributions Which Includes the Normal Ones.&quot; <em>Scandinavian Journal of Statistics</em> 12 (2): 171–178. <a href="https://doi.org/10.1111/j.1467-9469.1985.tb01174.x">https://doi.org/10.1111/j.1467-9469.1985.tb01174.x</a></li></ul><h3 id="Heteroskedasticity-based-Identification"><a class="docs-heading-anchor" href="#Heteroskedasticity-based-Identification">Heteroskedasticity-based Identification</a><a id="Heteroskedasticity-based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroskedasticity-based-Identification" title="Permalink"></a></h3><ul><li>Rigobon, Roberto. 2003. &quot;Identification through Heteroskedasticity.&quot; <em>Review of Economics and Statistics</em> 85 (4): 777–792. <a href="https://doi.org/10.1162/003465303772815727">https://doi.org/10.1162/003465303772815727</a></li><li>Lanne, Markku, and Helmut Lütkepohl. 2008. &quot;Identifying Monetary Policy Shocks via Changes in Volatility.&quot; <em>Journal of Money, Credit and Banking</em> 40 (6): 1131–1149. <a href="https://doi.org/10.1111/j.1538-4616.2008.00151.x">https://doi.org/10.1111/j.1538-4616.2008.00151.x</a></li><li>Normandin, Michel, and Louis Phaneuf. 2004. &quot;Monetary Policy Shocks: Testing Identification Conditions under Time-Varying Conditional Volatility.&quot; <em>Journal of Monetary Economics</em> 51 (6): 1217–1243. <a href="https://doi.org/10.1016/j.jmoneco.2003.11.002">https://doi.org/10.1016/j.jmoneco.2003.11.002</a></li><li>Lütkepohl, Helmut, and Aleksei Netšunajev. 2017. &quot;Structural Vector Autoregressions with Smooth Transition in Variances.&quot; <em>Journal of Economic Dynamics and Control</em> 84: 43–57. <a href="https://doi.org/10.1016/j.jedc.2017.09.001">https://doi.org/10.1016/j.jedc.2017.09.001</a></li></ul><h3 id="Independence-Measures"><a class="docs-heading-anchor" href="#Independence-Measures">Independence Measures</a><a id="Independence-Measures-1"></a><a class="docs-heading-anchor-permalink" href="#Independence-Measures" title="Permalink"></a></h3><ul><li>Székely, Gábor J., Maria L. Rizzo, and Nail K. Bakirov. 2007. &quot;Measuring and Testing Dependence by Correlation of Distances.&quot; <em>Annals of Statistics</em> 35 (6): 2769–2794. <a href="https://doi.org/10.1214/009053607000000505">https://doi.org/10.1214/009053607000000505</a></li><li>Gretton, Arthur, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. 2005. &quot;Measuring Statistical Dependence with Hilbert-Schmidt Norms.&quot; In <em>Algorithmic Learning Theory</em>, edited by Sanjay Jain, Hans Ulrich Simon, and Etsuji Tomita, 63–77. Berlin: Springer. <a href="https://doi.org/10.1007/11564089_7">https://doi.org/10.1007/11564089_7</a></li><li>Matteson, David S., and Ruey S. Tsay. 2017. &quot;Independent Component Analysis via Distance Covariance.&quot; <em>Journal of the American Statistical Association</em> 112 (518): 623–637. <a href="https://doi.org/10.1080/01621459.2016.1150851">https://doi.org/10.1080/01621459.2016.1150851</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../innovation_accounting/">« Innovation Accounting</a><a class="docs-footer-nextpage" href="../hypothesis_tests/">Unit Root &amp; Cointegration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Saturday 7 February 2026 11:44">Saturday 7 February 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
